{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24069346-2c9c-4d6b-b812-d59f2804e36c",
   "metadata": {},
   "source": [
    "## Exercise 3.3: Fully fused Ozaki-I Scheme\n",
    "\n",
    "Our next optimization will be to fuse the remaining portions of the epilogue function.  This would be casting anti-diagonal accumulators to FP64, scaling the FP64 values, accumulating anti-diagonals, and scaling based on the exponent shifting done for slicing.\n",
    "\n",
    "Once you are done, spend some time profiling the kernels across a few different problem shapes.  Think about how the results change and why.  What factors are causing this?  Hint: look at the grid dimensions and consider hardware resources.\n",
    "\n",
    "Some other questions you can consider:\n",
    "1. Where does fusion seem to help the most?\n",
    "2. Can you find cases where fusion does not help?\n",
    "\n",
    "<img src=\"Images/Ozaki-I-Multiplications-Fused.png\" width=\"800\" height=\"auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a204e-ea61-49a6-a97d-e783f3912013",
   "metadata": {},
   "source": [
    "### C++ Cmake Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44386b3-b024-429a-b78a-1ca743f73e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.sep.join([\"..\", \"utilities\", \"python\"]))\n",
    "from common_cuda import setup_cmake_project\n",
    "setup_cmake_project()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657980a5-14a1-4d9f-b013-cade838938a1",
   "metadata": {},
   "source": [
    "### Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24745538-973e-4721-bb29-7aa4e19dd505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import nvmath\n",
    "import math\n",
    "\n",
    "from nvmath.device import Matmul\n",
    "from nvmath.device.cublasdx import DevicePipeline, SharedStorageCalc, MAX_ALIGNMENT\n",
    "from nvmath.device.cublasdx_numba import pipeline_extensions\n",
    "from nvmath.device.common import axpby, clear, copy, copy_fragment, copy_wait, make_tensor, make_fragment_like\n",
    "from numba import cuda\n",
    "\n",
    "sys.path.append(os.sep.join([\"..\", \"utilities\", \"python\"]))\n",
    "\n",
    "from benchmark import *\n",
    "from emulation_utils import get_width, epilogue_ldexp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55d2c0-5479-4d9e-abbd-3ac0bcb7f0b4",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac7a49-07ab-4337-979c-aa9e121902f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cpp/2c_fully_fused_emulation/parameters.hpp.inc\n",
    "\n",
    "    // ===================================\n",
    "    // Problem configuration\n",
    "    // ===================================\n",
    "\n",
    "    // (gemm_m, gemm_n, gemm_k, alpha, beta)\n",
    "    std::vector<tutorial::gemm_problem_t> problems = {\n",
    "        {2048, 2048, 2048, 0.9, 1.1}\n",
    "    };\n",
    "    \n",
    "\n",
    "    // ===================================\n",
    "    // Global GEMM configuration\n",
    "    // ===================================\n",
    "\n",
    "    // The number of slices used in emulation algorithm\n",
    "    // More slices = higher precision but more computation\n",
    "    constexpr unsigned slices = 7;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9545479-9d2f-4130-b410-173f9cf87943",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cpp/2c_fully_fused_emulation/cublasdx_config.hpp.inc\n",
    "\n",
    "    using slice_value_type       = int8_t;  // Precision for individual slices\n",
    "    using accumulator_value_type = int32_t; // Precision for accumulation\n",
    "\n",
    "    // The shape of data tile processed by a single CTA block\n",
    "    constexpr int tile_m = 128;\n",
    "    constexpr int tile_n = 128;\n",
    "    constexpr int tile_k = 128;\n",
    "\n",
    "    // The shape of CTA block (number of threads)\n",
    "    constexpr int cta_shape_x = 128;\n",
    "    constexpr int cta_shape_y = 1;\n",
    "    constexpr int cta_shape_z = 1;\n",
    "\n",
    "    using BLAS = decltype(cublasdx::Size<tile_m, tile_n, tile_k>() +\n",
    "                          cublasdx::Precision<slice_value_type, slice_value_type, accumulator_value_type>() +\n",
    "                          cublasdx::Type<cublasdx::type::real>() + cublasdx::Function<cublasdx::function::MM>() +\n",
    "                          cublasdx::Arrangement<arrangement_a, arrangement_b, arrangement_c>() + cublasdx::Block() +\n",
    "                          cublasdx::BlockDim<cta_shape_x, cta_shape_y, cta_shape_z>() + cublasdx::StaticBlockDim() +\n",
    "                          cublasdx::WithPipeline() + cublasdx::MaxAlignment() + cublasdx::EnableInputStreaming() +\n",
    "                          cublasdx::SM<SM_VALUE, SM_MODIFIER_VALUE>());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a0f84-9477-4294-b59b-f4d806411cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cpp/2c_fully_fused_emulation/pipeline_config.hpp.inc\n",
    "\n",
    "        constexpr int pipeline_depth = 3;\n",
    "        auto device_pipeline = cublasdx::suggest_device_pipeline<pipeline_depth, BLAS, cublasdx::external_accumulation>(\n",
    "                                   tensor_slice_a, tensor_slice_b)\n",
    "                                   .value();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013bf66-8ad0-441d-b86e-694588047e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cpp/2c_fully_fused_emulation/fused_kernel.hpp.inc\n",
    "\n",
    "template<class BLAS,\n",
    "         class DevicePipeline,\n",
    "         class Alpha,\n",
    "         class Beta,\n",
    "         class CTensor,\n",
    "         class AShiftTensor,\n",
    "         class BShiftTensor,\n",
    "         int32_t Slices>\n",
    "__launch_bounds__(DevicePipeline::max_threads_per_block, 1) __global__\n",
    "    void fused_epilogue_kernel(__grid_constant__ DevicePipeline const device_pipeline,\n",
    "                               Alpha                                  alpha,\n",
    "                               Beta                                   beta,\n",
    "                               CTensor                                gmem_c_fp64,\n",
    "                               AShiftTensor const                     gmem_shift_a,\n",
    "                               BShiftTensor const                     gmem_shift_b) {\n",
    "    extern __shared__ __align__(device_pipeline.buffer_alignment()) char smem[];\n",
    "#ifdef __CUDA_ARCH__\n",
    "    /* \n",
    "     * EXERCISE --> Complete the kernel to compute all products, accumulate along diagonals, and convert back to FP64\n",
    "     */\n",
    "    if constexpr (cublasdx::sm_of_v<BLAS> == __CUDA_ARCH__) {\n",
    "        // ================================\n",
    "        // 1. SETUP AND TILE PREPARATION\n",
    "        // ================================\n",
    "\n",
    "        constexpr int tile_m = cublasdx::size_of_v_m<BLAS>;\n",
    "        constexpr int tile_n = cublasdx::size_of_v_n<BLAS>;\n",
    "\n",
    "        // EXERCISE --> Choose the diagonal and term along the diagonal that you'd like to start with\n",
    "        constexpr auto initial_diag = \n",
    "        constexpr auto initial_term = \n",
    "\n",
    "        auto [pipeline_smem, smem_shift_a, smem_shift_b] =\n",
    "            cublasdx::shared_memory::slice<char, int32_t, int32_t>(smem,\n",
    "                                                                   device_pipeline.buffer_alignment(),\n",
    "                                                                   device_pipeline.buffer_size(),\n",
    "                                                                   cublasdx::alignment_of_v_a<BLAS>,\n",
    "                                                                   cute::make_layout(cute::Int<tile_m>()),\n",
    "                                                                   cublasdx::alignment_of_v_b<BLAS>,\n",
    "                                                                   cute::make_layout(cute::Int<tile_n>()));\n",
    "\n",
    "        // Copy general purpose data\n",
    "        cublasdx::copy<BLAS, 16>(gmem_shift_a(cute::_, blockIdx.x), smem_shift_a);\n",
    "        cublasdx::copy<BLAS, 16>(gmem_shift_b(cute::_, blockIdx.y), smem_shift_b);\n",
    "        cublasdx::copy_wait();\n",
    "            \n",
    "        // Get pipeline tile\n",
    "        auto tile_pipeline = device_pipeline.get_tile(pipeline_smem,\n",
    "                                                      cublasdx::make_coord(blockIdx.x, initial_term),\n",
    "                                                      cublasdx::make_coord(blockIdx.y, initial_diag));\n",
    "\n",
    "        auto accumulator = tile_pipeline.get_accumulator();\n",
    "\n",
    "        // ================================\n",
    "        // 2. FP64 C INPUT / OUTPUT TILE SETUP\n",
    "        // ================================\n",
    "\n",
    "        auto tile_c_fp64_gmem = cublasdx::get_tile(gmem_c_fp64, BLAS::c_shape, blockIdx.x, blockIdx.y);\n",
    "\n",
    "        // ============================================\n",
    "        // 3. OZAKI SCHEME DIAGONAL ITERATION\n",
    "        // ============================================\n",
    "#    pragma unroll 1\n",
    "        for (int diag = initial_diag; /* for loop over diagonals */) {\n",
    "\n",
    "            // Initialize accumulator for this diagonal\n",
    "            accumulator.clear();\n",
    "\n",
    "            // ==========================================\n",
    "            // 4. SLICE COMBINATION COMPUTATION\n",
    "            // ==========================================\n",
    "#    pragma unroll 1\n",
    "            for (int term = initial_term; /* for loop to iterate along the diagonal */) {\n",
    "                // =========================================\n",
    "                // 5. N-STAGE MEMORY PIPELINE FOR GEMM\n",
    "                // =========================================\n",
    "\n",
    "                tile_pipeline.execute(accumulator);\n",
    "\n",
    "                const auto next_slice_row = // A slice index\n",
    "                const auto next_slice_col = // B slice index\n",
    "                device_pipeline.reset_tile(tile_pipeline,\n",
    "                                           cublasdx::make_coord(blockIdx.x, next_slice_row),\n",
    "                                           cublasdx::make_coord(blockIdx.y, next_slice_col));\n",
    "            }\n",
    "\n",
    "            // ========================================\n",
    "            // 6. RESULT RECONSTRUCTION AND EPILOGUE\n",
    "            // ========================================\n",
    "\n",
    "            auto c_fp64_frag = accumulator.make_partition_and_copy(tile_c_fp64_gmem);\n",
    "\n",
    "            if (accumulator.is_thread_active()) {\n",
    "                // Convert accumulated int32_t results back to double precision\n",
    "                // and apply appropriate scaling based on slice positions\n",
    "                auto gemm_results = accumulator.get_results();\n",
    "\n",
    "                // Load existing C values\n",
    "                auto d_fp64_frag = cublasdx::make_fragment_like<double>(gemm_results);\n",
    "\n",
    "                // At this point of the computation, we can no longer longer do tile based operations.  When we convert back to\n",
    "                // FP64 we need to know the shifts associated with the row of A and column of B that produced this value.  The\n",
    "                // cublasDx library gives us the ability to figure out the relative index within the tile.  We can use this to\n",
    "                // find our shifts, do some intermediate computations, and then proceed with more tile computations.\n",
    "                    \n",
    "                # pragma unroll\n",
    "                for (int i = 0; i < cublasdx::size(d_fp64_frag); ++i) {\n",
    "                    const auto [global_x, global_y] = accumulator.map_fragment_index(i);\n",
    "\n",
    "                    // Exercise --> Use shared memory to get the shifts for this particular element\n",
    "                    const auto shift_a_elem = \n",
    "                    const auto shift_b_elem = \n",
    "\n",
    "                    // Convert int32_t slice result back to double precision\n",
    "                    // with appropriate scaling for this diagonal and element\n",
    "                    d_fp64_frag(i) = nth_slice_to_fp64<int32_t, int8_t>(diag, gemm_results(i), shift_a_elem + shift_b_elem);\n",
    "                }\n",
    "\n",
    "                // Apply alpha/beta scaling and accumulate into C\n",
    "                // Use beta only for the first diagonal we process, then just add (beta=1.0)\n",
    "                double beta_used = beta;\n",
    "                if (/* EXERCISE --> Figure out when to use 1.0 for beta */) {\n",
    "                    beta_used = 1.0;\n",
    "                }\n",
    "                cublasdx::axpby(alpha, d_fp64_frag, beta_used, c_fp64_frag);                \n",
    "            }\n",
    "            \n",
    "            // Store results back to global memory\n",
    "            accumulator.partition_and_copy(c_fp64_frag, tile_c_fp64_gmem);\n",
    "        }\n",
    "    }\n",
    "#endif\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94a5e0-4f37-4a41-9524-31bf6f593cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cmake --build ./build -t 2c_fully_fused_emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29399cdc-c197-4e78-9e05-f2b9833dffc9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./build/2c_fully_fused_emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d5be5-c802-451d-b94b-c57a9571e009",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1c518-5494-42bd-8eca-a44314c9c2dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:49:12.098964Z",
     "iopub.status.busy": "2026-01-24T23:49:12.098749Z",
     "iopub.status.idle": "2026-01-24T23:49:12.237397Z",
     "shell.execute_reply": "2026-01-24T23:49:12.236569Z",
     "shell.execute_reply.started": "2026-01-24T23:49:12.098941Z"
    }
   },
   "source": [
    "We will rewrite kernel now and recompile the solution. If you want to restart your exercise make sure you rewrite kernel back and recompile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd00ed9-d723-4266-b1ee-b3eca06442ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cpp/2c_fully_fused_emulation/fused_kernel.hpp.inc\n",
    "\n",
    "template<class BLAS,\n",
    "         class DevicePipeline,\n",
    "         class Alpha,\n",
    "         class Beta,\n",
    "         class CTensor,\n",
    "         class AShiftTensor,\n",
    "         class BShiftTensor,\n",
    "         int32_t Slices>\n",
    "__launch_bounds__(DevicePipeline::max_threads_per_block, 1) __global__\n",
    "    void fused_epilogue_kernel(__grid_constant__ DevicePipeline const device_pipeline,\n",
    "                               Alpha                                  alpha,\n",
    "                               Beta                                   beta,\n",
    "                               CTensor                                gmem_c_fp64,\n",
    "                               AShiftTensor const                     gmem_shift_a,\n",
    "                               BShiftTensor const                     gmem_shift_b) {\n",
    "    extern __shared__ __align__(device_pipeline.buffer_alignment()) char smem[];\n",
    "#ifdef __CUDA_ARCH__\n",
    "    if constexpr (cublasdx::sm_of_v<BLAS> == __CUDA_ARCH__) {\n",
    "        // ================================\n",
    "        // 1. SETUP AND TILE PREPARATION\n",
    "        // ================================\n",
    "\n",
    "        constexpr int tile_m = cublasdx::size_of_v_m<BLAS>;\n",
    "        constexpr int tile_n = cublasdx::size_of_v_n<BLAS>;\n",
    "\n",
    "        constexpr auto initial_diag = Slices - 1;\n",
    "        constexpr auto initial_term = 0;\n",
    "\n",
    "        auto [pipeline_smem, smem_shift_a, smem_shift_b] =\n",
    "            cublasdx::shared_memory::slice<char, int32_t, int32_t>(smem,\n",
    "                                                                   device_pipeline.buffer_alignment(),\n",
    "                                                                   device_pipeline.buffer_size(),\n",
    "                                                                   cublasdx::alignment_of_v_a<BLAS>,\n",
    "                                                                   cute::make_layout(cute::Int<tile_m>()),\n",
    "                                                                   cublasdx::alignment_of_v_b<BLAS>,\n",
    "                                                                   cute::make_layout(cute::Int<tile_n>()));\n",
    "\n",
    "        // Copy general purpose data\n",
    "        cublasdx::copy<BLAS, 16>(gmem_shift_a(cute::_, blockIdx.x), smem_shift_a);\n",
    "        cublasdx::copy<BLAS, 16>(gmem_shift_b(cute::_, blockIdx.y), smem_shift_b);\n",
    "        cublasdx::copy_wait();\n",
    "\n",
    "\n",
    "        // Get pipeline tile\n",
    "        auto tile_pipeline = device_pipeline.get_tile(pipeline_smem,\n",
    "                                                      cublasdx::make_coord(blockIdx.x, initial_term),\n",
    "                                                      cublasdx::make_coord(blockIdx.y, initial_diag));\n",
    "\n",
    "        auto accumulator = tile_pipeline.get_accumulator();\n",
    "\n",
    "        // ================================\n",
    "        // 2. FP64 C INPUT / OUTPUT TILE SETUP\n",
    "        // ================================\n",
    "\n",
    "        auto tile_c_fp64_gmem = cublasdx::get_tile(gmem_c_fp64, BLAS::c_shape, blockIdx.x, blockIdx.y);\n",
    "\n",
    "        // ============================================\n",
    "        // 3. OZAKI SCHEME DIAGONAL ITERATION\n",
    "        // ============================================\n",
    "\n",
    "        // Iterate over diagonals in reverse order (highest power of 2 first)\n",
    "        // This ensures proper accumulation order for numerical stability\n",
    "#    pragma unroll 1\n",
    "        for (auto diag = initial_diag; diag >= 0; --diag) {\n",
    "\n",
    "            // Initialize accumulator for this diagonal\n",
    "            accumulator.clear();\n",
    "\n",
    "            // ==========================================\n",
    "            // 4. SLICE COMBINATION COMPUTATION\n",
    "            // ==========================================\n",
    "\n",
    "            // Compute all slice combinations that contribute to this diagonal\n",
    "            // For diagonal d, we compute: A_slice[i] * B_slice[d-i] for i = 0 to d\n",
    "#    pragma unroll 1\n",
    "            for (auto term = initial_term; term <= diag; ++term) {\n",
    "                // =========================================\n",
    "                // 5. N-STAGE MEMORY PIPELINE FOR GEMM\n",
    "                // =========================================\n",
    "\n",
    "                tile_pipeline.execute(accumulator);\n",
    "\n",
    "                const auto next_slice_row = (term == diag) ? 0 : term + 1;                         // A slice index\n",
    "                const auto next_slice_col = (term == diag) ? (diag - 1) : (diag - next_slice_row); // B slice index\n",
    "                device_pipeline.reset_tile(tile_pipeline,\n",
    "                                           cublasdx::make_coord(blockIdx.x, next_slice_row),\n",
    "                                           cublasdx::make_coord(blockIdx.y, next_slice_col));\n",
    "            } /* end of slice combination loop */\n",
    "\n",
    "            // ========================================\n",
    "            // 6. RESULT RECONSTRUCTION AND EPILOGUE\n",
    "            // ========================================\n",
    "\n",
    "            // Load existing C values\n",
    "            auto c_fp64_frag = accumulator.make_partition_and_copy(tile_c_fp64_gmem);\n",
    "\n",
    "            if (accumulator.is_thread_active()) {\n",
    "                // Convert accumulated int32_t results back to double precision\n",
    "                // and apply appropriate scaling based on slice positions\n",
    "                auto gemm_results = accumulator.get_results();\n",
    "\n",
    "                auto d_fp64_frag = cublasdx::make_fragment_like<double>(gemm_results);\n",
    "\n",
    "                // At this point of the compuation, we can no longer longer do tile based operations.  When we convert back to\n",
    "                // FP64 we need to know the shifts associated with the row of A and column of B that produced this value.  The\n",
    "                // cublasDx library gives us the ability to figure out the relative index within the tile.  We can use this to\n",
    "                // find our shifts, do some intermediate computations, and then proceed with more tile computations.\n",
    "\n",
    "                # pragma unroll\n",
    "                for (int i = 0; i < cublasdx::size(d_fp64_frag); ++i) {\n",
    "                    const auto [global_x, global_y] = accumulator.map_fragment_index(i);\n",
    "                    const auto shift_a_elem         = smem_shift_a(global_x);\n",
    "                    const auto shift_b_elem         = smem_shift_b(global_y);\n",
    "\n",
    "                    // Convert int32_t slice result back to double precision\n",
    "                    // with appropriate scaling for this diagonal and element\n",
    "                    d_fp64_frag(i) =\n",
    "                        nth_slice_to_fp64<int32_t, int8_t>(diag, gemm_results(i), shift_a_elem + shift_b_elem);\n",
    "                }\n",
    "\n",
    "                // Apply alpha/beta scaling and accumulate into C\n",
    "                // Use beta only for the first diagonal (highest order), then just add (beta=1.0)\n",
    "                cublasdx::axpby(alpha, d_fp64_frag, (diag == Slices - 1) ? beta : 1.0, c_fp64_frag);\n",
    "            }\n",
    "\n",
    "            // Store results back to global memory\n",
    "            accumulator.partition_and_copy(c_fp64_frag, tile_c_fp64_gmem);       \n",
    "        }\n",
    "    }\n",
    "#endif\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740fadd9-f450-4f10-abe8-8f40e683a44f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cmake --build ./build -t 2c_fully_fused_emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f8cefd-d8f2-4bae-9923-c2e309468cb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./build/2c_fully_fused_emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2683baa-4549-43a7-94e7-2915ea6a8838",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891635c0-7eef-49c7-b713-47ec1aea9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\n",
    "  (2048, 2048, 2048, 0.9, 1.1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628581e-2410-4ce1-ad6e-d6c3ec2b6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emulated_dgemm_kernel(BLAS):\n",
    "\n",
    "    assert BLAS.a_value_type == BLAS.b_value_type, \"Invalid BLAS configuration\"\n",
    "\n",
    "    tile_m, tile_n = BLAS.c_dim\n",
    "\n",
    "    uint8_width = get_width(np.uint8)\n",
    "    \n",
    "    @cuda.jit(device=True, forceinline=True)\n",
    "    def nth_slice_to_fp64(nth, nth_slice, exponent_shift):\n",
    "        ko = math.pow(2.0, -nth * uint8_width)\n",
    "\n",
    "        value = ko * np.float64(nth_slice)\n",
    "        return epilogue_ldexp(value, -exponent_shift)\n",
    "    \n",
    "    @cuda.jit(extensions=pipeline_extensions, launch_bounds=(BLAS.block_size, 1))\n",
    "    def dgemm_kernel(slices, shift_a_tensor, shift_b_tensor, alpha, beta, tensor_c, device_pipeline: DevicePipeline):\n",
    "        m, n = tensor_c.shape\n",
    "\n",
    "        # EXERCISE --> Complete the kernel to compute all products, accumulate along diagonals, and convert back to FP64\n",
    "\n",
    "        # ================================\n",
    "        # 1. SETUP AND TILE PREPARATION\n",
    "        # ================================\n",
    "\n",
    "        block_m = cuda.blockIdx.x\n",
    "        block_n = cuda.blockIdx.y\n",
    "        \n",
    "        # EXERCISE --> Choose the diagonal and term along the diagonal that you'd like to start with\n",
    "        initial_diag = -1\n",
    "        initial_term = -1\n",
    "\n",
    "        smem = cuda.shared.array(shape=(0,), dtype=np.int8, alignment=device_pipeline.buffer_alignment)\n",
    "        smem_pipeline, smem = smem[:device_pipeline.buffer_size], smem[device_pipeline.buffer_size:].view(np.int32)\n",
    "        smem_shift_a, smem = smem[:tile_m], smem[tile_m:]\n",
    "        smem_shift_b, smem = smem[:tile_n], smem[tile_n:]\n",
    "\n",
    "        # Copy general purpose data\n",
    "        block_start_m = block_m * tile_m\n",
    "        block_end_m = (block_m + 1) * tile_m\n",
    "\n",
    "        block_start_n = block_n * tile_n\n",
    "        block_end_n = (block_n + 1) * tile_n\n",
    "\n",
    "        if block_start_m >= m or block_start_n >= n:\n",
    "            return\n",
    "\n",
    "        shift_a_view = shift_a_tensor[block_start_m : block_end_m]\n",
    "        shift_b_view = shift_b_tensor[block_start_n : block_end_n]\n",
    "\n",
    "        tid = cuda.threadIdx.x\n",
    "        if tid < tile_m:\n",
    "            smem_shift_a[tid] = shift_a_view[tid]\n",
    "        if tid < tile_n:\n",
    "            smem_shift_b[tid] = shift_b_view[tid]\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Get pipeline tile\n",
    "        tile_pipeline = device_pipeline.get_tile(smem_pipeline,\n",
    "                                                 (block_m, np.int32(initial_term)),\n",
    "                                                 (block_n, np.int32(initial_diag)))\n",
    "        \n",
    "        accumulator = BLAS.suggest_accumulator()\n",
    "\n",
    "        # ================================\n",
    "        # 2. FP64 C INPUT / OUTPUT TILE SETUP\n",
    "        # ================================\n",
    "\n",
    "        c_view = tensor_c[\n",
    "            block_start_m : block_end_m,\n",
    "            block_start_n : block_end_n,\n",
    "        ]\n",
    "\n",
    "        ldc = max(c_view.strides) // c_view.itemsize\n",
    "        gmem_c = make_tensor(c_view, BLAS.get_layout_gmem_c(ldc))\n",
    "        \n",
    "        # ============================================\n",
    "        # 3. OZAKI SCHEME DIAGONAL ITERATION\n",
    "        # ============================================\n",
    "        for diag in range(-1): # EXERCISE --> for loop over diagonals\n",
    "            \n",
    "            accumulator.clear()\n",
    "\n",
    "            # ==========================================\n",
    "            # 4. SLICE COMBINATION COMPUTATION\n",
    "            # ==========================================\n",
    "            for term in range(-1): # EXERCISE --> for loop to iterate along the diagonal\n",
    "                # =========================================\n",
    "                # 5. N-STAGE MEMORY PIPELINE FOR GEMM\n",
    "                # =========================================\n",
    "                tile_pipeline.execute(accumulator)\n",
    "\n",
    "                # EXERCISE --> Determine which slice of A and slice of B to multiply\n",
    "                next_slice_row = -1\n",
    "                next_slice_col = -1\n",
    "\n",
    "                device_pipeline.reset_tile(tile_pipeline,\n",
    "                                           (block_m, np.int32(next_slice_row)),\n",
    "                                           (block_n, np.int32(next_slice_col)))\n",
    "\n",
    "            # ========================================\n",
    "            # 6. RESULT RECONSTRUCTION AND EPILOGUE\n",
    "            # ========================================\n",
    "            if accumulator.is_thread_active():\n",
    "                # Convert accumulated int32_t results back to double precision\n",
    "                # and apply appropriate scaling based on slice positions\n",
    "                gemm_results = accumulator.get_results()\n",
    "\n",
    "                # Load existing C values\n",
    "                c_fp64_frag = accumulator.make_partition_and_copy(gmem_c)\n",
    "                d_fp64_frag = make_fragment_like(gemm_results, np.float64)\n",
    "\n",
    "                # At this point of the compuation, we can no longer longer do tile based operations.  When we convert back to\n",
    "                # FP64 we need to know the shifts associated with the row of A and column of B that produced this value.  The\n",
    "                # nvmath-python cublasDx bindings give us the ability to figure out the relative index within the tile.  We can\n",
    "                # use this to find our shifts, do some intermediate computations, and then proceed with more tile computations.\n",
    "                for i in range(c_fp64_frag.layout.size):\n",
    "                    # Get the elements offsets within the output tile\n",
    "                    (global_x, global_y) = accumulator.map_fragment_index(i)\n",
    "                    # Exercise --> Use shared memory to get the shifts for this particular element\n",
    "                    shift_a = -1\n",
    "                    shift_b = -1\n",
    "\n",
    "                    # Convert int32_t slice result back to double precision\n",
    "                    # with appropriate scaling for this diagonal and element\n",
    "                    d_fp64_frag[i] = nth_slice_to_fp64(diag, gemm_results[i], shift_a + shift_b)\n",
    "\n",
    "                # Apply alpha/beta scaling and accumulate into C\n",
    "                # Use beta only for the first diagonal we process, then just add (beta=1.0)\n",
    "                beta_used = beta\n",
    "                if True: # EXERCISE -> Figure out when to use 1.0 for beta\n",
    "                    beta_used = 1.0\n",
    "                axpby(alpha, d_fp64_frag, beta_used, c_fp64_frag)\n",
    "\n",
    "                accumulator.partition_and_copy(c_fp64_frag, gmem_c)\n",
    "\n",
    "        tile_pipeline._del()\n",
    "\n",
    "    return dgemm_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7cee2d-006f-452b-a9d8-b83930f9160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fused_dgemm_ozaki(tensor_slicedA_cupy, tensor_slicedB_cupy, tensor_c_cupy, tensor_shift_a_cupy, tensor_shift_b_cupy, alpha, beta, context, warmup=True):\n",
    "    m, n           = tensor_c_cupy.shape\n",
    "    _, k, slices   = tensor_slicedA_cupy.shape\n",
    "\n",
    "    BLAS = context[\"BLAS\"]\n",
    "    PIPELINE_DEPTH = context[\"PIPELINE_DEPTH\"]\n",
    "    gemm_kernel = context[\"gemm_kernel\"]\n",
    "    grid = context[\"gemm_grid\"]\n",
    "    block = context[\"gemm_block\"]\n",
    "\n",
    "    TILE_M, TILE_N = BLAS.c_dim\n",
    "\n",
    "    tensor_slicedA = cuda.as_cuda_array(tensor_slicedA_cupy)\n",
    "    tensor_slicedB = cuda.as_cuda_array(tensor_slicedB_cupy)\n",
    "    tensor_shift_a = cuda.as_cuda_array(tensor_shift_a_cupy)\n",
    "    tensor_shift_b = cuda.as_cuda_array(tensor_shift_b_cupy)\n",
    "    tensor_c = cuda.as_cuda_array(tensor_c_cupy)\n",
    "\n",
    "    device_pipeline = BLAS.suggest_device_pipeline(PIPELINE_DEPTH, tensor_slicedA, tensor_slicedB)\n",
    "\n",
    "    smem_size = device_pipeline.buffer_size + (TILE_M + TILE_N) * np.dtype(np.int32).itemsize\n",
    "    if warmup:\n",
    "        set_max_dynamic_shared_size_bytes(gemm_kernel, smem_size,\n",
    "                                            slices, tensor_shift_a, tensor_shift_b, alpha, beta, tensor_c, device_pipeline)\n",
    "    gemm_kernel[grid, block, 0, smem_size](slices, tensor_shift_a, tensor_shift_b, alpha, beta, tensor_c, device_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec6e27-8186-4e47-8ce7-de9f3da75306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_func(m, n, k):\n",
    "    tile_m = 128\n",
    "    tile_n = 128\n",
    "    tile_k = 128\n",
    "    \n",
    "    pipeline_depth = 3\n",
    "    block_size = 128\n",
    "\n",
    "    assert m % tile_m == 0, \"Unsupported dimension m for TILE_M\"\n",
    "    assert n % tile_n == 0, \"Unsupported dimension n for TILE_N\"\n",
    "    assert k % tile_k == 0, \"Unsupported dimension k for TILE_K\"\n",
    "    assert k >= (tile_k * pipeline_depth), \"Unsupported pipeline depth for k\"\n",
    "    \n",
    "    BLAS = Matmul(size=(tile_m, tile_n, tile_k),\n",
    "                  precision=(np.int8, np.int8, np.int32),\n",
    "                  data_type=\"real\",\n",
    "                  alignment=MAX_ALIGNMENT,\n",
    "                  arrangement=(\"row_major\", \"col_major\", \"col_major\"), # Do not change\n",
    "                  execution=\"Block\",\n",
    "                  block_size=block_size,\n",
    "                  with_pipeline=True,\n",
    "                  enable_input_streaming=True,\n",
    "                  static_block_dim=True)\n",
    "\n",
    "    gemm_grid = (m // tile_m, n // tile_n)\n",
    "    gemm_block = BLAS.block_dim\n",
    "\n",
    "    return {\n",
    "        \"BLAS\": BLAS,\n",
    "        \"PIPELINE_DEPTH\": pipeline_depth,\n",
    "        \"gemm_kernel\" : get_emulated_dgemm_kernel(BLAS),\n",
    "        \"gemm_grid\": gemm_grid,\n",
    "        \"gemm_block\": gemm_block,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1d6ef-b04c-455b-a2e0-fbf80925e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_fused_emulated_dgemm(problems, setup_func, fused_dgemm_ozaki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970edfd-cd9c-4600-b865-feb23b59471f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d58a0-5507-4a8c-a95b-c1d316fa24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emulated_dgemm_kernel_solution(BLAS):\n",
    "\n",
    "    assert BLAS.a_value_type == BLAS.b_value_type, \"Invalid BLAS configuration\"\n",
    "\n",
    "    tile_m, tile_n = BLAS.c_dim\n",
    "\n",
    "    uint8_width = get_width(np.uint8)\n",
    "    \n",
    "    @cuda.jit(device=True, forceinline=True)\n",
    "    def nth_slice_to_fp64(nth, nth_slice, exponent_shift):\n",
    "        ko = math.pow(2.0, -nth * uint8_width)\n",
    "\n",
    "        value = ko * np.float64(nth_slice)\n",
    "        return epilogue_ldexp(value, -exponent_shift)\n",
    "    \n",
    "    @cuda.jit(extensions=pipeline_extensions, launch_bounds=(BLAS.block_size, 1))\n",
    "    def dgemm_kernel(slices, shift_a_tensor, shift_b_tensor, alpha, beta, tensor_c, device_pipeline: DevicePipeline):\n",
    "        m, n = tensor_c.shape\n",
    "\n",
    "        block_m = cuda.blockIdx.x\n",
    "        block_n = cuda.blockIdx.y\n",
    "\n",
    "        smem = cuda.shared.array(shape=(0,), dtype=np.int8, alignment=device_pipeline.buffer_alignment)\n",
    "        smem_pipeline, smem = smem[:device_pipeline.buffer_size], smem[device_pipeline.buffer_size:].view(np.int32)\n",
    "        smem_shift_a, smem = smem[:tile_m], smem[tile_m:]\n",
    "        smem_shift_b, smem = smem[:tile_n], smem[tile_n:]\n",
    "\n",
    "        block_start_m = block_m * tile_m\n",
    "        block_end_m = (block_m + 1) * tile_m\n",
    "\n",
    "        block_start_n = block_n * tile_n\n",
    "        block_end_n = (block_n + 1) * tile_n\n",
    "\n",
    "        if block_start_m >= m or block_start_n >= n:\n",
    "            return\n",
    "\n",
    "        shift_a_view = shift_a_tensor[block_start_m : block_end_m]\n",
    "        shift_b_view = shift_b_tensor[block_start_n : block_end_n]\n",
    "\n",
    "        tid = cuda.threadIdx.x\n",
    "        if tid < tile_m:\n",
    "            smem_shift_a[tid] = shift_a_view[tid]\n",
    "        if tid < tile_n:\n",
    "            smem_shift_b[tid] = shift_b_view[tid]\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        c_view = tensor_c[\n",
    "            block_start_m : block_end_m,\n",
    "            block_start_n : block_end_n,\n",
    "        ]\n",
    "\n",
    "        ldc = max(c_view.strides) // c_view.itemsize\n",
    "        gmem_c = make_tensor(c_view, BLAS.get_layout_gmem_c(ldc))\n",
    "        \n",
    "        initial_diag = slices - 1\n",
    "        initial_term = 0\n",
    "\n",
    "        tile_pipeline = device_pipeline.get_tile(smem_pipeline,\n",
    "                                                 (block_m, np.int32(initial_term)),\n",
    "                                                 (block_n, np.int32(initial_diag)))\n",
    "        \n",
    "        accumulator = BLAS.suggest_accumulator()\n",
    "        for diag in range(initial_diag, -1, -1):\n",
    "            \n",
    "            accumulator.clear()\n",
    "            for term in range(initial_term, diag + 1):\n",
    "                tile_pipeline.execute(accumulator)\n",
    "\n",
    "                next_slice_row =          0 if term == diag else term + 1\n",
    "                next_slice_col = (diag - 1) if term == diag else diag - next_slice_row\n",
    "\n",
    "                device_pipeline.reset_tile(tile_pipeline,\n",
    "                                           (block_m, np.int32(next_slice_row)),\n",
    "                                           (block_n, np.int32(next_slice_col)))\n",
    "\n",
    "            if accumulator.is_thread_active():\n",
    "                gemm_results = accumulator.get_results()\n",
    "        \n",
    "                acc_fp64_frag = make_fragment_like(gemm_results, np.float64)\n",
    "                c_fp64_frag = accumulator.make_partition_and_copy(gmem_c)\n",
    "        \n",
    "                # At this point of the compuation, we can no longer longer do tile based operations.  When we convert back to\n",
    "                # FP64 we need to know the shifts associated with the row of A and column of B that produced this value.  The\n",
    "                # nvmath-python cublasDx bindings give us the ability to figure out the relative index within the tile.  We can\n",
    "                # use this to find our shifts, do some intermediate computations, and then proceed with more tile computations.\n",
    "                for i in range(c_fp64_frag.layout.size):\n",
    "                    (global_x, global_y) = accumulator.map_fragment_index(i)\n",
    "                    shift_a = smem_shift_a[global_x]\n",
    "                    shift_b = smem_shift_b[global_y]\n",
    "        \n",
    "                    acc_fp64_frag[i] = nth_slice_to_fp64(diag, gemm_results[i], shift_a + shift_b)\n",
    "        \n",
    "                beta_used = beta if diag == slices - 1 else 1.0\n",
    "                axpby(alpha, acc_fp64_frag, beta_used, c_fp64_frag)\n",
    "                accumulator.partition_and_copy(c_fp64_frag, gmem_c)\n",
    "\n",
    "        tile_pipeline._del()\n",
    "\n",
    "    return dgemm_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f15d9-e6fd-43ca-8660-216d51f1bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_func_solution(m, n, k):\n",
    "    ctx = setup_func(m, n, k)\n",
    "    BLAS = ctx[\"BLAS\"]\n",
    "    ctx[\"gemm_kernel\"] = get_emulated_dgemm_kernel_solution(BLAS)\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16387c-8906-4c5a-ad98-10713ce0d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_fused_emulated_dgemm(problems, setup_func_solution, fused_dgemm_ozaki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446bb3ae-e948-4833-b8b0-eb07835f6ba3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we finished fusing the epilogue kernel into our emulated gemm kernel.  The core technique needed was an API to get our relative coordinates within the tile and use that to make element specific updates.  From there, we kept utilizing tile-based API's for efficiency and simplicity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
