{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45494e75-0bb2-4116-a92e-72bd2d5466f6",
   "metadata": {},
   "source": [
    "# Matrix Multiplication Fundamentals\n",
    "\n",
    "A GEMM (General Matrix Multiply) operation takes the form $C = \\alpha \\mathbf{A}\\mathbf{B} + \\beta\\mathbf{C}$ where $\\alpha, \\beta$ are scalars, $\\mathbf{A}$ is an $m \\times k$ matrix, $\\mathbf{B}$ is a $k \\times n$ matrix, and $\\mathbf{C}$ is a $m \\times n$ matrix.\n",
    "\n",
    "The element at row $i$ and column $j$ of matrix $\\mathbf{C}$ is calculated as the scaled and biased dot product of row $i$ of $\\mathbf{A}$ and column $j$ of $\\mathbf{B}$ as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{C}_{i, j} = \\alpha \\left(\\sum_{l=0}^{k} \\mathbf{A}_{i, l} \\mathbf{B}_{l, j} \\right) + \\beta \\mathbf{C}_{i, j}\n",
    "$$\n",
    "\n",
    "In implementation the above operation is usually split into 2 parts:\n",
    "1. Matrix Multiplication itself, computing $ \\mathbf{D}_{i, j} = \\sum_{l=0}^{k} \\mathbf{A}_{i, l} \\mathbf{B}_{l, j} $\n",
    "2. Epilogue, computing $ \\mathbf{C}_{i, j} = \\alpha \\cdot \\mathbf{D}_{i, j} + \\beta \\cdot \\mathbf{C}_{i, j} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce8553-5f92-4568-8e0c-d05bb80d293b",
   "metadata": {},
   "source": [
    "### Exercise Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04244e3-5c73-4c8f-a5f2-b2dc03cf3d81",
   "metadata": {},
   "source": [
    "#### C++ CMake setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc1b3e-d872-4de9-bdab-eb0ec22ee2ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.sep.join([\"..\", \"utilities\", \"python\"]))\n",
    "from common_cuda import setup_cmake_project\n",
    "setup_cmake_project()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23299eb4-fed2-451b-815d-f4f098e99a01",
   "metadata": {},
   "source": [
    "#### Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac6fc0-95d5-4c3a-9d30-000d3d4a3d92",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import nvmath\n",
    "\n",
    "from nvmath.device import Matmul\n",
    "from nvmath.device.cublasdx import DevicePipeline, SharedStorageCalc, MAX_ALIGNMENT\n",
    "from nvmath.device.cublasdx_numba import pipeline_extensions\n",
    "from nvmath.device.common import axpby, clear, copy, copy_fragment, copy_wait, make_tensor\n",
    "from numba import cuda\n",
    "\n",
    "sys.path.append(os.sep.join([\"..\", \"utilities\", \"python\"]))\n",
    "\n",
    "from benchmark import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd8594-9e87-406a-92c9-2386aaef7168",
   "metadata": {},
   "source": [
    "## Challenge Exercise 2.4: cuBLASDx\n",
    "\n",
    "In this exercise, we will convert previous custom tiled GEMM logic to cuBLASDx for both BLAS computations and data movement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410fc937-0bda-492c-a413-f00288dd9ba8",
   "metadata": {},
   "source": [
    "![cublasdx](images/cublasdx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b98c8-360e-409b-b151-7a97428c6715",
   "metadata": {},
   "source": [
    "### cuBLASDx shared memory tile kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6fff8-aea5-4fb0-bf93-3cf4e8cd265f",
   "metadata": {},
   "source": [
    "The following kernel reimplements the one from previous notebook using `cuBLASDx` for data movement and computation. How does this help us in improving the kernel? \n",
    "\n",
    "While we were able to increase data reuse on shared memory tile level, our code still missed several key features of a proper GEMM kernel:\n",
    "1. Use of MMA instructions, allowing for higher FLOP/s as well as better data reuse (on warp, warpgroup, block and cluster level)\n",
    "2. Use of async data copies to overlap computation with background data loading, on global, shared and register level\n",
    "3. Data load vectorization, operating on multiple elements at the same time\n",
    "4. Shared memory use without size increase or bank conflicts\n",
    "\n",
    "All these are provided by `cuBLASDx` together with multiple utilities allowing to keep the code performant, portable and tiny in size. \n",
    "\n",
    "cuBLASDx documentation offers a [short guide](https://docs.nvidia.com/cuda/cublasdx/using_cublasdx.html) on using library's functionality.\n",
    "\n",
    "![device_gemm](images/device_gemm.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04331a5-05b8-4e44-939a-99c47799ddfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### cuBLASDx C++ Guides\n",
    "\n",
    "It's best to use these guides as they will become necessary in exercise, instead of trying to remember all the details at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf260fe-86f4-425a-b938-2cfbe7e23f71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### cuBLASDx guide: Data Layouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7946aba-70a2-408c-b804-e12859863e2f",
   "metadata": {},
   "source": [
    "The way that data is laid out in shared memory is very important for GEMM performance, it allows or limits vectorization and shared memory bank conflicts. This arrangement of elements is called `layout` in `cuBLASDx` and is a first class element computed by the library for you. It can be accessed with:\n",
    "\n",
    "```\n",
    "auto default_layout_a = BLAS::get_layout_smem_a();\n",
    "```\n",
    "\n",
    "More information regarding default memory layouts can be found [here](https://docs.nvidia.com/cuda/cublasdx/api/other_methods.html#get-memory-layout). \n",
    "\n",
    "\n",
    "for regular `row-` or `column-major` layout (as described with the `cublasdx::Arrangement<...>()` operator) or:\n",
    "\n",
    "```\n",
    "auto optimal_layout_a = BLAS::suggest_layout_smem_a();\n",
    "```\n",
    "\n",
    "which computes a layout swizzled for maximum vectorization, removal of shared memory bank conflicts and enablement of instructions such as `ld.matrix` (`LDSM`). You can find out more about suggested layout [here](https://docs.nvidia.com/cuda/cublasdx/api/other_methods.html#suggested-shared-memory-layout)\n",
    "\n",
    "Such layouts can be used to later create tensors from them by combining with a data pointer:\n",
    "\n",
    "```\n",
    "auto tensor_a = cublasdx::make_tensor(data_pointer, BLAS::suggest_layout_smem_a());\n",
    "\n",
    "// elements are accesses with parentheses operator\n",
    "auto elem_0_0 = tensor_a(row_index, col_index);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d2883-9def-4063-b357-077442194494",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### cuBLASDx guide: Slicing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf95004-e844-4c2f-8f34-fa48113c81da",
   "metadata": {},
   "source": [
    "Manually moving pointers is tedious and error prone so cuBLASDx exposes `pointer slicing API` allowing to do it automatically for you.\n",
    "\n",
    "Slicing can be performed to get pointers:\n",
    "\n",
    "```\n",
    "auto [ptr_a, ptr_b, ptr_c] = cublasdx::slice_into_pointer<type_a, type_b, type_c>(start_pointer, \n",
    "                                                                                  alignment_a, layout_a,\n",
    "                                                                                  alignment_b, layout_b,\n",
    "                                                                                  alignment_c, num_elems_c);\n",
    "```\n",
    "\n",
    "or to get pointers and tensors:\n",
    "\n",
    "```\n",
    "auto [tensor_a, tensor_b, ptr_c] = cublasdx::slice<type_a, type_b, type_c>(start_pointer, \n",
    "                                                                     alignment_a, layout_a,\n",
    "                                                                     alignment_b, layout_b,\n",
    "                                                                     alignment_c, num_elems_c);\n",
    "```\n",
    "\n",
    "Detailed reference of slicing function and their use can be found in the [documentation](https://docs.nvidia.com/cuda/cublasdx/api/other_shared.html#shared-memory-slicing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e26891-7774-4ac7-a5c9-0ef290556a21",
   "metadata": {},
   "source": [
    "##### cuBLASDx guide: Shared Memory Copying "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee670f-bf7c-4a2a-9cac-14418f24a3d1",
   "metadata": {},
   "source": [
    "Moving data between global and shared memory is an important and complicated topic. The layout of tile data in shared memory must take under account:\n",
    "1. Pattern for best global memory read\n",
    "2. Pattern for best shared memory store\n",
    "3. Pattern for best compute load\n",
    "4. Pattern for best compute store\n",
    "\n",
    "All these steps can be recomposed into 2 elements:\n",
    "- A data memory layout (as described in `Data Layouts`)\n",
    "- Heuristic for combining `source layout` and `destination layout` into an algorithm maximizing achieved bandwidth.\n",
    "\n",
    "The latter part is provided by `cublasdx::copy`:\n",
    "\n",
    "```\n",
    "// Copy from global to shared using BLAS BlockDim config\n",
    "using alignment = cublasdx::alignment_of<BLAS>;\n",
    "cublasdx::copy<BLAS, alignment::a>(gmem_tensor_a, smem_tensor_a);\n",
    "cublasdx::copy<BLAS, alignment::b>(gmem_tensor_b, smem_tensor_b);\n",
    "cublasdx::copy_wait();\n",
    "\n",
    "// Copy from shared to global using 128 threads\n",
    "cublasdx::copy<128, alignment::a>(smem_tensor_a, gmem_tensor_a);\n",
    "cublasdx::copy_wait();\n",
    "```\n",
    "\n",
    "The copies are async by default so they can be overlapped with other operations, sync point is forced with `cublasdx::copy_wait` which will wait on all previous copies from the entire threadblock.\n",
    "\n",
    "A detailed reference of all copying overloads and functions can be found in the [documentation](https://docs.nvidia.com/cuda/cublasdx/api/other_tensors.html#cooperative-global-shared-copying)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce7bf4-72cb-4fef-8dbc-98e750a16061",
   "metadata": {},
   "source": [
    "##### cuBLASDx guide: Accumulators and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09bb24-fcbe-4c98-a222-ba0220b253d4",
   "metadata": {},
   "source": [
    "cuBLASDx `execute(...)` exposes several APIs to be chosen from by the user:\n",
    "\n",
    "```\n",
    "#1 Shared memory API with optional pre- and postprocessing lambdas\n",
    "BLAS().execute(alpha, tensor_a, tensor_b, beta, tensor_c, \n",
    "               [a_load_functor, b_load_functor, c_load_functor, c_store_functor]);\n",
    "\n",
    "#2 Register API without accumulation with optional preprocessing lambdas\n",
    "auto accumulator = BLAS().execute(tensor_a, tensor_b,\n",
    "                                  [a_load_functor, b_load_functor]);\n",
    "\n",
    "#3 Register API with accumulation with optional preprocessing lambdas\n",
    "BLAS().execute(tensor_a, tensor_b, accumulator,\n",
    "               [a_load_functor, b_load_functor]);\n",
    "```\n",
    "\n",
    "accumulator is a collection of per-thread C elements with associated execution properties. It exposes APIs such as:\n",
    "\n",
    "```\n",
    "// Retrieve register tensor with results\n",
    "auto res = accumulator.get_results();\n",
    "\n",
    "// Does this thread own some elements of C\n",
    "bool res = accumulator.is_thread_active();\n",
    "\n",
    "// Are there extra zero-elements owned by some threads\n",
    "bool res = accumulator.is_predicated();\n",
    "\n",
    "// shared_tensor_c = alpha * accumulator\n",
    "accumulator.axpby(alpha, beta, shared_tensor_c);\n",
    "```\n",
    "\n",
    "[cuBLASDx accumulator documentation](https://docs.nvidia.com/cuda/cublasdx/api/other_tensors.html#accumulator-and-register-fragment-tensors) provides a detailed description of general accumulator functionality as well as [copying functions](https://docs.nvidia.com/cuda/cublasdx/api/other_tensors.html#copying-registers-tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60406710-5c6b-4fe6-b707-c475242338d8",
   "metadata": {},
   "source": [
    "##### Data partitioning and mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83808654-7baf-4285-859a-0a4185e089d8",
   "metadata": {},
   "source": [
    "In GEMMs we are often decomposing bigger problems into smaller subproblems and offsetting pointers manually is error prone. Rich tensor types allow doing this automatically on multiple levels. \n",
    "\n",
    "`cublasdx::slice` is a slice value allowing to keep entire dimension in the resulting view.\n",
    "\n",
    "1. Dividing global memory tensor view into tiles and choosing entire row of tiles:\n",
    "```\n",
    "auto global_tile_row_a = cublasdx::get_tile_row(tensor, BLAS::a_shape, tile_row_index);\n",
    "\n",
    "// How to access:\n",
    "auto single_tile = global_tile_row_a(cublasdx::slice, cublasdx::slice, tile_col_index);\n",
    "```\n",
    "\n",
    "2. Dividing global memory tensor view into tiles and choosing entire column of tiles:\n",
    "```\n",
    "auto global_tile_col_b = cublasdx::get_tile_row(tensor, BLAS::b_shape, tile_col_index);\n",
    "\n",
    "// How to access:\n",
    "auto single_tile = global_tile_row_a(cublasdx::slice, cublasdx::slice, tile_row_index);\n",
    "```\n",
    "\n",
    "3. Dividing global memory tensor view into tiles and choosing a single one:\n",
    "```\n",
    "auto global_tile_c = cublasdx::get_tile(tensor, BLAS::b_shape, tile_row_index, tile_col_index);\n",
    "```\n",
    "\n",
    "apart from choosing tiles, it's important to map thread register result values to their appropriate locations inside the tile. This is allowed by `accumulator` APIs:\n",
    "\n",
    "```\n",
    "// If this thread takes part in GEMM\n",
    "if(accumulator.is_thread_active()) {\n",
    "   // For each element of register fragment\n",
    "   for(int i = 0; i < cublasdx::size(d_register_fragment); ++i) {\n",
    "      auto [tile_index_x, tile_index_y] = accumulator.map_fragment_index(i);\n",
    "      if((not accumulator.is_predicated()) or accumulator.is_index_in_bounds(i)) {\n",
    "         // Copy respective global element into it\n",
    "         d_register_fragment(i) = load_op(c_global_tensor(tile_index_x, tile_index_y));\n",
    "      }\n",
    "   }\n",
    "}\n",
    "```\n",
    "\n",
    "a per-thread view of a tile tensor can also be created:\n",
    "```\n",
    "auto global_c_thread_view = accumulator.partition_like_C(global_tile_c);\n",
    "```\n",
    "\n",
    "Multiple functionalities have been combined with partinioning to allow for a terse and simple code:\n",
    "\n",
    "```\n",
    "// Create empty fragment, partition tensor and load appropriate elements safely\n",
    "auto loaded_c_register_fragment = accumulator.make_partition_and_copy();\n",
    "// Partition tensor and store appropriate result elements safely\n",
    "accumulator.partition_and_store(tile_global_c);\n",
    "// Partition tensor and perform axpby on appropriate elements with results\n",
    "accumulator.axpby(alpha, beta, tile_global_c);\n",
    "// Store values from some_fragment to partitioned tensor\n",
    "accumulator.partition_and_copy(some_fragment, tile_global_c);\n",
    "// Load values from partitioned tensor to some_fragment\n",
    "accumulator.partition_and_copy(tile_global_c, some_fragment);\n",
    "```\n",
    "\n",
    "More examples concerning slicing and partitioning can be found in [pipeline documentation](https://docs.nvidia.com/cuda/cublasdx/using_pipelines.html#executing-pipelined-gemm) as well as [accumulator documentation](https://docs.nvidia.com/cuda/cublasdx/api/other_tensors.html#accumulator-and-register-fragment-tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c9b791-45e5-48e5-a107-a05e8a5b4a76",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321c458-37a1-418e-a773-80b543369823",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%writefile cpp/1d/parameters.hpp.inc\n",
    "\n",
    "    // (gemm_m, gemm_n, gemm_k, alpha, beta)\n",
    "    std::vector<tutorial::gemm_problem_t> problems = {\n",
    "        {2048, 2048, 2048, 0.9, 1.1}\n",
    "    };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f484be-8f47-44de-af8e-a0dd037dba9b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%writefile cpp/1d/cublasdx_config.hpp.inc\n",
    "    // 2. Define cuBLASDx description\n",
    "    constexpr int tile_m = 64;\n",
    "    constexpr int tile_n = 64;\n",
    "    constexpr int tile_k = 32;\n",
    "\n",
    "    constexpr int block_dim = 256;\n",
    "\n",
    "    using BLAS = decltype(cublasdx::Size<tile_m, tile_n, tile_k>() + // size of shared memory tile\n",
    "                          cublasdx::Precision<double, double, double>() + // precision of data (e.g. __nv_fp8_e5m2, __half, float)\n",
    "                          cublasdx::Type<cublasdx::type::real>() +  // choice between `real` and `complex` number type\n",
    "                          cublasdx::Function<cublasdx::function::MM>() + //BLAS operation, `MM` stands for Matrix Multiplication\n",
    "                          cublasdx::Arrangement<arr_a, arr_b, arr_c>() + //Expected global memory data ordering (row or column major)\n",
    "                          cublasdx::Block() + // Execution of operation\n",
    "                          cublasdx::BlockDim<block_dim>() + // block to be used, can be 1D, 2D or 3D\n",
    "                          cublasdx::MaxAlignment() + // will force max alignment on tensor pointers in shared memory\n",
    "                          cublasdx::SM<SM_VALUE, SM_MODIFIER_VALUE>() + // Which architecture is this code targeting\n",
    "                          cublasdx::StaticBlockDim());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6d80f-ce4a-4352-a0f2-b11bd27fe3dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%writefile cpp/1d/kernel.hpp.inc\n",
    "\n",
    "template<class BLAS, class TensorA, class TensorB, class TensorC>\n",
    "__launch_bounds__(BLAS::max_threads_per_block, 1) __global__\n",
    "    void kernel_1b_simple_dgemm_shared_cublasdx(double        alpha,\n",
    "                                                TensorA const tensor_a,\n",
    "                                                TensorB const tensor_b,\n",
    "                                                double        beta,\n",
    "                                                TensorC const tensor_c) {\n",
    "    extern __shared__ __align__(16) unsigned char smem[];\n",
    "\n",
    "    using alignment = cublasdx::alignment_of<BLAS>;\n",
    "\n",
    "    // EXERCISE --> use slicing guide to prepare shared memory tensors\n",
    "\n",
    "    auto const global_k = tutorial::size<1>(tensor_a);\n",
    "\n",
    "    // Define accumulator storage\n",
    "    // EXERCISE --> use accumulator guide to prepare the accumulator\n",
    "    \n",
    "\n",
    "    // EXERCISE --> Use partitioning guide to retrieve tile row from A, tile col from B and tile from C\n",
    "\n",
    "    // Computation loop --> dynamic, cannot unroll\n",
    "    auto const max_tile_iters = // EXERCISE\n",
    "\n",
    "    for (int tile_iter = 0; tile_iter < max_tile_iters; ++tile_iter) {\n",
    "\n",
    "        // EXERCISE --> Load current tiles into shared memory tensors, use slicing and copying guides\n",
    "        // EXERCISE --> use BLAS.execute()\n",
    "        // EXERCISE --> figure out where to sync around BLAS\n",
    "    }\n",
    "\n",
    "    // EXERCISE --> implement epilogue using either:\n",
    "    // 1. single index manual for-loop\n",
    "    // 2. retrieving global indices and using them for global store\n",
    "    // 3. separate partitioning and copying\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe7a94-11ff-421a-80c4-c6bda2d42c9b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!cmake --build build/ -t 1d_simple_dgemm_cublasdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143a06b-6935-41af-af81-7699157f2463",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!./build/1d_simple_dgemm_cublasdx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727dd04f-b8eb-4c96-9c89-e171c3fc0517",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990e5dd-9718-441a-9ca1-3a7a1c9b4898",
   "metadata": {},
   "source": [
    "We will rewrite kernel now and recompile the solution. If you want to restart your exercise make sure you rewrite kernel back and recompile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b01ff-4c6f-4d22-b50b-7e41dab73227",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%writefile cpp/1d/kernel.hpp.inc\n",
    "\n",
    "template<class BLAS, class TensorA, class TensorB, class TensorC>\n",
    "__launch_bounds__(BLAS::max_threads_per_block, 1) __global__\n",
    "    void kernel_1c_dgemm_shared_cublasdx(double        alpha,\n",
    "                                                TensorA const tensor_a,\n",
    "                                                TensorB const tensor_b,\n",
    "                                                double        beta,\n",
    "                                                TensorC const tensor_c) {\n",
    "    extern __shared__ __align__(16) unsigned char smem[];\n",
    "\n",
    "    using alignment = cublasdx::alignment_of<BLAS>;\n",
    "\n",
    "    auto [smem_tensor_a, smem_tensor_b] =\n",
    "        cublasdx::shared_memory::slice<double, double>(smem,\n",
    "                                                       cublasdx::alignment_of_v_a<BLAS>,\n",
    "                                                       BLAS::suggest_layout_smem_a(),\n",
    "                                                       cublasdx::alignment_of_v_b<BLAS>,\n",
    "                                                       BLAS::suggest_layout_smem_b());\n",
    "\n",
    "    // Assert that for A: mxk and B: kxn both Ks are the same size\n",
    "    auto const global_k = tutorial::size<1>(tensor_a);\n",
    "\n",
    "    // Define accumulator storage\n",
    "    auto accumulator = BLAS::suggest_accumulator();\n",
    "\n",
    "    auto global_tile_row_a = cublasdx::get_tile_row(tensor_a, BLAS::a_shape, blockIdx.x);\n",
    "    auto global_tile_col_b = cublasdx::get_tile_col(tensor_b, BLAS::b_shape, blockIdx.y);\n",
    "\n",
    "    auto global_tile_c   = cublasdx::get_tile(tensor_c, BLAS::c_shape, blockIdx.x, blockIdx.y);\n",
    "    auto global_tile_out = cublasdx::get_tile(tensor_c, BLAS::c_shape, blockIdx.x, blockIdx.y);\n",
    "\n",
    "    // Computation loop --> dynamic, cannot unroll\n",
    "    for (int tile_iter = 0; tile_iter < (global_k / cublasdx::size_of_v_k<BLAS>); ++tile_iter) {\n",
    "\n",
    "        // Load current tile into shared memory\n",
    "        auto current_global_tile_a = global_tile_row_a(cublasdx::slice, cublasdx::slice, tile_iter);\n",
    "        auto current_global_tile_b = global_tile_col_b(cublasdx::slice, cublasdx::slice, tile_iter);\n",
    "\n",
    "        cublasdx::copy<BLAS, alignment::a>(current_global_tile_a, smem_tensor_a);\n",
    "        cublasdx::copy<BLAS, alignment::b>(current_global_tile_b, smem_tensor_b);\n",
    "        cublasdx::copy_wait();\n",
    "\n",
    "        BLAS().execute(smem_tensor_a, smem_tensor_b, accumulator);\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    auto d_fragment = accumulator.make_partition_and_copy(global_tile_c);\n",
    "    cublasdx::axpby(alpha, accumulator.get_results(), beta, d_fragment);\n",
    "    accumulator.partition_and_copy(d_fragment, global_tile_out);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49704bd-fcc6-4f14-b423-a06641a3ed34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!cmake --build build/ -t 1d_simple_dgemm_cublasdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0385ded-d0d7-48ad-9663-8503ac5dfad6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!./build/1d_simple_dgemm_cublasdx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71298be2-988c-4122-847f-1064e4f1f40d",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13316b-d151-4f7b-a104-eb8f8d73ed59",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# The problems that we will benchmark and conduct accuracy tests on the tuple should be formed as:\n",
    "# (GEMM_M, GEMM_N, GEMM_K, ALPHA, BETA)\n",
    "problems = [\n",
    "  (2048, 2048, 2048, 0.9, 1.1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78f0da-a765-4968-a6fb-9bd41242204f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def choose_kernel_params_2_4(m, n, k, alpha, beta):\n",
    "    tile_m = 64\n",
    "    tile_n = 64\n",
    "    tile_k = 32\n",
    "    \n",
    "    block_size = 256\n",
    "    \n",
    "    return Matmul(\n",
    "        size=(tile_m, tile_n, tile_k),\n",
    "        precision=(np.float64, np.float64, np.float64),\n",
    "        data_type=\"real\",\n",
    "        arrangement=(\"row_major\", \"col_major\", \"col_major\"), # Do not change\n",
    "        execution=\"Block\",\n",
    "        block_size=block_size,\n",
    "        alignment=MAX_ALIGNMENT,\n",
    "        static_block_dim=True\n",
    "    )\n",
    "\n",
    "def get_shared_memory_size_2_4(BLAS):\n",
    "    smem_calc = SharedStorageCalc()\n",
    "    smem_calc.add(BLAS.alignment.a, np.dtype(BLAS.precision[0]).itemsize, BLAS.suggest_layout_smem_a())\n",
    "    smem_calc.add(BLAS.alignment.b, np.dtype(BLAS.precision[1]).itemsize, BLAS.suggest_layout_smem_b())\n",
    "    return smem_calc.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b518d-2ecf-4991-92bb-00ec34ede13c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_dgemm_kernel_2_4(BLAS):\n",
    "\n",
    "    assert BLAS.a_value_type == BLAS.b_value_type, \"Invalid BLAS configuration\"\n",
    "\n",
    "    c_size = BLAS.suggest_layout_rmem_c().cosize\n",
    "\n",
    "    tile_m, tile_n = BLAS.c_dim\n",
    "    tile_k = BLAS.a_dim[1]\n",
    "    alignment_a, alignment_b, alignment_c = BLAS.alignment\n",
    "    \n",
    "    @cuda.jit(launch_bounds=(BLAS.block_size, 1))\n",
    "    def dgemm_kernel(alpha, tensor_a, tensor_b, beta, tensor_c):\n",
    "        m, n = tensor_c.shape\n",
    "        _, k = tensor_a.shape\n",
    "\n",
    "        lda = max(tensor_a.strides) // tensor_a.itemsize\n",
    "        ldb = max(tensor_b.strides) // tensor_b.itemsize\n",
    "        ldc = max(tensor_c.strides) // tensor_c.itemsize\n",
    "\n",
    "        block_m = cuda.blockIdx.x\n",
    "        block_n = cuda.blockIdx.y\n",
    "\n",
    "        smem = cuda.shared.array(shape=(0,), dtype=BLAS.a_value_type, alignment=16)\n",
    "        smem_a_buff, smem = smem[0:BLAS.a_size], smem[BLAS.a_size:]\n",
    "        smem_b_buff, smem = smem[0:BLAS.b_size], smem[BLAS.b_size:]\n",
    "\n",
    "        block_start_m = block_m * tile_m\n",
    "        block_end_m = (block_m + 1) * tile_m\n",
    "\n",
    "        block_start_n = block_n * tile_n\n",
    "        block_end_n = (block_n + 1) * tile_n\n",
    "\n",
    "        if block_start_m >= m or block_start_n >= n:\n",
    "            return\n",
    "\n",
    "        a_view = tensor_a[block_start_m : block_end_m, :]\n",
    "        b_view = tensor_b[:, block_start_n : block_end_n]\n",
    "        c_view = tensor_c[\n",
    "            block_start_m : block_end_m,\n",
    "            block_start_n : block_end_n,\n",
    "        ]\n",
    "\n",
    "        smem_a = make_tensor(smem_a_buff, BLAS.suggest_layout_smem_a())\n",
    "        smem_b = make_tensor(smem_b_buff, BLAS.suggest_layout_smem_b())\n",
    "        gmem_c = make_tensor(c_view, BLAS.get_layout_gmem_c(ldc))\n",
    "\n",
    "        accumulator = BLAS.suggest_accumulator()\n",
    "\n",
    "        stages = k // tile_k\n",
    "\n",
    "        for stage in range(0, stages):\n",
    "            stage_start_k = stage * tile_k\n",
    "            stage_end_k = (stage + 1) * tile_k\n",
    "            \n",
    "            stage_a = a_view[:, stage_start_k : stage_end_k]\n",
    "            stage_b = b_view[stage_start_k : stage_end_k, :]\n",
    "\n",
    "            gmem_a = make_tensor(stage_a, BLAS.get_layout_gmem_a(lda))\n",
    "            gmem_b = make_tensor(stage_b, BLAS.get_layout_gmem_b(ldb))\n",
    "\n",
    "            # EXERCISE --> Load current tiles into shared memory tensors, use slicing and copying guides\n",
    "            #              Use copy and copy_wait instead of cublasdx::copy and cublasdx::copy_wait\n",
    "            #              Alignment is directly passed to copy\n",
    "            # EXERCISE --> use BLAS.execute()\n",
    "            # EXERCISE --> figure out where to sync around BLAS\n",
    "\n",
    "        # EXERCISE --> implement epilogue using either:\n",
    "        # 1. single index manual for-loop\n",
    "        # 2. retrieving global indices and using them for global store\n",
    "        # 3. separate partitioning and copying\n",
    "\n",
    "    return dgemm_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474095a0-0efd-4617-a14a-037ac07330df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "benchmark_dgemm_2_4(problems, get_dgemm_kernel_2_4, choose_kernel_params_2_4, get_shared_memory_size_2_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29e6fb-5353-44aa-ba54-f322ddbd47c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e755d6-09a6-48d9-8b1b-cfd7aaad65db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_dgemm_kernel_2_4_solution(BLAS):\n",
    "\n",
    "    assert BLAS.a_value_type == BLAS.b_value_type, \"Invalid BLAS configuration\"\n",
    "\n",
    "    c_size = BLAS.suggest_layout_rmem_c().cosize\n",
    "\n",
    "    tile_m, tile_n = BLAS.c_dim\n",
    "    tile_k = BLAS.a_dim[1]\n",
    "    alignment_a, alignment_b, alignment_c = BLAS.alignment\n",
    "    \n",
    "    @cuda.jit(launch_bounds=(BLAS.block_size, 1))\n",
    "    def dgemm_kernel(alpha, tensor_a, tensor_b, beta, tensor_c):\n",
    "        m, n = tensor_c.shape\n",
    "        _, k = tensor_a.shape\n",
    "\n",
    "        lda = max(tensor_a.strides) // tensor_a.itemsize\n",
    "        ldb = max(tensor_b.strides) // tensor_b.itemsize\n",
    "        ldc = max(tensor_c.strides) // tensor_c.itemsize\n",
    "\n",
    "        block_m = cuda.blockIdx.x\n",
    "        block_n = cuda.blockIdx.y\n",
    "\n",
    "        smem = cuda.shared.array(shape=(0,), dtype=BLAS.a_value_type, alignment=16)\n",
    "        smem_a_buff, smem = smem[0:BLAS.a_size], smem[BLAS.a_size:]\n",
    "        smem_b_buff, smem = smem[0:BLAS.b_size], smem[BLAS.b_size:]\n",
    "\n",
    "        block_start_m = block_m * tile_m\n",
    "        block_end_m = (block_m + 1) * tile_m\n",
    "\n",
    "        block_start_n = block_n * tile_n\n",
    "        block_end_n = (block_n + 1) * tile_n\n",
    "\n",
    "        if block_start_m >= m or block_start_n >= n:\n",
    "            return\n",
    "\n",
    "        a_view = tensor_a[block_start_m : block_end_m, :]\n",
    "        b_view = tensor_b[:, block_start_n : block_end_n]\n",
    "        c_view = tensor_c[\n",
    "            block_start_m : block_end_m,\n",
    "            block_start_n : block_end_n,\n",
    "        ]\n",
    "\n",
    "        smem_a = make_tensor(smem_a_buff, BLAS.suggest_layout_smem_a())\n",
    "        smem_b = make_tensor(smem_b_buff, BLAS.suggest_layout_smem_b())\n",
    "        gmem_c = make_tensor(c_view, BLAS.get_layout_gmem_c(ldc))\n",
    "\n",
    "        accumulator = BLAS.suggest_accumulator()\n",
    "\n",
    "        stages = k // tile_k\n",
    "\n",
    "        for stage in range(0, stages):\n",
    "            stage_start_k = stage * tile_k\n",
    "            stage_end_k = (stage + 1) * tile_k\n",
    "            \n",
    "            stage_a = a_view[:, stage_start_k : stage_end_k]\n",
    "            stage_b = b_view[stage_start_k : stage_end_k, :]\n",
    "\n",
    "            gmem_a = make_tensor(stage_a, BLAS.get_layout_gmem_a(lda))\n",
    "            gmem_b = make_tensor(stage_b, BLAS.get_layout_gmem_b(ldb))\n",
    "\n",
    "            copy(gmem_a, smem_a, alignment=alignment_a)\n",
    "            copy(gmem_b, smem_b, alignment=alignment_b)\n",
    "            copy_wait()\n",
    "\n",
    "            BLAS.execute(smem_a, smem_b, accumulator)\n",
    "\n",
    "            cuda.syncthreads()\n",
    "\n",
    "        d_fragment = accumulator.make_partition_and_copy(gmem_c)\n",
    "        axpby(alpha, accumulator.get_results(), beta, d_fragment)\n",
    "        accumulator.partition_and_copy(d_fragment, gmem_c)\n",
    "\n",
    "    return dgemm_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935abce0-41af-4ec0-8f31-15f403a69a6f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "benchmark_dgemm_2_4(problems, get_dgemm_kernel_2_4_solution, choose_kernel_params_2_4, get_shared_memory_size_2_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3e1ee-454c-4a5b-8544-7ba72baa8981",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook approaches to using cuBLASDx in device code were presented: the tile approach and the pipelined approach demonstrating how to efficiently use the library"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
