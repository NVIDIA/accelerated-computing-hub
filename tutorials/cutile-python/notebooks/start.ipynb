{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b692e38e",
   "metadata": {},
   "source": [
    "## CUDA Tile Tutorial\n",
    "\n",
    "In this tutorial, you'll learn the CUDA Tile programming model and how to use cuTile Python, cuTile C++, and Tile IR.\n",
    "\n",
    "CUDA Tile is an array-oriented parallel programming model. You divide your inputs into local arrays called tiles that are processed concurrently by groups of execution resources called blocks. You write tile kernels that are executed once per block. Array operations within a kernel are parallelized across the block. The framework handles parallelization, synchronization, and data movement behind the scenes. Architecture-specific details are abstracted away - you express your algorithm once in a high-level way, and the system lowers it to the right implementation for any NVIDIA GPU architecture.\n",
    "\n",
    "### Notebooks\n",
    "\n",
    "| # | Topic | Solution | Technologies | \n",
    "|---|-------|----------|--------------|\n",
    "| 01 | [cuTile Python Intro](01__cutile_python_intro__vector_add.ipynb) | - | cuTile Python |\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
