{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b6145d",
   "metadata": {},
   "source": [
    "## Exercise - CCCL - Customizing Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c05bf-5615-4b0b-8294-d66795f1f155",
   "metadata": {},
   "source": [
    "### What is `cuda-cccl`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98385a37-45b5-4b42-8a30-22112d2292df",
   "metadata": {},
   "source": [
    "The [CUDA Core Compute Libraries (CCCL)](https://nvidia.github.io/cccl/python/) provide high-quality, high-performance abstractions for CUDA development in Python. The `cuda-cccl` Python package is composed of two indepdendent subpackages:\n",
    "\n",
    "* `cuda.compute` is a **parallel algorithms library** containing algorithms like `reduce`, `transform`, `scan` and `sort`. These  can be combined to implement more complex algorithms, while delivering the performance of hand-optimized CUDA kernels, portable across different GPU architectures. They are general-purpose and **designed to be used with CuPy, PyTorch and other array/tensor frameworks.**.\n",
    "\n",
    "* `cuda.coop` is a lower-level library containing **cooperative algorithms meant to be used within (numba) CUDA kernels**.  Examples include _block-wide reduction_ and _warp-wide scan_, providing numba CUDA kernel developers with building blocks to create speed-of-light, custom kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79acd5e0-640c-4b61-8528-f57904d0ca95",
   "metadata": {},
   "source": [
    "### When to use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f05b64-f709-41de-8899-add8b4c3dcb3",
   "metadata": {},
   "source": [
    "`cccl` provides a level of abstraction in between tensor libraries and raw CUDA kernels.\n",
    "\n",
    "- If you want to implement custom functionality that can not easily and efficiently be expressed using PyTorch/CuPy operations, you can reach for `cuda.compute` before resorting to writing CUDA kernels.\n",
    "- If you _do_ need to write a kernel, you can often make use of the block-level and warp-level primitives offered by `cuda.coop` to write your kernel much more efficiently and concisely.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e2b1188-ce5e-4a10-84a1-ed6ace92922f",
   "metadata": {},
   "source": [
    "<img src=\"images/cccl-spectrum.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71178c05",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78704b-cc16-4f3a-8a76-a1ecb4acd8e3",
   "metadata": {},
   "source": [
    "The command below installs `cuda-cccl` along with pieces of the CUDA toolkit it needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c21a66-dcf9-44f5-8262-78aa77754523",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "pip install \"cuda-cccl[test-cu12]\" matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10355920-9bfc-4788-bfe7-ab99440a6d98",
   "metadata": {},
   "source": [
    "The `[test-cu12]` extras installs CuPy, which we will use in our examples. It is not strictly a dependency of `cuda-cccl` - you can use any array-like object (like PyTorch tensors) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5a026-db41-4079-808e-b8c3c7196c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy  as cp\n",
    "import cuda.compute as comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01908d54",
   "metadata": {},
   "source": [
    "## Hello `cccl`: Simple Reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d468957-1411-4cae-a050-a75692452cc2",
   "metadata": {},
   "source": [
    "A **reduction** takes many values and combines them into a single result using a binary operation.\n",
    "\n",
    "As a simple example, consider a sequence of values like $[2, 3, 5, 1, 7, 6, 8, 4]$. The *sum* of the values of that sequence is a reduction using _addition_ as the binary operation: $(2 + 3 + 5 + 1 + 7 + 6 + 8 + 4) = 36$. Similarly, the *maximum value* can be obtained by performing a reduction using `max(a, b)` as the binary operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83065c06-aeab-4d26-9d18-69edb8462c2d",
   "metadata": {},
   "source": [
    "A reduction can be computed in parallel. Typically this is done using a \"tree\" reduction where elements are combined in pairs across multiple levels, resembling the structure of a binary tree. At each level, the number of elements is halved as partial results are computed in parallel. This continues until a single final result is obtained at the root of the tree.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ee/Binomial_tree.gif\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d0feb1-7ed0-42dc-bb83-8b017d89a2a6",
   "metadata": {},
   "source": [
    "If you know some CUDA, you can quite easily write a kernel to implement this kind of parallel reduction. However, optimizing it for the specific CUDA architecture of your device, and generalizing for different data types and sizes can be difficult.\n",
    "\n",
    "This is where `cuda.compute` comes in. It provides optimized implementations of algorithms like reduction that give the best possible performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cb8fb8-8e35-4179-8a66-2c3b5e6077ae",
   "metadata": {},
   "source": [
    "### Using `reduce_into()` to compute the sum of a sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f6367-d7f9-4030-bc57-4b8920299b47",
   "metadata": {},
   "source": [
    "`cuda.compute` provides a `reduce_into()` function to compute general reductions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using `reduce_into()` to compute the sum of a sequence\n",
    "\"\"\"\n",
    "\n",
    "# Prepare the inputs and outputs.\n",
    "d_input = cp.array([2, 3, 5, 1, 7, 6, 8, 4], dtype=np.int32)  # input sequence, a CuPy (device) array\n",
    "d_output = cp.empty(1, dtype=np.int32)  # array which will hold the result, a CuPy (device) array of size 1\n",
    "h_init = np.array([0], dtype=np.int32)  # initial value of the reduction, a NumPy (host) array of size 1\n",
    "\n",
    "# Perform the reduction.\n",
    "comp.reduce_into(d_input, d_output, comp.OpKind.PLUS, len(d_input), h_init)\n",
    "\n",
    "print(d_input)\n",
    "# Verify the result.\n",
    "expected_output = 36\n",
    "assert (d_output == expected_output).all()\n",
    "result = d_output[0]\n",
    "print(f\"Sum reduction result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00121b-bfb1-4b37-9651-230386d9c256",
   "metadata": {},
   "source": [
    "### Exercise: computing the minimum value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e9ffc-89cd-4859-97ea-93abbb8b3f4b",
   "metadata": {},
   "source": [
    "`reduce_into()` can be used to compute other reductions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241706a-b152-41b3-bba7-d281c9e43675",
   "metadata": {},
   "source": [
    "Similar to the examples above, below is an incomplete code snippet for computing the minimum value of a sequence. Complete the section between the comments `begin TODO` and `end TODO` to use `reduce_into()` to compute the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb3daf-1a82-4af3-965e-b0d4be56b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using `reduce_into()` to compute the minimum value of a sequence\n",
    "\"\"\"\n",
    "\n",
    "d_input = cp.array([-2, 3, 5, 1, 7, -6, 8, -4], dtype=np.int32)\n",
    "d_output = cp.empty(1, dtype=np.int32)\n",
    "\n",
    "# begin TODO\n",
    "\n",
    "\n",
    "# end TODO\n",
    "\n",
    "expected_output = -6\n",
    "assert (d_output == expected_output).all()\n",
    "result = d_output[0]\n",
    "print(f\"Min reduction result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9839aacd-7256-484c-8205-e48068f3217b",
   "metadata": {},
   "source": [
    "## Custom Reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74da96-38ff-434a-87fa-bba49e37bf5a",
   "metadata": {},
   "source": [
    "### Example: sum of even values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0395884-0786-4b75-9442-046609041439",
   "metadata": {},
   "source": [
    "At this point, you might be thinking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ef69c-07d1-4ca7-af22-89f105d7c532",
   "metadata": {},
   "source": [
    "> **_Umm, can't I just use CuPy or PyTorch to compute sum or max?_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42b854-3576-4cf8-9880-f1aed514a10b",
   "metadata": {},
   "source": [
    "Of course, given a CuPy array, it's trivial to do simple reductions like `sum`, `min` or `max`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61248d58-dcb7-4bf2-9b8b-9669ea2cd3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_input = cp.array([-2, 3, 5, 1, 7, -6, 8, -4], dtype=np.int32)\n",
    "\n",
    "print(f\"Sum using cp.sum: {cp.sum(d_input)}\")\n",
    "print(f\"Max value using cp.max: {cp.max(d_input)}\")\n",
    "print(f\"Min value using cp.min: {cp.min(d_input)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96e0729-87d3-4423-ac13-28c5d34e3786",
   "metadata": {},
   "source": [
    "The benefit of `cuda-cccl` is more apparent when you want to do custom operations. For example, rather than just computing a straightforward `sum`, let's say we wanted to compute the sum of **only even values** in a sequence. Naively, here's how to do that with CuPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b31ba-ce77-4fcd-9750-5efa0c13c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_input = cp.array([2, 3, 5, 1, 7, 6, 8, 4], dtype=np.int32)\n",
    "result = (d_input[d_input % 2 == 0]).sum()\n",
    "print(f\"Sum of even values with CuPy: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd15a3-f616-4337-a7d7-c81c999a73f7",
   "metadata": {},
   "source": [
    "Now, let's do the same thing with `parallel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03947ed8-c6f9-49ae-b382-db7a0ef14931",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using `reduce_into()` with a custom binary operation\n",
    "\"\"\"\n",
    "\n",
    "# Define a custom binary operation for the reduction.\n",
    "def sum_even_op(a, b):\n",
    "    return (a if a % 2 == 0 else 0) + (b if b % 2 == 0 else 0)\n",
    "\n",
    "d_input = cp.array([2, 3, 5, 1, 7, 6, 8, 4], dtype=np.int32)\n",
    "d_output = cp.empty(1, dtype=np.int32)\n",
    "h_init = np.array([0], dtype=np.int32)\n",
    "\n",
    "# Call `reduce_into()` passing the function above for the binary operation:\n",
    "comp.reduce_into(d_input, d_output, sum_even_op, len(d_input), h_init)\n",
    "result = d_output.get()[0]\n",
    "print(f\"Sum of even values with `cuda.compute`: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9205d-7668-4a72-a01d-f57e2d1a3bb1",
   "metadata": {},
   "source": [
    "We got the same result using `cuda.compute`, but we had to write significantly more code. Is it worth it? Below is a small benchmarking script comparing timings for a range of input sizes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afe1e9-c870-43e0-b884-2c7f93581869",
   "metadata": {},
   "source": [
    "### Comparing custom reduction performance with naive CuPy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a1867-3a21-4f09-af97-f02d0a562d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare the performance of the `parallel` implementation with a naive CuPy implementation\n",
    "\"\"\"\n",
    "\n",
    "import timeit\n",
    "\n",
    "def evens_sum_cupy(d_input, d_output, h_init):\n",
    "    # ignore h_init\n",
    "    cp.sum(d_input[d_input % 2 == 0], out=d_output[0])\n",
    "\n",
    "def evens_sum_cccl(d_input, d_output, h_init):\n",
    "    # note, using `op` as the binary operation, rather than `OpKind.PLUS`:\n",
    "    comp..reduce_into(d_input, d_output, sum_even_op, len(d_input), h_init)\n",
    "\n",
    "def time_gpu_func(f, *args, **kwargs):\n",
    "    cp.cuda.Device().synchronize()\n",
    "    t1 = timeit.default_timer()\n",
    "    n = 1_000\n",
    "    for i in range(n):\n",
    "        f(*args, **kwargs)\n",
    "        cp.cuda.Device().synchronize()\n",
    "    t2 = timeit.default_timer()\n",
    "    return t2 - t1\n",
    "\n",
    "sizes = [10_000, 100_000, 1_000_000, 10_000_000, 100_000_000]\n",
    "cccl_times = []\n",
    "cp_times = []\n",
    "\n",
    "for n in sizes:\n",
    "    d_input = cp.random.randint(low=0, high=10, size=n, dtype=np.int32)\n",
    "    d_out = cp.empty(1, dtype=np.int32)\n",
    "    h_init = np.array([0], dtype=np.int32)\n",
    "\n",
    "    cccl_times.append(time_gpu_func(evens_sum_cccl, d_input, d_out, h_init))\n",
    "    cp_times.append(time_gpu_func(evens_sum_cupy, d_input, d_out, h_init))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.loglog(sizes, cccl_times, marker='o', label='cuda.ccl')\n",
    "plt.loglog(sizes, cp_times, marker='s', label='CuPy')\n",
    "\n",
    "# Annotate each cuda.ccl point with speedup vs CuPy\n",
    "for x, t_cccl, t_cp in zip(sizes, cccl_times, cp_times):\n",
    "    speedup = t_cp / t_cccl\n",
    "    label = f\"{speedup:.1f}x faster\"\n",
    "    plt.annotate(label,\n",
    "                 (x, t_cccl),\n",
    "                 textcoords=\"offset points\",\n",
    "                 xytext=(5, -10),  # offset position\n",
    "                 ha='left',\n",
    "                 fontsize=9,\n",
    "                 color='green')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Timing Comparison for evens_sum.')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a0d085-75ab-4836-afb6-72ec1abd1d6a",
   "metadata": {},
   "source": [
    "We see that using `cuda.compute` is much faster than our naive CuPy approach. This is because:\n",
    "\n",
    "* Operator fusion: the CuPy operation `x[x % 2 == 0]).sum()` is actually 4 separate operations (and at least 4 separate CUDA kernel invocations). With `cuda.compute`, we have a single call to `reduce_into()` that does all the computation.\n",
    "* No intermediate memory allocations.\n",
    "* Lesser Python overhead: `cuda.compute` is a lower-level library. You don't have to jump through multiple layers of Python before invoking device code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a987e11b-777b-4da3-81f8-5808c0dd8836",
   "metadata": {},
   "source": [
    "## Scan Operations\n",
    "\n",
    "### What is a Scan Operation?\n",
    "\n",
    "A **scan** (also called prefix sum) computes a running total of elements. For each position, it shows the cumulative result up to that point.\n",
    "\n",
    "**Two types of scans:**\n",
    "* **Inclusive scan**: Includes the current element in the sum\n",
    "* **Exclusive scan**: Excludes the current element (shifts results)\n",
    "\n",
    "**Visual example:**\n",
    "\n",
    "```\n",
    "Input:     [3, 1, 4, 1, 5]\n",
    "Inclusive: [3, 4, 8, 9, 14]  (3, 3+1, 3+1+4, 3+1+4+1, 3+1+4+1+5)\n",
    "Exclusive: [0, 3, 4, 8, 9]   (0, 3, 3+1, 3+1+4, 3+1+4+1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca0df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_input = cp.array([3, 1, 4, 1, 5, 9, 2, 6], dtype=np.int32)\n",
    "d_inclusive = cp.empty_like(d_input)\n",
    "d_exclusive = cp.empty_like(d_input)\n",
    "h_init = np.array([0], dtype=np.int32)\n",
    "\n",
    "def add_op(a, b):\n",
    "    return a + b\n",
    "\n",
    "comp.inclusive_scan(d_input, d_inclusive, add_op, h_init, len(d_input))\n",
    "comp.exclusive_scan(d_input, d_exclusive, add_op, h_init, len(d_input))\n",
    "\n",
    "print(f\"Input:           {d_input.get()}\")\n",
    "print(f\"Inclusive scan:  {d_inclusive.get()}\")\n",
    "print(f\"Exclusive scan:  {d_exclusive.get()}\")\n",
    "\n",
    "# Verify with NumPy\n",
    "np_inclusive = np.cumsum(d_input.get())\n",
    "np_exclusive = np.concatenate([[0], np_cumsum[:-1]])\n",
    "np.testing.assert_allclose(d_inclusive.get(), np_inclusive)\n",
    "np.testing.assert_allclose(d_exclusive.get(), np_exclusive)\n",
    "print(f\"NumPy inclusive:    {np_result}\")\n",
    "print(f\"NumPy exclusive:    {np_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4b010",
   "metadata": {},
   "source": [
    "### Maximum Scan Example\n",
    "\n",
    "Scans aren't limited to addition. Here's an example using maximum operation to find running maximum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running maximum example\n",
    "d_input = cp.array([3, 7, 2, 9, 1, 8, 4, 6], dtype=np.int32)\n",
    "d_output = cp.empty_like(d_input)\n",
    "\n",
    "def max_op(a, b):\n",
    "    return a if a > b else b\n",
    "\n",
    "# Start with a very small value\n",
    "h_init = np.array([-999999], dtype=np.int32)\n",
    "\n",
    "# Perform inclusive scan with max operation\n",
    "comp.inclusive_scan(d_input, d_output, max_op, h_init, len(d_input))\n",
    "\n",
    "print(f\"Input:       {d_input.get()}\")\n",
    "print(f\"Running max: {d_output.get()}\")\n",
    "\n",
    "# Verify with NumPy\n",
    "np_running_max = np.maximum.accumulate(d_input.get())\n",
    "print(f\"NumPy max:   {np_running_max}\")\n",
    "print(f\"Match:       {np.array_equal(d_output.get(), np_running_max)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37c3f0-b7cb-45e6-83bf-2bbbeeab74b2",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa94ff",
   "metadata": {},
   "source": [
    "### Merge Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4043e-6dec-44f4-ab6b-15f24d0c3cfb",
   "metadata": {},
   "source": [
    "The `merge_sort` function can be used to perform key-value sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a893a898-e74b-4ea2-b69a-4432a342fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input arrays.\n",
    "d_in_keys = cp.asarray([-5, 0, 2, -3, 2, -3, 0, -3, -5, 2], dtype=\"int32\")\n",
    "d_in_values = cp.asarray(\n",
    "    [-3.2, 2.2, 1.9, 4.0, -3.9, 2.7, 0, 8.3 - 1, 2.9, 5.4], dtype=\"float32\"\n",
    ")\n",
    "\n",
    "# Perform the merge sort.\n",
    "comp.merge_sort(\n",
    "    d_in_keys,\n",
    "    d_in_values,\n",
    "    d_in_keys,  # reuse input array to store output\n",
    "    d_in_values,  # reuse input array to store output\n",
    "    comp.OpKind.LESS,\n",
    "    d_in_keys.size,\n",
    ")\n",
    "\n",
    "print(f\"Sorted keys: {d_in_keys.get()}\")\n",
    "print(f\"Sorted values: {d_in_values.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dafff6-7a05-43d4-bedb-1c6cc0027573",
   "metadata": {},
   "source": [
    "If you just want to sort keys (with no corresponding values), just pass `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90bc0c-810e-46d9-9ef9-9f3adaeecd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input and output arrays.\n",
    "d_in_keys = cp.asarray([-5, 0, 2, -3, 2, -3, 0, -3, -5, 2], dtype=\"int32\")\n",
    "\n",
    "print(d_in_keys)\n",
    "\n",
    "# Perform the merge sort.\n",
    "comp.merge_sort(\n",
    "    d_in_keys,\n",
    "    None,  # don't specify a values array\n",
    "    d_in_keys,  # reuse input array to store output\n",
    "    None,  # don't specify a values array\n",
    "    comp.OpKind.LESS,\n",
    "    d_in_keys.size,\n",
    ")\n",
    "\n",
    "print(f\"Sorted keys: {d_in_keys.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ffd71-90d1-461f-843b-96aca2990206",
   "metadata": {},
   "source": [
    "#### Exercise - sort by the last digit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b91fe2a-169e-4ee6-8408-ee87cf49b481",
   "metadata": {},
   "source": [
    "In this excercise, you'll use `merge_sort` with a custom comparator function to sort elements by the last digit.\n",
    "For example, $[29, 9, 136, 1001, 72, 24, 32, 1] \\rightarrow [1001, 1, 72, 32, 24, 136, 29, 9]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e95ff4-013a-4ca9-bdf4-5e122ba0f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input and output arrays.\n",
    "d_in_keys = cp.asarray([29, 9, 136, 1001, 72, 24, 32, 1], dtype=\"int32\")\n",
    "\n",
    "# define the custom comparator.\n",
    "def comparison_op(lhs, rhs):\n",
    "    # begin TODO\n",
    "\n",
    "    # end TODO\n",
    "\n",
    "# Perform the merge sort.\n",
    "comp.merge_sort(\n",
    "    # begin TODO\n",
    "\n",
    "    # end TODO\n",
    ")\n",
    "\n",
    "print(f\"Result: {d_in_keys}\")\n",
    "expected = np.asarray([1001, 1, 72, 32, 24, 136, 29, 9], dtype=np.int32)\n",
    "assert (d_in_keys.get() == expected).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b45660-9d80-43a9-9b7b-22eaeed7df4f",
   "metadata": {},
   "source": [
    "### Radix Sort\n",
    "\n",
    "The `radix_sort` function provides fast sorting for numeric types using the radix sort algorithm. Unlike merge sort, radix sort doesn't use comparisons but instead processes the bits/digits of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic radix sort example (ascending order)\n",
    "d_input = cp.array([64, 34, 25, 12, 22, 11, 90, 5, 77, 30], dtype=np.int32)\n",
    "d_output = cp.empty_like(d_input)\n",
    "\n",
    "print(f\"Input:  {d_input.get()}\")\n",
    "\n",
    "# Sort in ascending order\n",
    "comp.radix_sort(\n",
    "    d_input,                           # Input keys\n",
    "    d_output,                          # Output keys\n",
    "    None,                              # Input values (none for keys-only sort)\n",
    "    None,                              # Output values (none)\n",
    "    comp.SortOrder.ASCENDING,          # Sort order\n",
    "    len(d_input)                       # Number of elements\n",
    ")\n",
    "\n",
    "print(f\"Sorted: {d_output.get()}\")\n",
    "\n",
    "# Verify sorting\n",
    "is_sorted = all(d_output.get()[i] <= d_output.get()[i+1] for i in range(len(d_output.get())-1))\n",
    "print(f\"Properly sorted: {is_sorted}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descending order sort\n",
    "d_input = cp.array([3, 1, 4, 1, 5, 9, 2, 6, 5, 3], dtype=np.int32)\n",
    "d_output = cp.empty_like(d_input)\n",
    "\n",
    "comp.radix_sort(\n",
    "    d_input, d_output, None, None,\n",
    "    comp.SortOrder.DESCENDING,    # Sort in reverse order\n",
    "    len(d_input)\n",
    ")\n",
    "\n",
    "print(f\"Input:            {d_input.get()}\")\n",
    "print(f\"Descending sort:  {d_output.get()}\")\n",
    "\n",
    "# Verify descending order\n",
    "is_descending = all(d_output.get()[i] >= d_output.get()[i+1] for i in range(len(d_output.get())-1))\n",
    "print(f\"Properly descending: {is_descending}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key-value sorting: sort scores while keeping student IDs aligned\n",
    "scores = [85, 92, 78, 96, 88, 71, 94]\n",
    "student_ids = [101, 102, 103, 104, 105, 106, 107]\n",
    "\n",
    "d_keys = cp.array(scores, dtype=np.int32)\n",
    "d_values = cp.array(student_ids, dtype=np.int32)\n",
    "d_keys_out = cp.empty_like(d_keys)\n",
    "d_values_out = cp.empty_like(d_values)\n",
    "\n",
    "print(\"Before sorting:\")\n",
    "for score, student_id in zip(scores, student_ids):\n",
    "    print(f\"  Student {student_id}: {score}\")\n",
    "\n",
    "# Sort by scores (highest first), keep student IDs aligned\n",
    "comp.radix_sort(\n",
    "    d_keys, d_keys_out,                # Input/output keys (scores)\n",
    "    d_values, d_values_out,            # Input/output values (student IDs)\n",
    "    comp.SortOrder.DESCENDING,    # Highest scores first\n",
    "    len(d_keys)\n",
    ")\n",
    "\n",
    "sorted_scores = d_keys_out.get()\n",
    "sorted_ids = d_values_out.get()\n",
    "\n",
    "print(\"\\nAfter sorting (by score, highest first):\")\n",
    "for score, student_id in zip(sorted_scores, sorted_ids):\n",
    "    print(f\"  Student {student_id}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423fd14a",
   "metadata": {},
   "source": [
    "## Transforming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c001e63-54ab-4943-83be-7503fea3ae0a",
   "metadata": {},
   "source": [
    "#### Unary transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55614c6-6865-4bb8-941d-ae73290c7a91",
   "metadata": {},
   "source": [
    "The `unary_transform` function applies a user-provided unary operation to each element of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45d79d-87a3-47c2-9681-8810535d3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input and output arrays.\n",
    "d_in = cp.asarray([1, 2, 3, 4, 5], dtype=np.int32)\n",
    "d_out = cp.empty_like(d_in)\n",
    "\n",
    "def double_op(a):\n",
    "    return a * 2\n",
    "\n",
    "# Perform the unary transform.\n",
    "comp.unary_transform(d_in, d_out, double_op, len(d_in))\n",
    "print(f\"Result of unary transform: {d_out.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e413c39-444b-43f8-b5e5-bd1adc18417c",
   "metadata": {},
   "source": [
    "#### Binary transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa210a46-0c41-4c3f-94bd-954bc6add058",
   "metadata": {},
   "source": [
    "The `binary_transform` function applies a user-provided binary operation to pairs of elements from two inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346192c1-2318-437f-aaf5-c8e5f3b21d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input and output arrays.\n",
    "d_in1 = cp.asarray([2, 8, 9, 6, 3], dtype=np.int32)\n",
    "d_in2 = cp.asarray([7, 2, 1, 0, -1], dtype=np.int32)\n",
    "d_out = cp.empty_like(d_in1)\n",
    "\n",
    "# Perform the binary transform.\n",
    "comp.binary_transform(d_in1, d_in2, d_out, comp.OpKind.PLUS, len(d_in1))\n",
    "print(f\"Result of binary transform: {d_out.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76102c-c085-4893-b047-5c22eeabb20b",
   "metadata": {},
   "source": [
    "#### Data Normalization with Transform\n",
    "\n",
    "Transform operations are commonly used in machine learning for data preprocessing, such as normalizing features to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd56eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Normalize house prices for machine learning\n",
    "house_prices = np.array([250000, 180000, 320000, 420000, 150000, 380000, 220000, 295000], dtype=np.float32)\n",
    "d_prices = cp.array(house_prices)\n",
    "d_normalized = cp.empty_like(d_prices)\n",
    "\n",
    "# Calculate statistics for normalization\n",
    "price_mean = float(np.mean(house_prices))\n",
    "price_std = float(np.std(house_prices))\n",
    "\n",
    "print(f\"Original prices: {house_prices}\")\n",
    "print(f\"Mean: ${price_mean:,.0f}, Std: ${price_std:,.0f}\")\n",
    "\n",
    "def z_score_normalize(price):\n",
    "    \"\"\"Z-score normalization: (x - mean) / std\"\"\"\n",
    "    return (price - price_mean) / price_std\n",
    "\n",
    "# Apply normalization transformation\n",
    "comp.unary_transform(d_prices, d_normalized, z_score_normalize, len(house_prices))\n",
    "\n",
    "normalized_result = d_normalized.get()\n",
    "print(f\"Normalized prices: {normalized_result}\")\n",
    "print(f\"Normalized mean: {np.mean(normalized_result):.6f}\")\n",
    "print(f\"Normalized std: {np.std(normalized_result):.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf385d3d",
   "metadata": {},
   "source": [
    "#### Transform with Iterators for Memory Efficiency\n",
    "\n",
    "Combining transforms with iterators allows complex computations without storing intermediate arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sum of squares from 1 to 1000 without storing intermediate arrays\n",
    "def square_func(x):\n",
    "    return x * x\n",
    "\n",
    "def add_op(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Method 1: Using iterators (memory efficient)\n",
    "counting_it = comp.CountingIterator(np.int64(1))  # 1, 2, 3, ...\n",
    "squares_it = comp.TransformIterator(counting_it, square_func)  # 1², 2², 3², ...\n",
    "\n",
    "d_result = cp.empty(1, dtype=np.int64)\n",
    "h_init = np.array([0], dtype=np.int64)\n",
    "\n",
    "# Sum the squares directly without storing them\n",
    "comp.reduce_into(squares_it, d_result, add_op, 1000, h_init)\n",
    "iterator_result = d_result.get()[0]\n",
    "\n",
    "# Mathematical verification: sum of squares = n(n+1)(2n+1)/6\n",
    "n = 1000\n",
    "formula_result = n * (n + 1) * (2 * n + 1) // 6\n",
    "\n",
    "print(f\"Sum of squares from 1 to {n}:\")\n",
    "print(f\"Iterator result: {iterator_result:,}\")\n",
    "print(f\"Formula result:  {formula_result:,}\")\n",
    "print(f\"Correct: {iterator_result == formula_result}\")\n",
    "print(f\"Memory used: Only space for final result (~8 bytes)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17282ee7",
   "metadata": {},
   "source": [
    "## Custom (Struct) Types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541308b1-65b3-4856-adb9-aa1f039f0396",
   "metadata": {},
   "source": [
    "So far, we've seen how to use `parallel` with input arrays composed of numeric values (ints and floats). A powerful feature of `parallel` is that it can also work with \"struct\" values, i.e., values that are in turn composed of more than one value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4ed2b7-a379-4ff4-941d-f0da11ac0a7a",
   "metadata": {},
   "source": [
    "For example, consider a sequence of RGB values, like those used in graphics applications. Each RGB value represents a pixel's color and consists of three components: <font color=\"red\">**red**</font>, <font color=\"green\">**green**</font>, and <font color=\"blue\">**blue**</font> intensity levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5625f-a13f-468a-baa1-84b7e5abd427",
   "metadata": {},
   "source": [
    "The code below shows how you can use `parallel` to find the pixel with the highest <font color=\"green\">**green**</font> intensity level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9281737-5422-41a3-8052-7ade54a96de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `@gpu_struct` to define the data type of each value:\n",
    "@comp.gpu_struct\n",
    "class Pixel:\n",
    "    r: np.int32\n",
    "    g: np.int32\n",
    "    b: np.int32\n",
    "\n",
    "# Define a reduction operation that operates on two `Pixel` objects:\n",
    "def max_g_value(x, y):\n",
    "    return x if x.g > y.g else y\n",
    "\n",
    "# Prepare the input and output arrays. These are just CuPy arrays:\n",
    "dtype = np.dtype([(\"r\", np.int32), (\"g\", np.int32), (\"b\", np.int32)], align=True)  # alternately, use `Pixel.dtype`\n",
    "d_rgb = cp.random.randint(0, 256, (10, 3), dtype=np.int32).view(dtype)\n",
    "d_out = cp.empty(1, dtype)\n",
    "\n",
    "# Define the initial value for the reduction. This must be a `Pixel` object:\n",
    "h_init = Pixel(0, 0, 0)\n",
    "\n",
    "# Perform the reduction.\n",
    "comp.reduce_into(d_rgb, d_out, max_g_value, d_rgb.size, h_init)\n",
    "\n",
    "# Verify the result.\n",
    "print(f\"Input RGB values: \\n {d_rgb.get()}\")\n",
    "result = d_out.get()\n",
    "print(f\"Pixel with greatest 'g' intensity: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2567bc4d",
   "metadata": {},
   "source": [
    "## Working with Iterators\n",
    "\n",
    "Now you have a taste for how to use `parallel` with **custom ops** and **custom data types**. _Iterators_ are another powerful tool in your toolbox for solving more complex problems.\n",
    "\n",
    "Iterators represent streams of data that are computed \"on-the-fly\". Unlike arrays, iterators do not require any memory allocation, and thus can represent huge sequences without consuming valuable GPU memory. Iterators can be used as inputs (and sometimes outputs) to algorithms in place of arrays.\n",
    "\n",
    "Note that \"iterators\" in the context of the `parallel` library is distinct from the concept of [iterators](https://docs.python.org/3/glossary.html#term-iterator) in the Python language. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f350bc-3825-49c3-a858-647aa34177aa",
   "metadata": {},
   "source": [
    "### `CountingIterators` and `ConstantIterator`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514e4183-fc23-4355-8ad4-7b9989c9eaf4",
   "metadata": {},
   "source": [
    "A `CountingIterator` represents the sequence `a, a + 1, a + 2, a + 3,.... `. In the following example, we use a `CountingIterator` as the input to `reduce_into` to compute the sum $1 + 2 + 3 + 4 + 5 = 15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e5f6b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the inputs and outputs:\n",
    "it_input = comp.CountingIterator(np.int32(1))  # represents the sequence 1, 2, 3, ....\n",
    "d_output = cp.empty(1, dtype=np.int32)\n",
    "h_init = np.array([0], dtype=np.int32)\n",
    "\n",
    "# Perform the reduction.\n",
    "comp.reduce_into(it_input, d_output, comp.OpKind.PLUS, 5, h_init)  # compute the reduction for `5` input items\n",
    "\n",
    "print(f\"Sum: {d_output.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7e377",
   "metadata": {},
   "source": [
    "A `ConstantIterator` represents the sequence `a, a, a, ...`. In the following example, we use a `ConstantIterator` as one of the inputs to `binary_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff9cb6-ac1d-43e6-b439-ba7c89029b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input and output arrays.\n",
    "d_in1 = cp.asarray([2, 8, 9, 6, 3], dtype=np.int32)\n",
    "it_in2 = comp.ConstantIterator(np.int32(1))\n",
    "d_out = cp.empty_like(d_in1)\n",
    "\n",
    "# Perform the binary transform.\n",
    "comp.binary_transform(d_in1, it_in2, d_out, comp.OpKind.PLUS, len(d_in1))\n",
    "print(f\"Result of binary transform: {d_out.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e88c3f-8325-47f5-a759-3355b73083f3",
   "metadata": {},
   "source": [
    "### `TransformIterator`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8231ca7-8daf-4208-9739-b77fd06719f9",
   "metadata": {},
   "source": [
    "`TransformIterator` provides a way to compose operations by applying a function to each element as it's accessed. The following code is similar to the `CountingIterator` example above, but it wraps the iterator with a `TransformIterator` to compute the sum $1^2 + 2^2 + 3^2 + 4^2 + 5^2 = 55$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce538d-260c-49a5-83f7-3988aa536803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transform operation.\n",
    "def square(a):\n",
    "    return a**2\n",
    "\n",
    "# prepare the inputs and output.\n",
    "it_count = comp.CountingIterator(np.int32(1))  # represents the sequence 1, 2, 3, ....\n",
    "it_input = comp.TransformIterator(it_count, square)  # represents the sequence 1**2, 2**2, 3**2, ...\n",
    "d_output = cp.empty(1, dtype=np.int32)\n",
    "h_init = np.array([0], dtype=np.int32)\n",
    "\n",
    "# Perform the reduction.\n",
    "comp.reduce_into(it_input, d_output, comp.OpKind.PLUS, 5, h_init)  # compute the reduction for `5` input items\n",
    "\n",
    "print(f\"Sum: {d_output.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c05bf4-f477-456b-8238-aa5fc8bbce18",
   "metadata": {},
   "source": [
    "You can also wrap an array with a `TransformIterator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2301f1f-5a56-4075-9c46-c001bc9bab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_arr = cp.asarray([2, 3, 5, 1, 6, 7, 8, 4], dtype=np.int32)\n",
    "it_input = comp.TransformIterator(d_arr, square)  # represents the sequence [2**2, 3**2, ... 4**2]\n",
    "d_output = cp.empty(1, dtype=np.int32)\n",
    "h_init = np.array([0], dtype=np.int32)\n",
    "\n",
    "# Perform the reduction.\n",
    "comp.reduce_into(it_input, d_output, comp.OpKind.PLUS, len(d_arr), h_init)\n",
    "\n",
    "print(f\"Sum: {d_output.get()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c7736a-248b-4512-a262-cf452c46de8e",
   "metadata": {},
   "source": [
    "Finally, you can use `TransformOutputIterator` as the output of an algorithm, to apply a function to the result as it's being written.\n",
    "\n",
    "⚠️ Note that when using `TransformOutputIterator`, you must currently provide explicit type annotations for the transform function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1142521-452a-4a3a-9f4d-2a1f01251a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_arr = cp.asarray([2, 3, 5, 1, 6, 7, 8, 4], dtype=np.float32)\n",
    "it_input = comp.TransformIterator(d_arr, square)  # represents the sequence [2**2, 3**2, ... 4**2]\n",
    "d_out = cp.empty(1, dtype=np.float32)\n",
    "\n",
    "# provide type annotations when using `TransformOutputIterator`\n",
    "def sqrt(a: np.float32) -> np.float32:\n",
    "    return a**2\n",
    "\n",
    "it_output = comp.TransformOutputIterator(d_out, sqrt)\n",
    "\n",
    "h_init = np.array([0], dtype=np.float32)\n",
    "\n",
    "# Perform the reduction.\n",
    "comp.reduce_into(it_input, it_output, comp.OpKind.PLUS, len(d_arr), h_init)  # compute the reduction for `5` input items\n",
    "\n",
    "print(f\"Sum: {d_out.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c08e0-629b-4428-96c9-59cc3c132b2d",
   "metadata": {},
   "source": [
    "### `ZipIterator`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d7a82-a627-41dc-923d-242a23eae810",
   "metadata": {},
   "source": [
    "A `ZipIterator` combines multiple iterators (or arrays) into a single iterator. To access the individual components of any element of a `ZipIterator`, use numeric indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a5d75-1518-4102-8955-6a8e99e6d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in1 = cp.asarray([2, 3, 5, 1, 6, 7, 8, 4], dtype=np.int32)\n",
    "d_in2 = cp.asarray([7, 7, 9, 3, 1, 2, 6, 0], dtype=np.int32)\n",
    "it_in3 = comp.CountingIterator(np.int32(0))\n",
    "it_input = comp.ZipIterator(d_in1, d_in2, it_in3)\n",
    "\n",
    "def op(x):\n",
    "    return x[0] + x[1] + x[2]\n",
    "\n",
    "d_output = cp.empty_like(d_in1)\n",
    "comp.unary_transform(it_input, d_output, op, len(d_in1))\n",
    "\n",
    "print(f\"Result: {d_output.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf37c9-5d7e-4b2d-a619-e4bd8dbeab46",
   "metadata": {},
   "source": [
    "In the example below, we compute the `min` and `max` of a sequence within a single call to `reduce_into`, using `ZipIterator`. Note the need to define `MinMax` to specify the output type of `minmax_op`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44215d1-8bad-454b-8a0e-a87895dc1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@comp.gpu_struct\n",
    "class MinMax:\n",
    "    min_value: np.int32\n",
    "    max_value: np.int32\n",
    "\n",
    "def minmax_op(x, y):\n",
    "    return MinMax(min(x[0], y[0]), max(x[1], y[1]))\n",
    "\n",
    "d_in = cp.asarray([2, 3, 5, 1, 6, 7, 8, 4], dtype=np.int32)\n",
    "\n",
    "it_input = comp.ZipIterator(d_in, d_in)\n",
    "d_output = cp.empty(2, dtype=np.int32).view(MinMax.dtype)\n",
    "\n",
    "SMALLEST_INT = np.iinfo(np.int32).min\n",
    "LARGEST_INT = np.iinfo(np.int32).max\n",
    "h_init = MinMax(LARGEST_INT, SMALLEST_INT)\n",
    "\n",
    "comp.reduce_into(it_input, d_output, minmax_op, len(d_in), h_init)\n",
    "\n",
    "print(f\"Min value: {d_output.get()[0]['min_value']}\")\n",
    "print(f\"Max value: {d_output.get()[0]['max_value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2acfef-656b-4c07-9b29-6e8de94add5e",
   "metadata": {},
   "source": [
    "#### Iterator Composition\n",
    "\n",
    "You can chain multiple iterator types together to create sophisticated data processing pipelines without intermediate storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a88473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sum of squares of even numbers from 1 to 20\n",
    "def square_if_even(x):\n",
    "    \"\"\"Square the number if it's even, otherwise return 0\"\"\"\n",
    "    return (x * x) if (x % 2 == 0) else 0\n",
    "\n",
    "def add_op(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Chain operations: generate numbers → filter/square evens → sum\n",
    "counting_it = comp.CountingIterator(np.int32(1))  # 1, 2, 3, ..., 20\n",
    "transform_it = comp.TransformIterator(counting_it, square_if_even)  # 0, 4, 0, 16, 0, 36, ...\n",
    "\n",
    "d_result = cp.empty(1, dtype=np.int32)\n",
    "h_init = np.array([0], dtype=np.int32)\n",
    "\n",
    "comp.reduce_into(transform_it, d_result, add_op, 20, h_init)\n",
    "\n",
    "# Verify: even numbers 2,4,6,8,10,12,14,16,18,20 -> squares 4,16,36,64,100,144,196,256,324,400\n",
    "evens = [x for x in range(1, 21) if x % 2 == 0]\n",
    "expected = sum(x * x for x in evens)\n",
    "\n",
    "print(f\"Numbers 1-20: even squares sum\")\n",
    "print(f\"Even numbers: {evens}\")\n",
    "print(f\"Their squares: {[x*x for x in evens]}\")\n",
    "print(f\"Iterator result: {d_result.get()[0]}\")\n",
    "print(f\"Expected result: {expected}\")\n",
    "print(f\"Correct: {d_result.get()[0] == expected}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c859995",
   "metadata": {},
   "source": [
    "### Exercise 3: implementing running average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f16d8f-76e9-40d6-b9ed-159c68379d02",
   "metadata": {},
   "source": [
    "In this example, you'll implement the running average of a sequence, using a single call to the [inclusive_scan](https://nvidia.github.io/cccl/python/parallel_api.html#cuda.compute.algorithms.inclusive_scan) API. To do this, you'll have to piece together many of the concepts we've learned about so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1a1e5-ef83-470d-8991-a2808b8b6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@comp.gpu_struct\n",
    "class SumAndCount:\n",
    "    # begin TODO\n",
    "\n",
    "    # end TODO\n",
    "\n",
    "def reduce_op(x, y) -> SumAndCount:\n",
    "    # begin TODO\n",
    "\n",
    "    # end TODO\n",
    "\n",
    "def compute_running_average(x: SumAndCount) -> np.float32:\n",
    "    # begin TODO\n",
    "\n",
    "    # end TODO\n",
    "\n",
    "d_input = cp.array([2, 3, 5, 1, 7, 6, 8, 4], dtype=np.float32)\n",
    "d_output = cp.empty(len(d_input), dtype=np.float32)\n",
    "h_init = SumAndCount(0, 0)\n",
    "\n",
    "it_input = comp.ZipIterator(d_input, comp.ConstantIterator(np.int32(1)))\n",
    "it_output = comp.TransformOutputIterator(d_output, compute_running_average)\n",
    "\n",
    "# Perform the reduction.\n",
    "comp.inclusive_scan(it_input, it_output, reduce_op, h_init, len(d_input))\n",
    "\n",
    "print(d_input)\n",
    "\n",
    "h_input = d_input.get()\n",
    "expected = h_input.cumsum() / np.arange(1, len(h_input) + 1)\n",
    "\n",
    "print(f\"Running average result: {d_output}\")\n",
    "np.testing.assert_allclose(d_output.get(), expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a22e1a",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* `cuda-cccl` Documentation: https://nvidia.github.io/cccl/python/\n",
    "* `parallel` API Reference: https://nvidia.github.io/cccl/python/parallel_api.html#cuda-cccl-parallel-api-reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
