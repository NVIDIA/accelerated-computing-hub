{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc72f899-45b3-4951-a63f-f729b21a3d67",
   "metadata": {},
   "source": [
    "### CPU and GPU Comparison\n",
    "\n",
    "The CPU is the most common type of processor for executing your code. CPUs have one or more serial processors which each take single instructions from a stack and **execute them sequentially**.\n",
    "\n",
    "GPUs are a form of coprocessor which are commonly used for video and image rendering, but are extremely popular in machine learning and data science fields too. GPUs have one or more streaming multiprocessors which take in arrays of instructions and **execute them in parallel**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345434c3-0798-4a75-906a-b21670de786c",
   "metadata": {},
   "source": [
    "<figure>\n",
    "\n",
    "![CPU GPU Comparison](images/cpu-gpu.png)\n",
    "\n",
    "<figcaption style=\"text-align: center;\"> \n",
    "    \n",
    "Image source <a href=\"https://docs.nvidia.com/cuda/cuda-c-programming-guide/\">https://docs.nvidia.com/cuda/cuda-c-programming-guide/</a>\n",
    "    \n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1963293-c6ce-4d1c-becc-5861743cd3ec",
   "metadata": {},
   "source": [
    "### What is a kernel?\n",
    "\n",
    "A kernel is similar to a function, it is a block of code which takes some inputs and is executed by a processor.\n",
    "\n",
    "The difference between a function and a kernel is:\n",
    "- A kernel cannot return anything, it must instead modify memory\n",
    "- A kernel must specify its thread hierarchy (threads and blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922c26aa-73b0-4436-86db-004e2d8e16bc",
   "metadata": {},
   "source": [
    "### What are grids, threads and blocks (and warps)?\n",
    "\n",
    "[Threads and blocks](https://en.wikipedia.org/wiki/Thread_block_(CUDA_programming) ) are how you instruct you GPU to process some code in parallel. Our GPU is a parallel processor, so we need to specify how many times we want our kernel to be executed.\n",
    "\n",
    "Threads have the benefit of having some shared cache memory between them, but there are a limited number of cores on each GPU so we need to break our work down into blocks which will be scheduled and run in parallel on the GPU.\n",
    "\n",
    "<figure>\n",
    "\n",
    "![CPU GPU Comparison](images/threads-blocks-warps.png)\n",
    "\n",
    "<figcaption style=\"text-align: center;\"> \n",
    "    \n",
    "Image source <a href=\"https://docs.nvidia.com/cuda/cuda-c-programming-guide/\">https://docs.nvidia.com/cuda/cuda-c-programming-guide/</a>\n",
    "    \n",
    "</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688c518-3545-4c0c-ae90-a7aa4bf40690",
   "metadata": {},
   "source": [
    "### So how do you control the GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b6124-a7cc-4d92-ba6d-43d3bd7cdd55",
   "metadata": {},
   "source": [
    "Executing code on your GPU feels a lot like executing code on a second computer over a network.\n",
    "\n",
    "If I wanted to send a Python program to another machine to be executed I would need a few things:\n",
    "- A way to copy data and code to the remote machine (SCP, SFTP, SMB, NFS, etc)\n",
    "- A way to log in and execute programs on that remote machine (SSH, VNC, Remote Desktop, etc)\n",
    "\n",
    "![CPU GPU Comparison](images/two-computers-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e534a-5f6e-4562-a90b-10624dd6afea",
   "metadata": {},
   "source": [
    "To achieve the same things with the GPU we need to use CUDA over PCI. But the idea is still the same &mdash; we need to move data and code to the device and execute that code. \n",
    "\n",
    "\n",
    "\n",
    "![CPU GPU Comparison](images/computer-gpu-cuda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8385d5e-5a11-4d30-b574-418f69fbfbf9",
   "metadata": {},
   "source": [
    "### What is CUDA?\n",
    "\n",
    "[CUDA](https://developer.nvidia.com/cuda-zone) (Compute Unified Device Architecture) is a parallel computing platform and programming model developed by NVIDIA that allows developers to use NVIDIA GPUs for general-purpose processing, not just graphics. It enables programmers to harness the massive parallelism of GPUs to significantly accelerate compute-intensive applications in fields like artificial intelligence, scientific simulations, and data analysis.\n",
    "\n",
    "### What is CUDA Python?\n",
    "\n",
    "[CUDA Python](https://nvidia.github.io/cuda-python/latest/) is the home for accessing NVIDIA’s CUDA platform from Python. It consists of multiple components:\n",
    "\n",
    "- **cuda.core**: Pythonic access to CUDA runtime and other core functionalities\n",
    "- **cuda.bindings**: Low-level Python bindings to CUDA C APIs\n",
    "- **cuda.pathfinder**: Utilities for locating CUDA components installed in the user’s Python environment\n",
    "- **cuda.coop**: A Python module providing CCCL’s reusable block-wide and warp-wide device primitives for use within Numba CUDA kernels\n",
    "- **cuda.compute**: A Python module for easy access to CCCL’s highly efficient and customizable parallel algorithms, like sort, scan, reduce, transform, etc, that are callable on the host\n",
    "- **numba.cuda**: Numba’s target for CUDA GPU programming by directly compiling a restricted subset of Python code into CUDA kernels and device functions following the CUDA execution model.\n",
    "- **nvmath-python**: Pythonic access to NVIDIA CPU & GPU Math Libraries, with both host and device (through nvmath.device) APIs. It also provides low-level Python bindings to host C APIs (through nvmath.bindings).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07174e57-4015-4844-97be-c6d6909ccd85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
