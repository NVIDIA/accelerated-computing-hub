{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d2e341ff-0c1e-40e8-8c33-9e3039de8013",
      "metadata": {
        "id": "d2e341ff-0c1e-40e8-8c33-9e3039de8013"
      },
      "source": [
        "# NumPy `ndarray` Basics - SOLUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ba6a1c",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. [The De Facto Standard for Array Data](#1.-The-De-Facto-Standard-for-Array-Data)\n",
        "2. [Anatomy of an `ndarray`: Structure and Memory](#2.-Anatomy-of-an-`ndarray`:-Structure-and-Memory)\n",
        "3. [Array Creation and Logical Views (Views vs. Copies)](#3.-Array-Creation-and-Logical-Views-(Views-vs.-Copies))\n",
        "4. [Aggregations and Axes](#4.-Aggregations-and-Axes)\n",
        "5. [Broadcasting: The \"Stretch\" Rule](#5.-Broadcasting:-The-\"Stretch\"-Rule)\n",
        "6. [Why Vectorize? The Speed Advantage](#6.-Why-Vectorize?-The-Speed-Advantage)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b30427de",
      "metadata": {},
      "source": [
        "## 1. The De Facto Standard for Array Data\n",
        "\n",
        "NumPy is the foundational library for High Performance Computing (HPC) and Machine Learning (ML) in Python. Libraries like PyTorch, Pandas, and Scikit-learn are built upon or mirror the NumPy API. Learning NumPy is essential for mastering the Array Programming paradigm.\n",
        "\n",
        "NumPy provides the `ndarray` (N-dimensional array), a powerful, high-performance, and uniform container that enables highly efficient memory management, indexing, slicing, and, most importantly, vectorized arithmetic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cc4596d8-d9ff-4c66-8822-246c0fc830c7",
      "metadata": {
        "id": "cc4596d8-d9ff-4c66-8822-246c0fc830c7"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c59fce80",
      "metadata": {},
      "source": [
        "## 2. Anatomy of an `ndarray`: Structure and Memory\n",
        "\n",
        "Unlike a standard Python list, an `ndarray` is a fixed-size, structured block of contiguous memory. Its efficiency comes from these four key, immutable properties:\n",
        "\n",
        "- **Data**: A pointer to the memory location holding the elements.\n",
        "- **dtype**: The data type (e.g., `int32`, `float64`) which is uniform across all elements.\n",
        "- **Shape**: A tuple defining the size along each dimension (e.g., $(100, 50)$ for 100 rows and 50 columns).\n",
        "- **Strides**: The number of bytes to step in memory to reach the next element along each dimensionâ€”this is how NumPy efficiently handles different shapes and views.\n",
        "\n",
        "Let's explore these properties by creating a large dataset.\n",
        "\n",
        "---\n",
        "\n",
        "**Quick Docs**\n",
        "- `np.arange(start, stop, step)`: Returns evenly spaced values in the half-open interval $[\\text{start}, \\text{stop})$.\n",
        "- `arr.nbytes`: Total bytes consumed by the array's elements (in bytes).\n",
        "- `arr.ndim`: The number of array dimensions (integer).\n",
        "- `arr.size`: The total number of elements in the array (integer).\n",
        "- `arr.shape`: The tuple of array dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465e35bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use a large number to clearly demonstrate the memory density of ndarrays\n",
        "N = 50_000_000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1a613f-bc87-4950-b195-a66bb5bc05d3",
      "metadata": {
        "id": "5f1a613f-bc87-4950-b195-a66bb5bc05d3"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Create the input data array with the numbers 1 to 50_000_000 (inclusive).\n",
        "# np.arange generates values within a half-open interval [start, stop), so we use N + 1 as the stop value.\n",
        "arr = np.arange(1, N + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50530f2c-29bf-4061-8f84-bc5be00a5622",
      "metadata": {
        "id": "50530f2c-29bf-4061-8f84-bc5be00a5622"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Calculate how large the array is in GB with nbytes.\n",
        "# GB is 1e9 bytes. The .nbytes attribute returns the total bytes consumed by the elements.\n",
        "# Note: This demonstrates that arrays are dense memory blocks, unlike pointer-heavy Python lists.\n",
        "arr.nbytes / 1e9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc15dad-e2fd-4b96-8b39-3496519d0656",
      "metadata": {
        "id": "ffc15dad-e2fd-4b96-8b39-3496519d0656"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: How many dimensions does the array have? (ndim)\n",
        "arr.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b15cdf25-eb35-4926-b306-90ffd62b3d28",
      "metadata": {
        "id": "b15cdf25-eb35-4926-b306-90ffd62b3d28"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: How many elements does the array have? (size)\n",
        "arr.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63887722-c9d7-405e-a019-e75646115541",
      "metadata": {
        "id": "63887722-c9d7-405e-a019-e75646115541"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: What is the shape of the array?\n",
        "arr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5e58ee4",
      "metadata": {},
      "source": [
        "## 3. Array Creation and Logical Views (Views vs. Copies)\n",
        "\n",
        "Arrays can logically represent data in many ways (e.g., 1D signal, 2D image, 4D video batch) independent of the underlying physical memory block.\n",
        "\n",
        "A critical performance feature is that operations like transposing or `reshape` often return a **View** instead of a **Copy**. A View only changes the metadata (`shape` and `strides`) without duplicating the physical data, making these operations nearly instantaneous.\n",
        "\n",
        "---\n",
        "\n",
        "**Quick Docs**\n",
        "- `np.linspace(start, stop, num)`: Returns `num` evenly spaced samples, calculated over the interval $[\\text{start}, \\text{stop}]$.\n",
        "- `np.random.default_rng().random(size)`: Returns random floats in $[0.0, 1.0)$. `size` can be a tuple.\n",
        "- `arr.sort()`: Sorts an array in-place (modifies the original data). Use `np.sort(arr)` to return a sorted copy.\n",
        "- `arr.reshape(new_shape)`: Returns a View with a new shape. One dimension can be -1, instructing NumPy to calculate the size automatically.\n",
        "- `np.resize(arr, new_shape)`: Returns a new array with the specified shape. If the new shape is larger, it fills the new elements by repeating the original array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1527b4f6-5d75-47d4-97e0-d0e78bbc59f9",
      "metadata": {
        "id": "1527b4f6-5d75-47d4-97e0-d0e78bbc59f9"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Create a new array with 5_000_000 elements containing equally spaced values between 0 to 1000 (inclusive).\n",
        "# np.linspace returns 'num' evenly spaced samples over the closed interval [start, stop].\n",
        "arr = np.linspace(0, 1000, 5_000_000)\n",
        "arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f51aa2e-b994-4a91-aed6-4a4632eb7050",
      "metadata": {
        "id": "2f51aa2e-b994-4a91-aed6-4a4632eb7050"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Create a random array that is 10_000 rows by 5_000 columns.\n",
        "# np.random.default_rng().random(size) returns random floats in [0.0, 1.0). size can be a tuple.\n",
        "arr = np.random.default_rng().random((10_000, 5_000))\n",
        "arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec06270-6e08-4cce-9385-9dc8b53e95fd",
      "metadata": {
        "id": "4ec06270-6e08-4cce-9385-9dc8b53e95fd"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Sort that array (in-place).\n",
        "# Note: arr.sort() modifies the array directly, which is typically faster than creating a copy.\n",
        "arr.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdde560b-5ba6-484c-a601-00b7ef71273d",
      "metadata": {
        "id": "cdde560b-5ba6-484c-a601-00b7ef71273d"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Reshape the array to have the last dimension of length 5. \n",
        "# Using -1 lets NumPy automatically calculate the first dimension.\n",
        "# .reshape() returns a View (not a copy) when possible, so no data is duplicated.\n",
        "arr_new = arr.reshape(-1, 5)\n",
        "arr_new"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54982876",
      "metadata": {},
      "source": [
        "## 4. Aggregations and Axes\n",
        "\n",
        "When performing aggregations (like `sum`, `mean`, `max`), you must specify the **Axis** you want to collapse (or reduce) the array along.\n",
        "\n",
        "- **Axis 0**: The first dimension (often rows in 2D). Aggregating across Axis 0 produces a result for each column.\n",
        "- **Axis 1**: The second dimension (often columns in 2D). Aggregating across Axis 1 produces a result for each row.\n",
        "\n",
        "---\n",
        "\n",
        "**Quick Docs**\n",
        "- `np.sum(a, axis=None)`: Sum of array elements over a given axis.\n",
        "  - `axis=0`: Collapse the rows (sum vertical columns).\n",
        "  - `axis=1`: Collapse the columns (sum horizontal rows).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44dd3ac2-c9b7-4327-ba63-860b074c0583",
      "metadata": {
        "id": "44dd3ac2-c9b7-4327-ba63-860b074c0583"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Find the sum of each row in the reshaped array (arr_new) above.\n",
        "# To sum the row's content, we reduce across the columns (axis=1).\n",
        "# axis=1 collapses the second dimension (columns), leaving one sum per row.\n",
        "arr_sum = np.sum(arr_new, axis=1)\n",
        "arr_sum"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed072cee",
      "metadata": {},
      "source": [
        "## 5. Broadcasting: The \"Stretch\" Rule\n",
        "\n",
        "Broadcasting is NumPy's mechanism for performing arithmetic between arrays of different shapes. If dimensions don't match, NumPy attempts to \"stretch\" the smaller array to match the larger one.\n",
        "\n",
        "**The Compatibility Rule:** Two dimensions are compatible when:\n",
        "1. They are equal, or\n",
        "2. One of them is 1.\n",
        "\n",
        "If a dimension is 1, NumPy logically copies that single value across the dimension to match the other array's shape **without allocating any new memory**.\n",
        "\n",
        "---\n",
        "\n",
        "**Quick Docs**\n",
        "- **Arithmetic Operators** (`/`, `*`, `+`, `-`): These operate element-wise. Broadcasting occurs if shapes are different but compatible.\n",
        "- `np.allclose(a, b)`: Returns `True` if two floating-point arrays are element-wise equal within a tolerance. Essential for comparisons instead of using `==`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b15342af-2916-481a-9724-9874acf4ed24",
      "metadata": {
        "id": "b15342af-2916-481a-9724-9874acf4ed24"
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Normalize each row of the 2D array (arr_new) by dividing by the sum you just computed (arr_sum).\n",
        "# 'arr_new' has shape (M, N) and 'arr_sum' has shape (M,).\n",
        "# To successfully divide, we reshape 'arr_sum' to (M, 1) so broadcasting can stretch it across the N columns.\n",
        "# Alternative approaches: arr_sum[:, np.newaxis] or arr_sum[:, None] also work.\n",
        "arr_normalized = arr_new / arr_sum.reshape(-1, 1)\n",
        "arr_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04622b8-c6de-4756-8a56-e3d2835a5eaf",
      "metadata": {
        "id": "b04622b8-c6de-4756-8a56-e3d2835a5eaf"
      },
      "outputs": [],
      "source": [
        "# SOLUTION (EXTRA CREDIT): Prove that your normalized array is actually normalized.\n",
        "# If normalized correctly, the sum of every row should now be 1.0.\n",
        "# We compute row sums (axis=1) and check if they are all close to 1.0 using np.allclose.\n",
        "np.allclose(np.sum(arr_normalized, axis=1), 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31657dd2",
      "metadata": {},
      "source": [
        "## 6. Why Vectorize? The Speed Advantage\n",
        "\n",
        "The entire Array Programming paradigm hinges on **Vectorization**.\n",
        "\n",
        "Why use complex shapes and broadcasting instead of simple Python `for` loops?\n",
        "\n",
        "NumPy's array functions are implemented in highly optimized native code (C/C++, Fortran). An operation like `A + A**2`, where `A` is a massive `ndarray`, is often $\\mathbf{100\\times}$ faster than performing the equivalent element-wise operation using explicit Python loops.\n",
        "\n",
        "**Always choose a vectorized NumPy function or operator over a manual Python loop.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
