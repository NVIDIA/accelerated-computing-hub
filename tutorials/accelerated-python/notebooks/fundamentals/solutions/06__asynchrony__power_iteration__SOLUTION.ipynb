{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchrony and Power Iteration - SOLUTION\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction and Setup](#1-Introduction-and-Setup)\n",
    "   - [1.1 Environment Setup](#11-Environment-Setup)\n",
    "2. [Theory: Streams and Synchronization](#2-Theory:-Streams-and-Synchronization)\n",
    "3. [The Baseline Implementation](#3-The-Baseline-Implementation)\n",
    "4. [Profiling the Baseline](#4-Profiling-the-Baseline)\n",
    "5. [Better Visibility with NVTX](#5-Better-Visibility-with-NVTX)\n",
    "6. [Implementing Asynchrony](#6-Implementing-Asynchrony)\n",
    "7. [Performance Analysis](#7-Performance-Analysis)\n",
    "\n",
    "## 1. Introduction and Setup\n",
    "\n",
    "GPU programming is inherently asynchronous. In this exercise, we will explore the implications of this behavior when using CuPy and learn how to analyze the flow of execution using profiling tools.\n",
    "\n",
    "We will revisit the Power Iteration algorithm. Our goal is to take a standard implementation, profile it to identify bottlenecks caused by implicit synchronization, and then optimize it using CUDA streams and asynchronous memory transfers.\n",
    "\n",
    "### 1.1 Environment Setup\n",
    "\n",
    "First, we need to ensure the Nsight Systems profiler (nsys), Nsightful, and NVTX are installed and available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Install necessary tools if running in Google Colab\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "  !curl -s -L -O https://developer.nvidia.com/downloads/assets/tools/secure/nsight-systems/2025_3/NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb\n",
    "  !sudo dpkg -i NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb > /dev/null\n",
    "  !pip install \"nvtx\" \"nsightful[notebook] @ git+https://github.com/brycelelbach/nsightful.git\" > /dev/null 2>&1\n",
    "\n",
    "print(\"Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theory: Streams and Synchronization\n",
    "\n",
    "All GPU work is launched asynchronously on a stream. The work items in a stream are executed in order. If you launch `f` on a stream and later launch `g` on that same stream, then `f` will be executed before `g`. But if `f` and `g` are launched on different streams, then their execution might overlap.\n",
    "\n",
    "**How CuPy handles this:**\n",
    "\n",
    "- **Default Stream:** Unless specified, CuPy launches work on the default CUDA stream.\n",
    "\n",
    "- **Sequential Device Execution:** By default, CuPy work executes sequentially on the GPU.\n",
    "\n",
    "- **Asynchronous Host Execution:** From the Python (Host) perspective, the code often returns immediately after launching the GPU kernel, before the work is actually finished.\n",
    "\n",
    "**SOLUTION:** Certain operations force the CPU to wait for the GPU to finish (implicit synchronization):\n",
    "- Accessing element values from device arrays (e.g., `x[0]`, `.item()`)\n",
    "- Printing device array values\n",
    "- Device-to-host memory transfers with `cp.asnumpy()` (by default)\n",
    "- Explicit synchronization calls\n",
    "\n",
    "## 3. The Baseline Implementation\n",
    "\n",
    "We will start with a baseline implementation of the Power Iteration algorithm.\n",
    "\n",
    "**Note:** The cell below writes the code to a file named `power_iteration__baseline.py`. We do this because we must run the code through the Nsight Systems profiler via the command line.\n",
    "\n",
    "**SOLUTION:** The baseline code below already includes NVTX annotations and `cpx.profiler.profile()` to demonstrate the proper profiling setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile power_iteration__baseline.py\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cupyx as cpx\n",
    "import nvtx\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PowerIterationConfig:\n",
    "  dim: int = 8192\n",
    "  dominance: float = 0.05\n",
    "  max_steps: int = 1000\n",
    "  check_frequency: int = 10\n",
    "  progress: bool = True\n",
    "  residual_threshold: float = 1e-10\n",
    "\n",
    "def generate_device(cfg=PowerIterationConfig()):\n",
    "  cp.random.seed(42)\n",
    "  weak_lam = cp.random.random(cfg.dim - 1) * (1.0 - cfg.dominance)\n",
    "  lam = cp.random.permutation(cp.concatenate((cp.asarray([1.0]), weak_lam)))\n",
    "  P = cp.random.random((cfg.dim, cfg.dim))\n",
    "  D = cp.diag(cp.random.permutation(lam))\n",
    "  A = ((P @ D) @ cp.linalg.inv(P))\n",
    "  return A\n",
    "\n",
    "def estimate_device(A, cfg=PowerIterationConfig()):\n",
    "  with nvtx.annotate(\"Setup\"):\n",
    "    A_gpu = cp.asarray(A) # If `A` is on the host, copy from host to device.\n",
    "                          # Otherwise, does nothing.\n",
    "\n",
    "    x = cp.ones(A_gpu.shape[0], dtype=np.float64)\n",
    "\n",
    "  with nvtx.annotate(\"Loop\"):\n",
    "    for i in range(0, cfg.max_steps, cfg.check_frequency):\n",
    "      with nvtx.annotate(f\"Step {i} to {i + cfg.check_frequency}\"):\n",
    "        with nvtx.annotate(f\"Compute & Residual {i}\"):\n",
    "          y = A_gpu @ x\n",
    "          lam = (x @ y) / (x @ x)            # Rayleigh quotient.\n",
    "          res = cp.linalg.norm(y - lam * x)\n",
    "          x = y / cp.linalg.norm(y)          # Normalize for next step.\n",
    "\n",
    "        with nvtx.annotate(f\"Copy {i}\"):\n",
    "          res_host = cp.asnumpy(res)\n",
    "          x_host = cp.asnumpy(x)\n",
    "\n",
    "        with nvtx.annotate(f\"I/O {i}\"):\n",
    "          if cfg.progress:\n",
    "            print(f\"step {i}: residual = {res_host:.3e}\")\n",
    "\n",
    "          np.savetxt(f\"device_{i}.txt\", x_host) # Copy from device to host and\n",
    "                                                # save a checkpoint.\n",
    "\n",
    "          if res_host < cfg.residual_threshold:\n",
    "            break\n",
    "\n",
    "        with nvtx.annotate(f\"Compute {i}\"):\n",
    "          for _ in range(cfg.check_frequency - 1):\n",
    "            y = A_gpu @ x # We have to use `A_gpu` here as well.\n",
    "            x = y / cp.linalg.norm(y) # Normalize for next step.\n",
    "\n",
    "  return cp.asnumpy((x.T @ (A_gpu @ x)) / (x.T @ x)) # Copy from device to host.\n",
    "\n",
    "A_device = generate_device()\n",
    "\n",
    "# Warmup to ensure modules are loaded and code is JIT compiled before timing.\n",
    "estimate_device(A_device, cfg=PowerIterationConfig(progress=False))\n",
    "\n",
    "with cpx.profiler.profile():\n",
    "  start = cp.cuda.get_current_stream().record()\n",
    "  lam_est_device = estimate_device(A_device).item()\n",
    "  stop = cp.cuda.get_current_stream().record()\n",
    "\n",
    "duration = cp.cuda.get_elapsed_time(start, stop) / 1e3\n",
    "\n",
    "print()\n",
    "print(f\"GPU Execution Time: {duration:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Profiling the Baseline\n",
    "\n",
    "Now let's profile our code by running it under the Nsight Systems `nsys` tool. The syntax for this is `nsys <nsys flags> <your program> <your program args>`. It will run your program while collecting a birdseye view of everything going on in your program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo nsys profile --cuda-event-trace=false --capture-range=cudaProfilerApi --capture-range-end=stop --force-overwrite true -o power_iteration__baseline python power_iteration__baseline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's view our report and explore what's going on in our program.\n",
    "\n",
    "Run the next cell, which will generate the report and create a button that when clicked will open it up in Perfetto, a web-based no-install visual profiler.\n",
    "\n",
    "**EXTRA CREDIT:** Download the Nsight Systems GUI and open the report in it to see even more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nsightful\n",
    "\n",
    "!nsys export --type sqlite --quiet true --force-overwrite true power_iteration__baseline.nsys-rep\n",
    "nsightful.display_nsys_sqlite_file_in_notebook(\"power_iteration__baseline.sqlite\", title=\"Power Iteration - Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Better Visibility with NVTX\n",
    "\n",
    "Nsight Systems shows us a lot of information - sometimes it's too much and not all relevant.\n",
    "\n",
    "There's two ways that we can filter and annotate what we see in Nsight systems.\n",
    "\n",
    "The first is to limit when we start and stop profiling in the program. In Python, we can do this with `cupyx.profiler.profile()`, which give us a Python context manager. Any CUDA code used during scope will be included in the profile.\n",
    "\n",
    "```\n",
    "not_in_the profile()\n",
    "with cpx.profiler.profile():\n",
    "  in_the_profile()\n",
    "not_in_the_profile()\n",
    "```\n",
    "\n",
    "For this to work, we have to pass `--capture-range=cudaProfilerApi --capture-range-end=stop` as flags to `nsys`.\n",
    "\n",
    "We can also annotate specific regions of our code, which will show up in the profiler. We can even add categories, domains, and colors to these regions, and they can be nested. To add these annotations, we use `nvtx.annnotate()`, another Python context manager, this time from a library called NVTX.\n",
    "\n",
    "```\n",
    "with nvtx.annotate(\"Loop\")\n",
    "  for i in range(20):\n",
    "     with nvtx.annotate(f\"Step {i}\"):\n",
    "       pass\n",
    "```\n",
    "\n",
    "**SOLUTION:** The baseline code above already includes:\n",
    "\n",
    "- `nvtx.annotate()` regions for \"Setup\", \"Loop\", \"Step\", \"Compute & Residual\", \"Copy\", \"I/O\", and \"Compute\" phases.\n",
    "\n",
    "- A `cpx.profiler.profile()` around the timing section.\n",
    "\n",
    "- The `nsys` command includes `--capture-range=cudaProfilerApi --capture-range-end=stop` flags.\n",
    "\n",
    "From our profile trace, we can see that both our CPU and GPU are idly waiting for each other! Device code is idle during every I/O step when we print the residual and write the checkpoint, and host code spends a long time synchronizing on `cudaMemcpyAsync`.\n",
    "\n",
    "Here's what happens at the start of each I/O step:\n",
    "\n",
    "- We copy from device to host, which synchronizes with any outstanding work on the device. This blocks the host for awhile.\n",
    "- After that synchronous transfer has completed, we begin the I/O (printing and writing the checkpoint). During this time, the device is idle.\n",
    "- After the I/O has completed on the host, we start launching the next set of iterations.\n",
    "\n",
    "This is inefficient; we can do better by overlapping compute and I/O:\n",
    "\n",
    "- First, host code asynchronously initiate our device to host copies.\n",
    "- Then, host code asynchronously launch the next set of compute steps on the device.\n",
    "- Next, host code synchronize with the asynchronous copies we started.\n",
    "- Finally, the host performs the I/O while the device performs the next set of compute steps.\n",
    "\n",
    "Everything is still going to run on one stream, but we want to be able to synchronize with just the I/O, which is launched on the stream before the compute work. We'll use a CUDA event, which we will record on the stream right after the copy. Then, we can synchronize with the event later, waiting for the I/O but not the compute!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementing Asynchrony\n",
    "\n",
    "Remember what we've learned about streams and how to use them with CuPy:\n",
    "\n",
    "- By default, all CuPy operations within a single thread run on the same stream. You can access this stream with `cp.cuda.get_current_stream()`.\n",
    "\n",
    "- You can create a new stream with `cp.cuda.Stream(non_blocking=True)`. Use `with` statements to use the stream for all CuPy operations within a block.\n",
    "\n",
    "- You can record an event on a stream by calling `.record()` on it.\n",
    "\n",
    "- You can synchronize on an event (or an entire stream) by calling `.synchronize()` on it.\n",
    "\n",
    "- Memory transfers will block by default. You can launch them asynchronously with `cp.asarray(..., blocking=False)` (for host to device transfers) and `cp.asnumpy(..., blocking=False)` (for device to host transfers).\n",
    "\n",
    "**SOLUTION:** The implementation below uses asynchronous memory transfers and CUDA events to overlap compute and I/O operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile power_iteration__async.py\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cupyx as cpx\n",
    "import nvtx\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PowerIterationConfig:\n",
    "  dim: int = 8192\n",
    "  dominance: float = 0.05\n",
    "  max_steps: int = 1000\n",
    "  check_frequency: int = 10\n",
    "  progress: bool = True\n",
    "  residual_threshold: float = 1e-10\n",
    "\n",
    "def generate_device(cfg=PowerIterationConfig()):\n",
    "  cp.random.seed(42)\n",
    "  weak_lam = cp.random.random(cfg.dim - 1) * (1.0 - cfg.dominance)\n",
    "  lam = cp.random.permutation(cp.concatenate((cp.asarray([1.0]), weak_lam)))\n",
    "  P = cp.random.random((cfg.dim, cfg.dim))\n",
    "  D = cp.diag(cp.random.permutation(lam))\n",
    "  A = ((P @ D) @ cp.linalg.inv(P))\n",
    "  return A\n",
    "\n",
    "def estimate_device(A, cfg=PowerIterationConfig()):\n",
    "  with nvtx.annotate(\"Setup\"):\n",
    "    A_gpu = cp.asarray(A) # If `A` is on the host, copy from host to device.\n",
    "                          # Otherwise, does nothing.\n",
    "\n",
    "    x = cp.ones(A_gpu.shape[0], dtype=np.float64)\n",
    "\n",
    "  with nvtx.annotate(\"Loop\"):\n",
    "    for i in range(0, cfg.max_steps, cfg.check_frequency):\n",
    "      with nvtx.annotate(f\"Step {i} to {i + cfg.check_frequency}\"):\n",
    "        with nvtx.annotate(f\"Compute & Residual {i}\"):\n",
    "          y = A_gpu @ x\n",
    "          lam = (x @ y) / (x @ x)            # Rayleigh quotient.\n",
    "          res = cp.linalg.norm(y - lam * x)\n",
    "          x = y / cp.linalg.norm(y)          # Normalize for next step.\n",
    "\n",
    "        with nvtx.annotate(f\"Copy {i}\"):\n",
    "          res_host = cp.asnumpy(res, blocking=False)\n",
    "          x_host = cp.asnumpy(x, blocking=False)\n",
    "          copy_event = cp.cuda.get_current_stream().record()\n",
    "\n",
    "        with nvtx.annotate(f\"Compute {i}\"):\n",
    "          for _ in range(cfg.check_frequency - 1):\n",
    "            y = A_gpu @ x # We have to use `A_gpu` here as well.\n",
    "            x = y / cp.linalg.norm(y) # Normalize for next step.\n",
    "\n",
    "        with nvtx.annotate(f\"I/O {i}\", payload=i):\n",
    "          copy_event.synchronize() # Wait for the copies to complete.\n",
    "\n",
    "          if cfg.progress:\n",
    "            print(f\"step {i}: residual = {res_host:.3e}\")\n",
    "\n",
    "          np.savetxt(f\"device_{i}.txt\", x_host) # Save a checkpoint.\n",
    "\n",
    "          if res_host < cfg.residual_threshold:\n",
    "            break\n",
    "\n",
    "  return cp.asnumpy((x.T @ (A_gpu @ x)) / (x.T @ x)) # Copy from device to host.\n",
    "\n",
    "A_device = generate_device()\n",
    "\n",
    "# Warmup to ensure modules are loaded and code is JIT compiled before timing.\n",
    "estimate_device(A_device, cfg=PowerIterationConfig(progress=False))\n",
    "\n",
    "with cpx.profiler.profile():\n",
    "  start = cp.cuda.get_current_stream().record()\n",
    "  lam_est_device = estimate_device(A_device).item()\n",
    "  stop = cp.cuda.get_current_stream().record()\n",
    "\n",
    "duration = cp.cuda.get_elapsed_time(start, stop) / 1e3\n",
    "\n",
    "print()\n",
    "print(f\"GPU Execution Time: {duration:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python power_iteration__async.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Analysis\n",
    "\n",
    "Before we profile the improved code, let's compare the execution times of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_iteration_baseline_output   = !python power_iteration__baseline.py\n",
    "power_iteration_baseline_duration = float(power_iteration_baseline_output[-1].split()[-2])\n",
    "power_iteration_async_output      = !python power_iteration__async.py\n",
    "power_iteration_async_duration    = float(power_iteration_async_output[-1].split()[-2])\n",
    "speedup = power_iteration_baseline_duration / power_iteration_async_duration\n",
    "\n",
    "print(f\"GPU Execution Time\")\n",
    "print()\n",
    "print(f\"power_iteration_baseline: {power_iteration_baseline_duration:.3f} s\")\n",
    "print(f\"power_iteration_async:    {power_iteration_async_duration:.3f} s\")\n",
    "print(f\"power_iteration_async speedup over power_iteration_baseline: {speedup:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's capture a profile report of our improved code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo nsys profile --cuda-event-trace=false --capture-range=cudaProfilerApi --capture-range-end=stop --force-overwrite true -o power_iteration__async python power_iteration__async.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at the profile in Perfetto and confirm we've gotten rid of the idling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nsys export --type sqlite --quiet true --force-overwrite true power_iteration__async.nsys-rep\n",
    "nsightful.display_nsys_sqlite_file_in_notebook(\"power_iteration__async.sqlite\", title=\"Power Iteration - Async\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
