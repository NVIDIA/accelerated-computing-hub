{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9a5bf9",
   "metadata": {},
   "source": [
    "## CUDA Core Tutorial - Low-Level GPU Programming\n",
    "### Table of Contents\n",
    "\n",
    "7. Exercise Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd7b7c0-99bf-4b05-949b-8c1153a4d92b",
   "metadata": {},
   "source": [
    "### 7. Exercise: Vector Operations\n",
    "Write a CUDA kernel that performs element-wise multiplication of two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95d896e4-a189-40e4-9c74-f00422ecbe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Compile your kernel here\n",
    "from cuda.core.experimental import Device, Program\n",
    "\n",
    "multiply_kernel_source = \"\"\"\n",
    "// TODO: Implement vector multiplication kernel\n",
    "extern \"C\" __global__ void vector_multiply(float *a, float *b, float *c, int n) {\n",
    "    // Each thread calculates its unique index\n",
    "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    \n",
    "    // Make sure we don't go beyond our array bounds\n",
    "    if (i < n) {\n",
    "        c[i] = a[i] * b[i];  // Multiply corresponding elements\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Initialize our GPU\n",
    "device = Device(0)\n",
    "device.set_current()\n",
    "\n",
    "# Compile the CUDA code into a program\n",
    "program = Program(multiply_kernel_source, code_type='c++')\n",
    "compiled_program = program.compile(target_type='cubin')\n",
    "\n",
    "# Get the specific kernel function we want to use\n",
    "kernel = compiled_program.get_kernel(\"vector_multiply\")\n",
    "\n",
    "print(\"Kernel compiled successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf1e9fb4-812d-4d38-967f-008709938f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input arrays have 1000 elements each\n",
      "Launch configuration: 4 blocks of 256 threads each\n",
      "Total threads: 1024\n",
      "Kernel launched and executed\n",
      "Results copied back to CPU\n",
      "Kernel execution successful: True\n",
      "First 10 results: [ 0.  1.  4.  9. 16. 25. 36. 49. 64. 81.]\n",
      "Expected first 10: [ 0.  1.  4.  9. 16. 25. 36. 49. 64. 81.]\n"
     ]
    }
   ],
   "source": [
    "# Launch your kernel here\n",
    "import cupy as cp\n",
    "from cuda.core.experimental import launch, LaunchConfig\n",
    "\n",
    "def vector_multiply(a, b):\n",
    "    # Step 1: Initialize device\n",
    "    device = Device(0) \n",
    "    device.set_current()\n",
    "    s = device.create_stream()\n",
    "    \n",
    "    # Step 2: Prepare our test data\n",
    "    N = 1000  # Number of elements\n",
    "    a = np.arange(N, dtype=np.float32)      # [0, 1, 2, ..., 999]\n",
    "    b = np.arange(N, dtype=np.float32)      # [0, 1, 2, ..., 999]\n",
    "    print(f\"Input arrays have {N} elements each\")\n",
    "\n",
    "    # Step 3: Copy input data from CPU to GPU\n",
    "    d_a = cp.asarray(a)\n",
    "    d_b = cp.asarray(b)\n",
    "    d_c = cp.ones(N, dtype=cp.float32)\n",
    "    \n",
    "    # Step 4: Configure how to launch the kernel\n",
    "    block_size = 256  # Number of threads per block\n",
    "    grid_size = (N + block_size - 1) // block_size  # Number of blocks needed\n",
    "    \n",
    "    print(f\"Launch configuration: {grid_size} blocks of {block_size} threads each\")\n",
    "    print(f\"Total threads: {grid_size * block_size}\")\n",
    "    \n",
    "    # Create the launch configuration\n",
    "    config = LaunchConfig(grid=(grid_size,), block=(block_size,))\n",
    "    ker_args = (d_a.data.ptr, d_b.data.ptr, d_c.data.ptr, N)\n",
    "    \n",
    "    # Step 5: Launch the kernel!\n",
    "    launch(s, config, kernel, *ker_args)\n",
    "    s.sync()\n",
    "    print(\"Kernel launched and executed\")\n",
    "    \n",
    "    # Step 6: Copy the result back from GPU to CPU\n",
    "    c = cp.asnumpy(d_c)\n",
    "    print(\"Results copied back to CPU\")\n",
    "    \n",
    "    return c\n",
    "\n",
    "# Execute our vector addition\n",
    "a = np.arange(1000, dtype=np.float32)\n",
    "result = vector_multiply(a, a)\n",
    "\n",
    "# Verify the result\n",
    "expected = a * a\n",
    "success = np.allclose(result, expected)\n",
    "print(f\"Kernel execution successful: {success}\")\n",
    "print(f\"First 10 results: {result[:10]}\")\n",
    "print(f\"Expected first 10: {expected[:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
