{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f966f67f",
      "metadata": {},
      "source": [
        "# Accelerated Computing with CuPy\n",
        "\n",
        "## Table of Contents\n",
        "1. [Creating Arrays: CPU vs. GPU](#1.-Creating-Arrays:-CPU-vs.-GPU)\n",
        "2. [Basic Operations](#2.-Basic-Operations)\n",
        "   - [Sequential Operations & Memory](#Sequential-Operations-&-Memory)\n",
        "3. [Complex Operations (Linear Algebra)](#3.-Complex-Operations-(Linear-Algebra))\n",
        "   - [Agnostic Code (NumPy Dispatch)](#Agnostic-Code-(NumPy-Dispatch))\n",
        "4. [Device Management](#4.-Device-Management)\n",
        "5. [Exercise - NumPy to CuPy](#Exercise---NumPy-to-CuPy)\n",
        "   - [Part 1](#Part-1)\n",
        "   - [Part 2](#Part-2)\n",
        "\n",
        "---\n",
        "\n",
        "Let's shift gears to high-level array functionality using **[CuPy](https://cupy.dev/)**.\n",
        "\n",
        "### What is CuPy?\n",
        "CuPy is a library that implements the familiar **NumPy API** but runs on the GPU (using CUDA C++ in the backend). \n",
        "\n",
        "**Why use it?**\n",
        "* **Zero Friction:** If you know NumPy, you already know CuPy.\n",
        "* **Speed:** It provides out-of-the-box GPU acceleration for array operations.\n",
        "* **Ease of use:** You can often port CPU code to GPU simply by changing `import numpy as np` to `import cupy as cp`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d369bcdc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "from cupyx.profiler import benchmark\n",
        "\n",
        "# Helper to display benchmark results concisely.\n",
        "# We use CuPy's benchmark() throughout this notebook for accurate GPU timing.\n",
        "def print_benchmark(result, device=\"gpu\"):\n",
        "    \"\"\"Print benchmark result showing only the relevant time.\"\"\"\n",
        "    if device == \"gpu\":\n",
        "        avg_ms = result.gpu_times.mean() * 1000\n",
        "        std_ms = result.gpu_times.std() * 1000\n",
        "        print(f\"{result.name}: {avg_ms:.3f} ms +/- {std_ms:.3f} ms\")\n",
        "    else:\n",
        "        avg_ms = result.cpu_times.mean() * 1000\n",
        "        std_ms = result.cpu_times.std() * 1000\n",
        "        print(f\"{result.name}: {avg_ms:.3f} ms +/- {std_ms:.3f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15fc304c",
      "metadata": {},
      "source": [
        "## 1. Creating Arrays: CPU vs. GPU\n",
        "\n",
        "Let's compare the performance of creating a large 3D array (approx. 2GB in size) on the CPU versus the GPU.\n",
        "\n",
        "We will use `np.ones` for the CPU and `cp.ones` for the GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f8b002",
      "metadata": {},
      "outputs": [],
      "source": [
        "# CPU creation\n",
        "print_benchmark(benchmark(np.ones, ((1000, 500, 500),), n_repeat=10), device=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19309ca7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU creation\n",
        "print_benchmark(benchmark(cp.ones, ((1000, 500, 500),), n_repeat=10), device=\"gpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae637eaf",
      "metadata": {},
      "source": [
        "We can see here that creating this array on the GPU is much faster than doing so on the CPU!\n",
        "\n",
        "**About `cupyx.profiler.benchmark`:**\n",
        "\n",
        "We use CuPy's built-in `benchmark` utility for timing GPU operations. This is important because GPU operations are **asynchronous** - when you call a CuPy function, the CPU places a task in the GPU's \"to-do list\" (stream) and immediately moves on without waiting.\n",
        "\n",
        "The `benchmark` function handles all the complexity of proper GPU timing for us:\n",
        "- It automatically synchronizes GPU streams to get accurate measurements.\n",
        "- It runs warm-up iterations to avoid cold-start overhead.\n",
        "- It reports both CPU and GPU times separately.\n",
        "\n",
        "This makes it the recommended way to time CuPy code, as it's both accurate and convenient."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d179e9b",
      "metadata": {},
      "source": [
        "## 2. Basic Operations\n",
        "\n",
        "The syntax for mathematical operations is identical. Let's multiply every value in our arrays by `5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5bdefb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create fresh arrays for the benchmark\n",
        "x_cpu = np.ones((1000, 500, 500))\n",
        "x_gpu = cp.ones((1000, 500, 500))\n",
        "\n",
        "def multiply(x):\n",
        "    return x * 5\n",
        "\n",
        "# CPU Operation\n",
        "print_benchmark(benchmark(multiply, (x_cpu,), n_repeat=10), device=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a7f32b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU Operation\n",
        "print_benchmark(benchmark(multiply, (x_gpu,), n_repeat=10), device=\"gpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc24579f",
      "metadata": {},
      "source": [
        "The GPU completes this operation notably faster, with the code staying the same."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c69334",
      "metadata": {},
      "source": [
        "### Sequential Operations & Memory\n",
        "\n",
        "Now let's do a couple of operations sequentially, something which would suffer from memory transfer times in Numba examples without explicit memory management."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0294dbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sequential_math(x):\n",
        "    x = x * 5\n",
        "    x = x * x\n",
        "    x = x + x\n",
        "    return x\n",
        "\n",
        "# CPU: Sequential math\n",
        "print_benchmark(benchmark(sequential_math, (x_cpu,), n_repeat=10), device=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acafdbe7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU: Sequential math\n",
        "print_benchmark(benchmark(sequential_math, (x_gpu,), n_repeat=10), device=\"gpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f250bbb",
      "metadata": {},
      "source": [
        "The GPU ran that much faster even without us explicitly managing memory. This is because CuPy is handling all of this for us transparently."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84221268",
      "metadata": {},
      "source": [
        "## 3. Complex Operations (Linear Algebra)\n",
        "\n",
        "GPUs excel at Linear Algebra. Let's look at **Singular Value Decomposition (SVD)**, a computationally heavy $O(N^3)$ operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "978af795",
      "metadata": {},
      "outputs": [],
      "source": [
        "# CPU SVD\n",
        "x_cpu = np.random.random((1000, 1000))\n",
        "print_benchmark(benchmark(np.linalg.svd, (x_cpu,), n_repeat=5), device=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0bc855b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU SVD\n",
        "x_gpu = cp.random.random((1000, 1000))\n",
        "print_benchmark(benchmark(cp.linalg.svd, (x_gpu,), n_repeat=5), device=\"gpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e298f0ea",
      "metadata": {},
      "source": [
        "The GPU outperforms the CPU again with exactly the same API!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0870d0",
      "metadata": {},
      "source": [
        "### Agnostic Code (NumPy Dispatch)\n",
        "\n",
        "A key feature of CuPy is that many **NumPy functions work on CuPy arrays without changing your code**.\n",
        "\n",
        "When you pass a CuPy GPU array (`x_gpu`) into a NumPy function that supports the `__array_function__` protocol (e.g., `np.linalg.svd`), NumPy detects the CuPy input and **delegates the operation to CuPy’s own implementation**, which runs on the GPU.\n",
        "\n",
        "This allows you to write code using standard `np.*` syntax and have it run on either CPU or GPU seamlessly - **as long as CuPy implements an override for that function.**\n",
        "\n",
        "CuPy also protects you from hidden performance penalties: **it forbids implicit GPU → CPU copies**, raising a `TypeError` when NumPy tries to convert a `cupy.ndarray` into a `numpy.ndarray` behind the scenes. This ensures all device-to-host transfers are **explicit and intentional**, never silent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4f2863",
      "metadata": {},
      "outputs": [],
      "source": [
        "# We create the data on the GPU\n",
        "x_gpu = cp.random.random((1000, 1000))\n",
        "\n",
        "# BUT we call the standard NumPy function - CuPy dispatches it to the GPU!\n",
        "print_benchmark(benchmark(np.linalg.svd, (x_gpu,), n_repeat=5), device=\"gpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e37faae",
      "metadata": {},
      "source": [
        "## 4. Device Management\n",
        "\n",
        "If you have multiple GPUs, CuPy uses the concept of a \"Current Device\" context. \n",
        "\n",
        "You can use a `with` statement to ensure specific arrays are created on specific cards (e.g., GPU 0 vs GPU 1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26aa4f57",
      "metadata": {},
      "outputs": [],
      "source": [
        "with cp.cuda.Device(0):\n",
        "   x_on_gpu0 = cp.random.random((100000, 1000))\n",
        "\n",
        "print(f\"Array is on device: {x_on_gpu0.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32f7226a",
      "metadata": {},
      "source": [
        "**Note:** CuPy functions generally expect all input arrays to be on the **same** device. Passing an array stored on a non-current device may work depending on the hardware configuration but is generally discouraged as it may not be performant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e0a4a03",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2e341ff-0c1e-40e8-8c33-9e3039de8013",
      "metadata": {
        "id": "d2e341ff-0c1e-40e8-8c33-9e3039de8013"
      },
      "source": [
        "## Exercise - NumPy to CuPy\n",
        "\n",
        "### Part 1\n",
        "Let's put the \"Drop-in Replacement\" philosophy to the test with the same data pipeline as the previous notebook. Specifically, the single block of code below performs the following steps:\n",
        "1) Generate a massive dataset (50 million elements).\n",
        "2) Process it using a heavy operation (Sorting).\n",
        "3) Manipulate the shape and normalize the data (Broadcasting).\n",
        "4) Verify the integrity of the result.\n",
        "\n",
        "**TODO:**\n",
        "1. Run the cell below with `xp = np` (CPU Mode). Note the benchmark output.\n",
        "2. Change the setup line to `xp = cp` (GPU Mode). Run it again.\n",
        "3. Observe how the exact same logic runs significantly faster on the GPU with CuPy while retaining the implementation properties of NumPy.\n",
        "\n",
        "Note: We use `cupyx.profiler.benchmark` for timing, which automatically handles GPU synchronization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4596d8-d9ff-4c66-8822-246c0fc830c7",
      "metadata": {
        "id": "cc4596d8-d9ff-4c66-8822-246c0fc830c7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "from cupyx.profiler import benchmark\n",
        "\n",
        "# Re-defined here so this exercise cell is self-contained and can run independently.\n",
        "def print_benchmark(result, device=\"gpu\"):\n",
        "    \"\"\"Print benchmark result showing only the relevant time.\"\"\"\n",
        "    if device == \"gpu\":\n",
        "        avg_ms = result.gpu_times.mean() * 1000\n",
        "        std_ms = result.gpu_times.std() * 1000\n",
        "    else:\n",
        "        avg_ms = result.cpu_times.mean() * 1000\n",
        "        std_ms = result.cpu_times.std() * 1000\n",
        "    print(f\"  -> {result.name}: {avg_ms:.3f} ms +/- {std_ms:.3f} ms\")\n",
        "\n",
        "# --- 1. SETUP: CHOOSE YOUR DEVICE ---\n",
        "xp = np  # Toggle this to 'cp' for GPU acceleration\n",
        "\n",
        "print(f\"Running on: {xp.__name__.upper()}\")\n",
        "\n",
        "# --- 2. DATA GENERATION ---\n",
        "N = 50_000_000\n",
        "print(f\"Generating {N:,} random elements ({N*8/1e9:.2f} GB)...\")\n",
        "arr = xp.random.rand(N)\n",
        "\n",
        "# --- 3. HEAVY COMPUTATION (TIMED) ---\n",
        "print(\"Sorting data...\")\n",
        "# benchmark() handles GPU synchronization automatically\n",
        "result = benchmark(xp.sort, (arr,), n_repeat=5)\n",
        "print_benchmark(result, device=\"gpu\" if xp == cp else \"cpu\")\n",
        "\n",
        "# --- 4. MANIPULATION & BROADCASTING ---\n",
        "# Purpose: Demonstrate that CuPy supports complex reshaping and broadcasting rules exactly like NumPy.\n",
        "# This shows you don't need to rewrite your data processing logic.\n",
        "\n",
        "# Reshape to a matrix with 5 columns\n",
        "arr_new = arr.reshape((-1, 5))\n",
        "\n",
        "# Normalize: Divide every row by its sum using broadcasting\n",
        "row_sums = arr_new.sum(axis=1)\n",
        "normalized_matrix = arr_new / row_sums[:, xp.newaxis]\n",
        "\n",
        "# --- 5. VERIFICATION ---\n",
        "# Purpose: Verify mathematical correctness/integrity of the result.\n",
        "check_sums = xp.sum(normalized_matrix, axis=1)\n",
        "xp.testing.assert_allclose(check_sums, 1.0)\n",
        "\n",
        "print(\"  -> Verification: PASSED (All rows sum to 1.0)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077b7589",
      "metadata": {},
      "source": [
        "**TODO: When working with CuPy arrays, try changing `xp.testing.assert_allclose` to `np.testing.assert_allclose`. What happens and why?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AxU_hG5M-LKS",
      "metadata": {
        "id": "AxU_hG5M-LKS"
      },
      "source": [
        "### Part 2\n",
        "We will now create a massive dataset (50 million points) representing a sine wave and see how fast the GPU can sort it compared to the CPU. \n",
        "\n",
        "**TODO:** \n",
        "1) **Generate Data:** Create a NumPy array (`y_cpu`) and a CuPy array (`y_gpu`) representing $\\sin(x)$ from $0$ to $2\\pi$ with `50,000,000` points.\n",
        "2) **Benchmark CPU and GPU:** Use `benchmark()` from `cupyx.profiler` to measure both `np.sort` and `cp.sort`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EKwfS_iM9Yps",
      "metadata": {
        "id": "EKwfS_iM9Yps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "from cupyx.profiler import benchmark\n",
        "\n",
        "# --- Step 1: Generate Data ---\n",
        "N = 50_000_000\n",
        "print(f\"Generating {N} points...\")\n",
        "\n",
        "# TODO: Create x_cpu using np.linspace from 0 to 2*pi\n",
        "# TODO: Create y_cpu by taking np.sin(x_cpu)\n",
        "\n",
        "# TODO: Create x_gpu using cp.linspace from 0 to 2*pi\n",
        "# TODO: Create y_gpu by taking cp.sin(x_gpu)\n",
        "\n",
        "\n",
        "# --- Step 2: Benchmark NumPy (CPU) ---\n",
        "print(\"Benchmarking NumPy Sort (this may take a few seconds)...\")\n",
        "# TODO: Use benchmark(function, (args,), n_repeat=5)\n",
        "# Hint: Pass the function `np.sort` and the argument `(y_cpu,)`\n",
        "# Note: The comma in (y_cpu,) is required to make it a tuple!\n",
        "\n",
        "\n",
        "# --- Step 3: Benchmark CuPy (GPU) ---\n",
        "print(\"Benchmarking CuPy Sort...\")\n",
        "# TODO: Use benchmark(function, (args,), n_repeat=5)\n",
        "# Hint: Pass the function `cp.sort` and the argument `(y_gpu,)`\n",
        "# Note: The comma in (y_gpu,) is required to make it a tuple!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qnAvEk5QFAA8",
      "metadata": {
        "id": "qnAvEk5QFAA8"
      },
      "source": [
        "**EXTRA CREDIT: Benchmark with different array sizes and find the size at which CuPy and NumPy take the same amount of time. Try to extract the timing data from `cupyx.profiler.benchmark`'s return value and customize how the output is displayed. You could even make a graph.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42YwwyrJFTyV",
      "metadata": {
        "id": "42YwwyrJFTyV"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
