{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f966f67f",
      "metadata": {},
      "source": [
        "# Accelerated Computing with CuPy\n",
        "\n",
        "## Table of Contents\n",
        "1. [Creating Arrays: CPU vs. GPU](#1.-Creating-Arrays:-CPU-vs.-GPU)\n",
        "2. [Basic Operations](#2.-Basic-Operations)\n",
        "   - [Sequential Operations & Memory](#Sequential-Operations-&-Memory)\n",
        "3. [Complex Operations (Linear Algebra)](#3.-Complex-Operations-(Linear-Algebra))\n",
        "   - [Agnostic Code (NumPy Dispatch)](#Agnostic-Code-(NumPy-Dispatch))\n",
        "4. [Device Management](#4.-Device-Management)\n",
        "5. [Exercise - NumPy to CuPy](#Exercise---NumPy-to-CuPy)\n",
        "   - [Part 1](#Part-1)\n",
        "   - [Part 2](#Part-2)\n",
        "\n",
        "---\n",
        "\n",
        "Let's shift gears to high-level array functionality using **[CuPy](https://cupy.dev/)**.\n",
        "\n",
        "### What is CuPy?\n",
        "CuPy is a library that implements the familiar **NumPy API** but runs on the GPU (using CUDA C++ in the backend). \n",
        "\n",
        "**Why use it?**\n",
        "* **Zero Friction:** If you know NumPy, you already know CuPy.\n",
        "* **Speed:** It provides out-of-the-box GPU acceleration for array operations.\n",
        "* **Ease of use:** You can often port CPU code to GPU simply by changing `import numpy as np` to `import cupy as cp`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d369bcdc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "# Ensure the GPU is clean and ready\n",
        "cp.cuda.Stream.null.synchronize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c38845d",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15fc304c",
      "metadata": {},
      "source": [
        "## 1. Creating Arrays: CPU vs. GPU\n",
        "\n",
        "Let's compare the performance of creating a large 3D array (approx. 2GB in size) on the CPU versus the GPU.\n",
        "\n",
        "We will use `np.ones` for the CPU and `cp.ones` for the GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f8b002",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit -r 1 -n 10\n",
        "# CPU creation\n",
        "global x_cpu\n",
        "x_cpu = np.ones((1000, 500, 500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19309ca7",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit -n 10\n",
        "# GPU creation\n",
        "global x_gpu\n",
        "x_gpu = cp.ones((1000, 500, 500))\n",
        "\n",
        "# Force the CPU to wait for the GPU to finish before stopping the timer\n",
        "cp.cuda.Stream.null.synchronize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae637eaf",
      "metadata": {},
      "source": [
        "We can see here that creating this array on the GPU is much faster than doing so on the CPU! You also likely noticed the line `cp.cuda.Stream.null.synchronize()` in the code above. This is vital for accurate timing.\n",
        "\n",
        "**How CuPy works:**\n",
        "1.  When you call a CuPy function, the CPU places a task in the GPU's \"to-do list\" (stream).\n",
        "2.  The CPU immediately moves to the next line of code **without waiting** for the GPU to finish.\n",
        "3.  This is called **Asynchronous Execution**.\n",
        "\n",
        "If we didn't call `synchronize()`, the timer would stop as soon as the CPU issued the command. This would report a misleadingly fast time because it only measures how long it took to launch the task, not how long the GPU actually took to execute it. `synchronize()` forces the CPU to wait until the GPU has finished its work."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d179e9b",
      "metadata": {},
      "source": [
        "## 2. Basic Operations\n",
        "\n",
        "The syntax for mathematical operations is identical. Let's multiply every value in our arrays by `5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5bdefb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# CPU Operation\n",
        "x_cpu *= 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a7f32b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# GPU Operation\n",
        "x_gpu *= 5\n",
        "\n",
        "cp.cuda.Stream.null.synchronize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc24579f",
      "metadata": {},
      "source": [
        "The GPU completes this operation notably faster, with the code staying the same."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c69334",
      "metadata": {},
      "source": [
        "### Sequential Operations & Memory\n",
        "\n",
        "Now let's do a couple of operations sequentially, something which would suffer from memory transfer times in Numba examples without explicit memory management."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0294dbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# CPU: Sequential math\n",
        "x_cpu *= 5\n",
        "x_cpu *= x_cpu\n",
        "x_cpu += x_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acafdbe7",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# GPU: Sequential math\n",
        "x_gpu *= 5\n",
        "x_gpu *= x_gpu\n",
        "x_gpu += x_gpu\n",
        "\n",
        "cp.cuda.Stream.null.synchronize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f250bbb",
      "metadata": {},
      "source": [
        "The GPU ran that much faster even without us explicitly managing memory. This is because CuPy is handling all of this for us transparently."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84221268",
      "metadata": {},
      "source": [
        "## 3. Complex Operations (Linear Algebra)\n",
        "\n",
        "GPUs excel at Linear Algebra. Let's look at **Singular Value Decomposition (SVD)**, a computationally heavy $O(N^3)$ operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "978af795",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# CPU SVD\n",
        "x_cpu = np.random.random((1000, 1000))\n",
        "u, s, v = np.linalg.svd(x_cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0bc855b",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# GPU SVD\n",
        "x_gpu = cp.random.random((1000, 1000))\n",
        "u, s, v = cp.linalg.svd(x_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e298f0ea",
      "metadata": {},
      "source": [
        "The GPU outperforms the CPU again with exactly the same API!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0870d0",
      "metadata": {},
      "source": [
        "### Agnostic Code (NumPy Dispatch)\n",
        "\n",
        "A key feature of CuPy is that many **NumPy functions work on CuPy arrays without changing your code**.\n",
        "\n",
        "When you pass a CuPy GPU array (`x_gpu`) into a NumPy function that supports the `__array_function__` protocol (e.g., `np.linalg.svd`), NumPy detects the CuPy input and **delegates the operation to CuPy’s own implementation**, which runs on the GPU.\n",
        "\n",
        "This allows you to write code using standard `np.*` syntax and have it run on either CPU or GPU seamlessly - **as long as CuPy implements an override for that function.**\n",
        "\n",
        "CuPy also protects you from hidden performance penalties: **it forbids implicit GPU → CPU copies**, raising a `TypeError` when NumPy tries to convert a CuPy array into a NumPy array behind the scenes. This ensures all device-to-host transfers are **explicit and intentional**, never silent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4f2863",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# We create the data on the GPU\n",
        "x_gpu = cp.random.random((1000, 1000))\n",
        "\n",
        "# BUT we call the standard NumPy function\n",
        "u, s, v = np.linalg.svd(x_gpu)  \n",
        "\n",
        "cp.cuda.Stream.null.synchronize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e37faae",
      "metadata": {},
      "source": [
        "## 4. Device Management\n",
        "\n",
        "If you have multiple GPUs, CuPy uses the concept of a \"Current Device\" context. \n",
        "\n",
        "You can use a `with` statement to ensure specific arrays are created on specific cards (e.g., GPU 0 vs GPU 1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26aa4f57",
      "metadata": {},
      "outputs": [],
      "source": [
        "with cp.cuda.Device(0):\n",
        "   x_on_gpu0 = cp.random.random((100000, 1000))\n",
        "\n",
        "print(f\"Array is on device: {x_on_gpu0.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32f7226a",
      "metadata": {},
      "source": [
        "**Note:** CuPy functions generally expect all input arrays to be on the **same** device. Passing an array stored on a non-current device may work depending on the hardware configuration but is generally discouraged as it may not be performant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e0a4a03",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2e341ff-0c1e-40e8-8c33-9e3039de8013",
      "metadata": {
        "id": "d2e341ff-0c1e-40e8-8c33-9e3039de8013"
      },
      "source": [
        "## Exercise - NumPy to CuPy\n",
        "\n",
        "### Part 1\n",
        "Let's put the \"Drop-in Replacement\" philosophy to the test with the same data pipeline as the previous notebook. Specficially, the single block of code below performs the following steps:\n",
        "1) Generate a massive dataset (50 million elements).\n",
        "2) Process it using a heavy operation (Sorting).\n",
        "3) Manipulate the shape and normalize the data (Broadcasting).\n",
        "4) Verify the integrity of the result.\n",
        "\n",
        "**TODO:**\n",
        "1. Run the cell below with xp = np (CPU Mode). Note the \"Sort Time\".\n",
        "2. Change the setup line to xp = cp (GPU Mode). Run it again.\n",
        "3. Observe how the exact same logic runs significantly faster on the GPU with CuPy while retaining the implementation properties of NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4596d8-d9ff-4c66-8822-246c0fc830c7",
      "metadata": {
        "id": "cc4596d8-d9ff-4c66-8822-246c0fc830c7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import time\n",
        "\n",
        "# --- 1. SETUP: CHOOSE YOUR DEVICE ---\n",
        "xp = np  # Toggle this to 'cp' for GPU acceleration\n",
        "\n",
        "print(f\"Running on: {xp.__name__.upper()}\")\n",
        "\n",
        "# --- 2. DATA GENERATION ---\n",
        "N = 50_000_000\n",
        "print(f\"Generating {N:,} random elements ({N*8/1e9:.2f} GB)...\")\n",
        "arr = xp.random.rand(N)\n",
        "\n",
        "# --- 3. HEAVY COMPUTATION (TIMED) ---\n",
        "print(\"Sorting data...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "xp.sort(arr)\n",
        "\n",
        "# Ensure GPU finishes before stopping timer\n",
        "if xp == cp:\n",
        "    cp.cuda.Stream.null.synchronize()\n",
        "\n",
        "t1 = time.perf_counter()\n",
        "print(f\"  -> Sort Time: {t1 - t0:.4f} seconds\")\n",
        "\n",
        "# --- 4. MANIPULATION & BROADCASTING ---\n",
        "# Purpose: Demonstrate that CuPy supports complex reshaping and broadcasting rules exactly like NumPy.\n",
        "# This shows you don't need to rewrite your data processing logic.\n",
        "\n",
        "# Reshape to a matrix with 5 columns\n",
        "arr_new = arr.reshape((-1, 5))\n",
        "\n",
        "# Normalize: Divide every row by its sum using broadcasting\n",
        "row_sums = arr_new.sum(axis=1)\n",
        "normalized_matrix = arr_new / row_sums[:, xp.newaxis]\n",
        "\n",
        "# --- 5. VERIFICATION ---\n",
        "# Purpose: Verify mathematical correctness/integrity of the result.\n",
        "check_sums = xp.sum(normalized_matrix, axis=1)\n",
        "xp.testing.assert_allclose(check_sums, 1.0)\n",
        "\n",
        "print(\"  -> Verification: PASSED (All rows sum to 1.0)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077b7589",
      "metadata": {},
      "source": [
        "**TODO: When working with CuPy arrays, try changing `xp.testing.assert_allclose` to `np.testing.assert_allclose`. What happens and why?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AxU_hG5M-LKS",
      "metadata": {
        "id": "AxU_hG5M-LKS"
      },
      "source": [
        "### Part 2\n",
        "We will now create a massive dataset (50 million points) representing a sine wave and see how fast the GPU can sort it compared to the CPU. \n",
        "\n",
        "**TODO:** \n",
        "1) **Generate Data:** Create a NumPy array (`y_cpu`) and a CuPy array (`y_gpu`) representing $\\sin(x)$ from $0$ to $2\\pi$ with `50,000,000` points.\n",
        "2) **Benchmark CPU and GPU:** Use `cupyx.profiler.benchmark` to measure both `np.sort` and `cp.sort`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EKwfS_iM9Yps",
      "metadata": {
        "id": "EKwfS_iM9Yps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import cupyx.profiler\n",
        "\n",
        "# --- Step 1: Generate Data ---\n",
        "N = 50_000_000\n",
        "print(f\"Generating {N} points...\")\n",
        "\n",
        "# TODO: Create x_cpu using np.linspace from 0 to 2*pi\n",
        "# TODO: Create y_cpu by taking np.sin(x_cpu)\n",
        "\n",
        "# TODO: Create x_gpu using cp.linspace from 0 to 2*pi\n",
        "# TODO: Create y_gpu by taking cp.sin(x_gpu)\n",
        "\n",
        "\n",
        "# --- Step 2: Benchmark NumPy (CPU) ---\n",
        "print(\"Benchmarking NumPy Sort (this may take a few seconds)...\")\n",
        "# TODO: Use cupyx.profiler.benchmark(function, (args,), n_repeat=5)\n",
        "# Hint: Pass the function `np.sort` and the argument `(y_cpu,)`\n",
        "# Note: The comma in (y_cpu,) is required to make it a tuple!\n",
        "\n",
        "\n",
        "# --- Step 3: Benchmark CuPy (GPU) ---\n",
        "print(\"Benchmarking CuPy Sort...\")\n",
        "# TODO: Use cupyx.profiler.benchmark(function, (args,), n_repeat=5)\n",
        "# Hint: Pass the function `cp.sort` and the argument `(y_gpu,)`\n",
        "# Note: The comma in (y_gpu,) is required to make it a tuple!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qnAvEk5QFAA8",
      "metadata": {
        "id": "qnAvEk5QFAA8"
      },
      "source": [
        "**EXTRA CREDIT: Benchmark with different array sizes and find the size at which CuPy and NumPy take the same amount of time. Try to extract the timing data from `cupyx.profiler.benchmark`'s return value and customize how the output is displayed. You could even make a graph.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42YwwyrJFTyV",
      "metadata": {
        "id": "42YwwyrJFTyV"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (RAPIDS 25.10)",
      "language": "python",
      "name": "cudf-cu12-25.10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
