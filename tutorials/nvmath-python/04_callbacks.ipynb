{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af897c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0 AND CC-BY-NC-4.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1067bad8",
   "metadata": {},
   "source": [
    "<img src=\"./images/nvmath_head_panel@0.5x.png\" alt=\"nvmath-python\" />\n",
    "\n",
    "# Getting Started with nvmath-python: FFT Callbacks\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook introduces FFT callbacks in **nvmath-python**, which allow custom Python functions to be just-in-time (JIT) compiled and fused with FFT operations. This advanced feature enables significant performance improvements by combining multiple operations into a single kernel.\n",
    "\n",
    "**Learning Objectives:**\n",
    "* Understand what FFT callbacks are and how they work\n",
    "* Write custom epilog functions for FFT operations\n",
    "* Use `nvmath.fft.compile_epilog` to JIT-compile callback functions\n",
    "* Apply FFT callbacks to a real-world image processing problem (Gaussian filtering)\n",
    "* Benchmark performance improvements from kernel fusion with callbacks\n",
    "* Use stateful FFT APIs to amortize JIT compilation costs across multiple executions\n",
    "* Analyze the cost breakdown of compilation, planning, and execution phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d34b2",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction\n",
    "\n",
    "FFT callbacks are a powerful feature of **nvmath-python** that enables kernel fusion for FFT operations. Callbacks are custom Python functions that are *just-in-time (JIT)* compiled into *intermediate representation (LTO-IR)* and provided as *prolog* or *epilog* arguments to FFT functions. This allows you to fuse custom operations with FFT kernels, dramatically improving performance by:\n",
    "\n",
    "1. **Eliminating intermediate memory allocations**: Data doesn't need to be written to memory between FFT and the custom operation\n",
    "2. **Reducing kernel launch overhead**: Multiple operations are combined into a single kernel\n",
    "3. **Improving arithmetic intensity**: The fused kernel can better utilize GPU resources\n",
    "\n",
    "This notebook demonstrates FFT callbacks through a practical image processing example: implementing a Gaussian blur filter using FFT convolution.\n",
    "\n",
    "**Prerequisites:** To use this notebook, you will need:\n",
    "- A computer equipped with an NVIDIA GPU\n",
    "- An environment with properly installed Python libraries\n",
    "- Completion of previous notebooks (recommended)\n",
    "- Understanding of FFT concepts and image processing basics\n",
    "\n",
    "For detailed installation instructions, please refer to the [nvmath-python documentation](https://docs.nvidia.com/cuda/nvmath-python/latest/installation.html#install-nvmath-python).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a872184",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook uses the same benchmarking helper function from previous notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupyx as cpx\n",
    "\n",
    "\n",
    "# Helper function to benchmark two implementations F and (optionally) F_alternative\n",
    "# When F_alternative is provided, in addition to raw performance numbers (seconds)\n",
    "# speedup of F relative to F_alternative is reported\n",
    "def benchmark(\n",
    "    F, F_name=\"Implementation\", F_alternative=None, F_alternative_name=\"Alternative implementation\", n_repeat=10, n_warmup=1\n",
    "):\n",
    "    timing = cpx.profiler.benchmark(F, n_repeat=n_repeat, n_warmup=n_warmup)  # warm-up + repeated runs\n",
    "    perf = np.min(timing.gpu_times)  # best time from repeated runs\n",
    "    print(f\"{F_name} performance = {perf:0.4f} sec\")\n",
    "\n",
    "    if F_alternative is not None:\n",
    "        timing_alt = cpx.profiler.benchmark(F_alternative, n_repeat=n_repeat, n_warmup=n_warmup)\n",
    "        perf_alt = np.min(timing_alt.gpu_times)\n",
    "        print(f\"{F_alternative_name} performance = {perf_alt:0.4f} sec\")\n",
    "        print(f\"Speedup = {perf_alt / perf:0.4f}x\")\n",
    "    else:\n",
    "        perf_alt = None\n",
    "\n",
    "    return perf, perf_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68815a46",
   "metadata": {},
   "source": [
    "It also leverages a few other Python libraries that have to be additionally installed:\n",
    "\n",
    "```bash\n",
    "pip install scipy\n",
    "pip install matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223f8f3",
   "metadata": {},
   "source": [
    "---\n",
    "## Image Processing Example: Gaussian Filtering\n",
    "\n",
    "In this notebook, we explore a typical image processing problem: applying a Gaussian filter to an image. The Gaussian filter is widely used for image blurring and noise reduction.\n",
    "\n",
    "### Baseline Implementation with SciPy\n",
    "\n",
    "The following code implements a Gaussian filter using the [`scipy.ndimage`](https://docs.scipy.org/doc/scipy/reference/ndimage.html) library, which provides a convenient CPU-based implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90be84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "asset_path = \"./images/\"\n",
    "img = Image.open(asset_path + \"dog.jpg\").convert(\"L\") # Load the image and convert it to grayscale\n",
    "original_image = np.array(img, dtype=np.float32) / 255.0 # Convert the image to a float array and normalize it to [0, 1]\n",
    "\n",
    "sigma_value = 20.0  # Filter size\n",
    "\n",
    "filtered_image_scipy = gaussian_filter(original_image, sigma=sigma_value)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(filtered_image_scipy, cmap=\"gray\")\n",
    "plt.title(\"Filtered (SciPy)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78383cf",
   "metadata": {},
   "source": [
    "### GPU Implementation with CuPy\n",
    "\n",
    "Next, we implement the Gaussian filter using CuPy's 2D forward and inverse FFT, applying the filter (frequency response) in the frequency domain.\n",
    "\n",
    "The frequency response is implemented in the `create_gaussian_filter()` function, which leverages the mathematical property that the Fourier transform of a Gaussian distribution in the *spatial domain* corresponds to another Gaussian distribution in the *frequency domain* (and vice versa).\n",
    "\n",
    "**Implementation Details:**\n",
    "- The original image is loaded as a [NumPy](https://numpy.org/) array in CPU memory\n",
    "- We convert the image to a [CuPy](https://cupy.dev/) array to perform computations on the GPU\n",
    "- Forward FFT transforms the image to the frequency domain\n",
    "- We apply the Gaussian filter by element-wise multiplication\n",
    "- Inverse FFT transforms back to the spatial domain\n",
    "- The result is converted back to CPU memory for visualization with [`matplotlib`](https://matplotlib.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd444cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvmath  # Preload CTK libraries installed from wheels for CuPy\n",
    "import cupy as cp\n",
    "\n",
    "\n",
    "image_gpu = cp.asarray(original_image, dtype=cp.float32) \n",
    "\n",
    "fy = cp.fft.fftfreq(image_gpu.shape[0])[:, None].astype(cp.float32)\n",
    "fx = cp.fft.rfftfreq(image_gpu.shape[1])[None, :].astype(cp.float32)\n",
    "h = cp.exp(-2.0 * cp.pi * cp.pi * sigma_value * sigma_value * (fx * fx + fy * fy)).astype(cp.complex64)\n",
    "\n",
    "\n",
    "def gaussian_filter_cupy(image, clear_cache=True):\n",
    "    \"\"\"\n",
    "    Apply Gaussian filter using CuPy R2C/C2R FFT.\n",
    "    \"\"\"\n",
    "    if clear_cache:\n",
    "        cp.fft.config.clear_plan_cache()  # Clear CuPy FFT cache to ensure clean FFT benchmarking\n",
    "    image_fft = cp.fft.rfft2(image)  # Real to complex FFT\n",
    "    filtered = cp.fft.irfft2(image_fft * h)  # Complex to real FFT\n",
    "    return filtered\n",
    "\n",
    "filtered_image_cupy = gaussian_filter_cupy(image_gpu)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cp.asnumpy(filtered_image_cupy), cmap=\"gray\")\n",
    "plt.title(\"Filtered (CuPy)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de5f6e",
   "metadata": {},
   "source": [
    "### GPU Implementation with nvmath-python and FFT Callbacks\n",
    "\n",
    "Now we implement the Gaussian filter using **nvmath-python**'s forward and inverse FFTs with a fused epilog callback. \n",
    "\n",
    "**Key Difference from CuPy Implementation:**\n",
    "- The Gaussian kernel multiplication (previously a separate operation) is now compiled as an `epilog_impl` function into intermediate representation (LTO-IR)\n",
    "- This epilog is fused with the forward FFT operation\n",
    "- The fused kernel improves *arithmetic intensity* by eliminating intermediate memory operations\n",
    "- There is a one-time JIT compilation cost that can be amortized over multiple executions\n",
    "\n",
    "The epilog function multiplies the FFT output with the Gaussian filter and performs normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter_nvmath(image):\n",
    "    wh = image.shape[0] * image.shape[1] # In nvmath-python FFT must be explicitly normalized\n",
    "\n",
    "    # Define epilog function for gaussian kernel multiplication\n",
    "    def epilog_impl(data_out, offset, data, filter_data, unused):\n",
    "            data_out[offset] = data * filter_data[offset] / wh  # Normalize by the image area\n",
    "\n",
    "    # Compile the epilog to LTO-IR\n",
    "    epilog = nvmath.fft.compile_epilog(epilog_impl, \"complex64\", \"complex64\")\n",
    "\n",
    "    # Compute R2C FFT using nvmath with epilog to apply gaussian kernel multiplication\n",
    "    image_fft = nvmath.fft.rfft(image, epilog={\"ltoir\": epilog, \"data\": h.data.ptr})\n",
    "\n",
    "    # Inverse C2R FFT using nvmath\n",
    "    filtered = nvmath.fft.irfft(image_fft)\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n",
    "image_gpu = cp.asarray(original_image, dtype=cp.float32)\n",
    "filtered_image_nvmath = gaussian_filter_nvmath(image_gpu)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cp.asnumpy(filtered_image_nvmath), cmap=\"gray\")\n",
    "plt.title(\"Filtered (nvmath-python)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57095f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    lambda: gaussian_filter_nvmath(image_gpu),\n",
    "    \"nvmath-python API\",\n",
    "    lambda: gaussian_filter_cupy(image_gpu),\n",
    "    \"CuPy API\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115d2e1",
   "metadata": {},
   "source": [
    "---\n",
    "## Stateful FFT APIs for Batch Processing\n",
    "\n",
    "The **nvmath-python** library provides both *stateless* and *stateful* APIs for FFT, allowing you to separate the *planning* phase (including expensive JIT compilation of the epilog) from the *execution* phase. This enables you to amortize the planning cost through multiple executions.\n",
    "\n",
    "To illustrate this, let us consider the problem of applying the Gaussian filter to multiple images in a batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "images_gpu = [image_gpu] * batch_size\n",
    "\n",
    "# Display the array of identical images\n",
    "plt.figure(figsize=(30, 3))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(1, batch_size, i + 1)\n",
    "    plt.imshow(cp.asnumpy(images_gpu[i]), cmap=\"gray\")\n",
    "    plt.title(f\"Dog {i + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b589fc2",
   "metadata": {},
   "source": [
    "### CuPy Batch Implementation\n",
    "\n",
    "First, we create a reference implementation of the batched Gaussian filter using pure CuPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_cupy(images_gpu):\n",
    "    # Clear CuPy FFT cache to ensure clean FFT benchmarking during multiple repetitions (n_repeat > 1)\n",
    "    # For fair comparison, we do not want the planning cost of the first call to be ignored\n",
    "    cp.fft.config.clear_plan_cache()\n",
    "    filtered_images = []\n",
    "    for i in range(len(images_gpu)):\n",
    "        filtered_images.append(gaussian_filter_cupy(images_gpu[i], clear_cache=False))\n",
    "    return filtered_images\n",
    "\n",
    "\n",
    "filtered_images = process_batch_cupy(images_gpu)\n",
    "\n",
    "plt.figure(figsize=(30, 3))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(1, batch_size, i + 1)\n",
    "    plt.imshow(cp.asnumpy(filtered_images[i]), cmap=\"gray\")\n",
    "    plt.title(f\"Filtered {i + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90d189",
   "metadata": {},
   "source": [
    "### nvmath-python Batch Implementation with Stateful APIs\n",
    "\n",
    "Next, we implement the same logic using **nvmath-python**'s stateful API:\n",
    "\n",
    "**Implementation Strategy:**\n",
    "- Create two FFT objects: one for the forward FFT plan (which includes a compiled epilog) and another for the inverse FFT plan\n",
    "- We need two separate objects because a single object can only have one plan\n",
    "- Apply the filter to each image in the batch through a series of forward and inverse FFTs\n",
    "- Use the `reset_operand()` method to update operands for chained FFT operations\n",
    "\n",
    "**Key Benefits:**\n",
    "- The epilog compilation happens once\n",
    "- FFT plans are created once and reused for all images\n",
    "- Only execution is repeated for each image in the batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6549247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_nvmath(images_gpu):\n",
    "    wh = images_gpu[0].shape[0] * images_gpu[0].shape[1] # Normalization factor\n",
    "\n",
    "\n",
    "    # Define epilog function for gaussian kernel multiplication\n",
    "    def epilog_impl(data_out, offset, data, filter_data, unused):\n",
    "        data_out[offset] = data * filter_data[offset] / wh\n",
    "\n",
    "\n",
    "    # Compile the epilog to LTO-IR once\n",
    "    epilog = nvmath.fft.compile_epilog(epilog_impl, \"complex64\", \"complex64\")\n",
    "\n",
    "\n",
    "    def convolve_image_gpu(fft, ifft, image_gpu):\n",
    "        fft.reset_operand(image_gpu)\n",
    "        image_fft = fft.execute(direction=nvmath.fft.FFTDirection.FORWARD)\n",
    "        ifft.reset_operand(image_fft)\n",
    "        image_ifft = ifft.execute(direction=nvmath.fft.FFTDirection.INVERSE)\n",
    "        return image_ifft\n",
    "\n",
    "\n",
    "    image_gpu = images_gpu[0]  # Real input for R2C FFT\n",
    "    image_fft = cp.empty((image_gpu.shape[0], image_gpu.shape[1] // 2 + 1), dtype=cp.complex64)\n",
    "\n",
    "    with (\n",
    "        nvmath.fft.FFT(image_gpu) as fft,\n",
    "        nvmath.fft.FFT(image_fft, options={\"fft_type\": \"C2R\"}) as ifft,\n",
    "    ):\n",
    "        # Two plans are created, one for the forward R2C FFT with an epilog\n",
    "        # and another for the inverse C2R FFT\n",
    "        fft.plan(epilog={\"ltoir\": epilog, \"data\": h.data.ptr})\n",
    "        ifft.plan()\n",
    "\n",
    "        # Process each image in the batch\n",
    "        filtered_images = []\n",
    "        for i in range(len(images_gpu)):\n",
    "            filtered_images.append(convolve_image_gpu(fft, ifft, images_gpu[i]))\n",
    "    return filtered_images\n",
    "\n",
    "\n",
    "# Process the batch using nvmath stateful API\n",
    "filtered_images_nvmath = process_batch_nvmath(images_gpu)\n",
    "\n",
    "plt.figure(figsize=(30, 3))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(1, batch_size, i + 1)\n",
    "    plt.imshow(cp.asnumpy(filtered_images_nvmath[i]), cmap=\"gray\")\n",
    "    plt.title(f\"Filtered {i + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa2378",
   "metadata": {},
   "source": [
    "### Performance Comparison\n",
    "\n",
    "Now let's benchmark the performance. \n",
    "\n",
    "**Important Notes:**\n",
    "- CuPy inherently performs FFT plan *caching*, so subsequent calls with images of the same shape and dtype avoid re-planning overhead\n",
    "- With **nvmath-python**, we avoid re-planning explicitly by using *stateful* APIs\n",
    "- Both approaches benefit from amortizing planning costs, but the fused epilog in **nvmath-python** provides additional performance improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear CuPy FFT cache to ensure clean FFT operations\n",
    "cp.fft.config.clear_plan_cache()\n",
    "benchmark(\n",
    "    lambda: process_batch_nvmath(images_gpu),\n",
    "    \"nvmath-python stateful API\",\n",
    "    lambda: process_batch_cupy(images_gpu),\n",
    "    \"CuPy API\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d79f92",
   "metadata": {},
   "source": [
    "---\n",
    "## Performance Cost Breakdown\n",
    "\n",
    "Let us drill down to understand how much each phase costs in each library. For CuPy, the cost of the very first call (where FFT planning and plan caching is performed) is very different from subsequent calls (where the cached plan is reused).\n",
    "\n",
    "### CuPy Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827de35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cupy_first_call(image_gpu):\n",
    "    # To emulate the cost of the first call we need to clear the cache\n",
    "    cp.fft.config.clear_plan_cache()\n",
    "    gaussian_filter_cupy(image_gpu, clear_cache=False)\n",
    "\n",
    "def process_cupy_subsequent_call(image_gpu):\n",
    "    # With n_repeat > 1 the first call cost will be ignored\n",
    "    gaussian_filter_cupy(image_gpu, clear_cache=False)\n",
    "\n",
    "perf_cupy_subsequent_call, perf_cupy_first_call = benchmark(\n",
    "    lambda: process_cupy_subsequent_call(image_gpu),\n",
    "    \"CuPy subsequent calls\",\n",
    "    lambda: process_cupy_first_call(image_gpu),\n",
    "    \"CuPy first call\",\n",
    ")\n",
    "\n",
    "perf_cupy_planning = perf_cupy_first_call - perf_cupy_subsequent_call\n",
    "print(f\"Estimated CuPy planning cost = {perf_cupy_planning:0.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf370d",
   "metadata": {},
   "source": [
    "### nvmath-python Cost Analysis\n",
    "\n",
    "Similarly, let's break down the costs within the **nvmath-python** implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = image_gpu.shape[0] * image_gpu.shape[1] # Normalization factor\n",
    "# Define epilog function for gaussian kernel multiplication\n",
    "def epilog_impl(data_out, offset, data, filter_data, unused):\n",
    "    data_out[offset] = data * filter_data[offset] / wh  # Normalize by the image area\n",
    "\n",
    "# Compile the epilog to LTO-IR once\n",
    "def compile_epilog():\n",
    "    return nvmath.fft.compile_epilog(epilog_impl, \"complex64\", \"complex64\")\n",
    "\n",
    "def forward_fft_execute(fft, image_gpu):\n",
    "    fft.reset_operand(image_gpu)\n",
    "    return fft.execute(direction=nvmath.fft.FFTDirection.FORWARD)\n",
    "\n",
    "def inverse_fft_execute(ifft, image_gpu):\n",
    "    ifft.reset_operand(image_gpu)\n",
    "    return ifft.execute(direction=nvmath.fft.FFTDirection.INVERSE)\n",
    "\n",
    "def forward_fft_plan(image_gpu, epilog):\n",
    "    fft = nvmath.fft.FFT(image_gpu)\n",
    "    fft.plan(epilog={\"ltoir\": epilog, \"data\": h.data.ptr})\n",
    "    return fft\n",
    "\n",
    "def inverse_fft_plan(c2r_output):\n",
    "    ifft = nvmath.fft.FFT(c2r_output, options={\"fft_type\": \"C2R\"})\n",
    "    ifft.plan()\n",
    "    return ifft\n",
    "\n",
    "epilog = compile_epilog()\n",
    "c2r_output = cp.empty((image_gpu.shape[0], image_gpu.shape[1] // 2 + 1), dtype=cp.complex64)\n",
    "fft = forward_fft_plan(image_gpu, epilog)\n",
    "ifft = inverse_fft_plan(c2r_output)\n",
    "fft_image = forward_fft_execute(fft, image_gpu)\n",
    "filtered_image = inverse_fft_execute(ifft, fft_image)\n",
    "\n",
    "perf_compile_epilog = cpx.profiler.benchmark(lambda: compile_epilog(), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "perf_forward_fft_plan = cpx.profiler.benchmark(lambda: forward_fft_plan(image_gpu, epilog), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "perf_inverse_fft_plan = cpx.profiler.benchmark(lambda: inverse_fft_plan(c2r_output), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "perf_forward_fft_execute = cpx.profiler.benchmark(lambda: forward_fft_execute(fft, image_gpu), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "perf_inverse_fft_execute = cpx.profiler.benchmark(lambda: inverse_fft_execute(ifft, fft_image), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "\n",
    "print(f\"Compilation cost = {perf_compile_epilog:0.4f} sec\")\n",
    "print(f\"Forward FFT plan cost = {perf_forward_fft_plan:0.4f} sec\")\n",
    "print(f\"Inverse FFT plan cost = {perf_inverse_fft_plan:0.4f} sec\")\n",
    "print(f\"Forward FFT execute cost = {perf_forward_fft_execute:0.4f} sec\")\n",
    "print(f\"Inverse FFT execute cost = {perf_inverse_fft_execute:0.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fc754",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cost per Image Analysis\n",
    "\n",
    "# Plot CuPy and nvmath-python cost per image for batch sizes 1 to 16\n",
    "batch_sizes = np.arange(1, 17)\n",
    "\n",
    "# CuPy: First image includes planning + execution, subsequent images are execution only\n",
    "cupy_costs_per_image = [(perf_cupy_first_call + (n - 1) * perf_cupy_subsequent_call) / n for n in batch_sizes]\n",
    "\n",
    "# nvmath-python: First image includes compilation + planning + execution, subsequent images are execution only\n",
    "nvmath_costs_per_image = [(perf_compile_epilog + perf_forward_fft_plan + perf_inverse_fft_plan) / n + perf_forward_fft_execute + perf_inverse_fft_execute for n in batch_sizes]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes, cupy_costs_per_image, marker='o', linewidth=2, markersize=8, color='darkgreen', label='CuPy')\n",
    "plt.plot(batch_sizes, nvmath_costs_per_image, marker='s', linewidth=2, markersize=8, color='#76b900', label='nvmath-python')\n",
    "plt.xlabel('Number of Images', fontsize=12)\n",
    "plt.ylabel('Cost per Image (seconds)', fontsize=12)\n",
    "plt.title('Cost per Image Comparison: CuPy vs nvmath-python\\n(First image includes planning/compilation + execution, subsequent images execution only)', fontsize=13)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(batch_sizes)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(\"CuPy Cost Breakdown:\")\n",
    "print(f\"  Planning cost: {perf_cupy_planning:.4f} sec\")\n",
    "print(f\"  Execution cost (per image): {perf_cupy_subsequent_call:.4f} sec\")\n",
    "print(f\"  First image total: {perf_cupy_first_call:.4f} sec\")\n",
    "\n",
    "print(\"\\nnvmath-python Cost Breakdown:\")\n",
    "print(f\"  Compilation cost: {perf_compile_epilog:.4f} sec\")\n",
    "print(f\"  Forward FFT plan cost: {perf_forward_fft_plan:.4f} sec\")\n",
    "print(f\"  Inverse FFT plan cost: {perf_inverse_fft_plan:.4f} sec\")\n",
    "print(f\"  Execution cost (per image): {perf_forward_fft_execute + perf_inverse_fft_execute:.4f} sec\")\n",
    "print(f\"  First image total: {perf_compile_epilog + perf_forward_fft_plan + perf_inverse_fft_plan + perf_forward_fft_execute + perf_inverse_fft_execute:.4f} sec\")\n",
    "\n",
    "print(\"\\nCost per image comparison:\")\n",
    "for n in [1, 4, 8, 16]:\n",
    "    cupy_per_img = cupy_costs_per_image[n-1]\n",
    "    nvmath_per_img = nvmath_costs_per_image[n-1]\n",
    "    speedup = cupy_per_img / nvmath_per_img\n",
    "    print(f\"  {n:2d} images: CuPy={cupy_per_img:.4f} sec/img, nvmath={nvmath_per_img:.4f} sec/img, speedup={speedup:.2f}x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aaa70c",
   "metadata": {},
   "source": [
    "## Exercise: Applying Sepia and Gaussian blur filters to an image\n",
    "\n",
    "In this exercise you will perform the following steps:\n",
    "1. Load the color image using `PIL`.\n",
    "2. Create and compile the *Sepia* filter for the R2C FFT prolog \n",
    "3. Create and compile the *Gaussian Blur* filter for the C2R FFT prolog.\n",
    "4. Perform forward FFT with the compiled Sepia filter prolog.\n",
    "5. Perform backward C2R FFT with the compiled Gaussian Blur filter prolog.\n",
    "6. Display the processed image using `matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022c9cb",
   "metadata": {},
   "source": [
    "The following NumPy implementation is a reference code for you to follow while implementing nvmath-python variant with forward FFT prolog and epilog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f558b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Load the color image using PIL\n",
    "# Load the color image and convert it to NumPyarray normalized to [0, 1]\n",
    "asset_path = \"./images/\"\n",
    "original_image = np.array(Image.open(asset_path + \"dog.jpg\")) / 255.0\n",
    "\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(original_image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "original_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419cae6c",
   "metadata": {},
   "source": [
    "Note the shape of the array: spatial data goes in dimensions 0 and 1, followed by color channels data.\n",
    "\n",
    "The following code is a reference implementation of the Sepia filter, which is a color matrix transformation applied to original pixels capped by 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEPIA_FILTER_MATRIX = np.array([\n",
    "    [0.393, 0.769, 0.189],\n",
    "    [0.349, 0.686, 0.168],\n",
    "    [0.272, 0.534, 0.131]\n",
    "]).T\n",
    "\n",
    "\n",
    "def sepia_filter(image):\n",
    "    \"\"\"\n",
    "    Apply sepia filter to the image.\n",
    "    Image shape: (height, width, 3)\n",
    "    Returns: (height, width, 3)\n",
    "    \"\"\"\n",
    "    # Apply filter: (height*width, 3) @ (3, 3) = (height*width, 3)\n",
    "    return np.minimum(1.0, image @ SEPIA_FILTER_MATRIX)\n",
    "\n",
    "\n",
    "sepia_image = sepia_filter(original_image)\n",
    "\n",
    "# Display the sepia image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(sepia_image)\n",
    "plt.title(\"Sepia Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f81bc",
   "metadata": {},
   "source": [
    "Finally we apply Gaussian Blur filter implemented through R2C and C2R FFTs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 20.0\n",
    "fy = np.fft.fftfreq(sepia_image.shape[0])[:, None]  # column vector\n",
    "fx = np.fft.rfftfreq(sepia_image.shape[1])[None, :]  # row vector for R2C (only positive frequencies)\n",
    "h = np.exp(-2.0 * np.pi * np.pi * sigma * sigma * (fx * fx + fy * fy)).astype(np.complex64)\n",
    "print(h.shape)\n",
    "\n",
    "\n",
    "def gaussian_filter_numpy(image):\n",
    "    # Apply FFT on spatial dimensions (axes 0 and 1), leaving color channel intact\n",
    "    image_fft = np.fft.rfft2(image, axes=(0, 1))  # Real to complex FFT\n",
    "    blurred = np.fft.irfft2(image_fft * h[..., None], axes=(0, 1))  # Complex to real FFT\n",
    "    return blurred\n",
    "\n",
    "blurred_image = gaussian_filter_numpy(sepia_image)\n",
    "\n",
    "# Display the blurred image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(blurred_image)\n",
    "plt.title(\"Sepia & Blurred Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db0788",
   "metadata": {},
   "source": [
    "Note the shape of `h`: for R2C FFT we neeed only positive frequences, hence the size in `fx` dimension is `image.shape[1] // 2 + 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4bea2",
   "metadata": {},
   "source": [
    "Now porting the NumPy implementation to GPU with CuPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ea87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvmath # Workaround for CuPy: CTK shared objects preload from wheels\n",
    "import cupy as cp\n",
    "\n",
    "image_gpu = cp.asarray(original_image, dtype=cp.float32)\n",
    "SEPIA_FILTER_MATRIX_GPU = cp.asarray(SEPIA_FILTER_MATRIX).astype(cp.float32)\n",
    "\n",
    "\n",
    "def sepia_filter(image):\n",
    "    return cp.minimum(1.0, image @ SEPIA_FILTER_MATRIX_GPU)\n",
    "\n",
    "\n",
    "sepia_image = sepia_filter(image_gpu)\n",
    "\n",
    "# Display the sepia image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(sepia_image.get())\n",
    "plt.title(\"Sepia Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 20.0\n",
    "fy = cp.fft.fftfreq(sepia_image.shape[0])[:, None].astype(cp.float32)  # column vector\n",
    "fx = cp.fft.rfftfreq(sepia_image.shape[1])[None, :].astype(cp.float32)  # row vector for R2C (only positive frequencies)\n",
    "h = cp.exp(-2.0 * np.pi * np.pi * sigma * sigma * (fx * fx + fy * fy)).astype(cp.complex64)\n",
    "\n",
    "\n",
    "def gaussian_filter_cupy(image):\n",
    "    # Apply FFT on spatial dimensions (axes 0 and 1), leaving color channel intact\n",
    "    image_fft = cp.fft.rfft2(image, axes=(0, 1))  # Real to complex FFT\n",
    "    blurred = cp.fft.irfft2(image_fft * h[..., None], axes=(0, 1))  # Complex to real FFT\n",
    "    return blurred\n",
    "\n",
    "blurred_image = gaussian_filter_cupy(sepia_image)\n",
    "\n",
    "# Display the blurred image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(blurred_image.get())\n",
    "plt.title(\"Sepia & Blurred Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2afb1",
   "metadata": {},
   "source": [
    "Finally, we get to implement the above code using **nvmath-python** with compiled prolog and epilog functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d457351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER:Dimensions over which FFT is performed must be contiguous in memory.\n",
    "# Hint: Rearrange the dimensions so that spatial data is contiguous\n",
    "\n",
    "# 1. Copy original image to GPU and rearrange dimensions so that spatial data is contiguous\n",
    "# TODO: Implement this step\n",
    "\n",
    "# 2. Implement the sepia filter prolog\n",
    "def sepia_prolog_impl(data_in, offset, unused_user_info, unused):\n",
    "    # TODO: Implement this step\n",
    "    # 1. Get the channel index and pixel index from the offset\n",
    "    # 2. Access the (r,g,b) pixel data from data_in array\n",
    "    # 3. Based on the channel index, apply the sepia filter to the respective channel\n",
    "    # 4. Return the filtered pixel data as a function result\n",
    "    pass\n",
    "\n",
    "# 3. Implement the Gaussian blur prolog\n",
    "def blur_prolog_impl(data_in, offset, filter_data, unused):\n",
    "    # Offset is a flattened index of the three (R, G, B) FFTs. Each FFT has size h.size \n",
    "    pass\n",
    "\n",
    "# 4. Compile the prologs\n",
    "# TODO: Implement this step\n",
    "sepia_prolog = nvmath.fft.compile_prolog(sepia_prolog_impl, \"complex64\", \"complex64\")\n",
    "blur_prolog = nvmath.fft.compile_prolog(blur_prolog_impl, \"complex64\", \"complex64\")\n",
    "\n",
    "# 5. Perform forward R2C FFT with the compiled Sepia filter prolog\n",
    "# TODO: Implement this step\n",
    "\n",
    "# 6. Perform backward C2R FFT with the compiled Gaussian Blur prolog\n",
    "# TODO: Implement this step\n",
    "\n",
    "# 7. Display the processed image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(filtered_image.transpose(1, 2, 0).get())\n",
    "plt.title(\"Sepia & Blurred Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways_callbacks",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "\n",
    "- FFT callbacks allow custom Python functions to be JIT-compiled and fused with FFT kernels as prolog or epilog operations.\n",
    "- JIT compilation overhead is a one-time cost that can be amortized across multiple executions.\n",
    "- CuPy has a built-in plan caching mechanism that amortizes the initial planning cost across executions.\n",
    "- **nvmath-python** stateful API amortizes compilation and planning costs and avoids plan cache retrieval overhead in subsequent executions.\n",
    "- For batch processing, the cost per image decreases as batch size increases due to amortization of setup costs.\n",
    "\n",
    "---\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored FFT callbacks in **nvmath-python**, a powerful feature that enables kernel fusion for FFT operations. Through a practical image processing example (Gaussian filtering), we demonstrated how callbacks can significantly improve performance.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- FFT callbacks allow custom operations to be fused with FFT kernels by JIT-compiling Python functions to LTO-IR\n",
    "- Kernel fusion eliminates intermediate memory operations and reduces kernel launch overhead\n",
    "- Stateful FFT APIs enable separation of compilation/planning from execution, allowing cost amortization\n",
    "- For the Gaussian filtering example, **nvmath-python** with callbacks provides better performance than CuPy for batch processing\n",
    "- The cost per image decreases as batch size increases due to amortization of compilation and planning costs\n",
    "- CuPy's plan caching and **nvmath-python**'s stateful APIs both address the challenge of setup cost amortization, but with different trade-offs\n",
    "\n",
    "**Next Steps:**\n",
    "- Explore device APIs in the next notebook: [05_device_api.ipynb](05_device_api.ipynb)\n",
    "- Return to previous notebooks to review kernel fusion, memory spaces, and stateful APIs\n",
    "\n",
    "---\n",
    "## References\n",
    "\n",
    "- NVIDIA nvmath-python documentation, \"FFT API Reference,\" https://docs.nvidia.com/cuda/nvmath-python/, Accessed: October 23, 2025.\n",
    "- NVIDIA, \"cuFFT Library User Guide,\" https://docs.nvidia.com/cuda/cufft/, Accessed: October 23, 2025.\n",
    "- NVIDIA, \"cuFFT Callbacks,\" https://docs.nvidia.com/cuda/cufft/index.html#callback-routines, Accessed: October 23, 2025.\n",
    "- Williams, Samuel, et al., \"Roofline: An Insightful Visual Performance Model for Multicore Architectures,\" Communications of the ACM, 52(4), 65-76, 2009."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
