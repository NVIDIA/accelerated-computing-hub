{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671193a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0 AND CC-BY-NC-4.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e40334",
   "metadata": {},
   "source": [
    "<img src=\"./images/nvmath_head_panel@0.5x.png\" alt=\"nvmath-python\" />\n",
    "\n",
    "# Getting Started with nvmath-python: Device APIs\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook introduces **nvmath-python**'s device APIs, which enable the use of high-performance mathematical functions directly within custom CUDA kernels written with Numba CUDA. This powerful capability allows you to combine custom logic with optimized library functions in a single kernel, dramatically improving performance for complex algorithms.\n",
    "\n",
    "**Learning Objectives:**\n",
    "* Understand what device APIs are and how they differ from host APIs\n",
    "* Use `nvmath.device.random` for random number generation within custom CUDA kernels\n",
    "* Write custom CUDA kernels using Numba CUDA that incorporate **nvmath-python** device functions\n",
    "* Apply device APIs to implement Monte Carlo simulations (Geometric Brownian Motion)\n",
    "* Visualize stochastic processes including Arithmetic and Geometric Brownian Motion\n",
    "* Benchmark performance improvements from kernel fusion using device APIs\n",
    "* Optimize random number generation by consuming multiple variates per iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21497b",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction\n",
    "\n",
    "Device APIs in **nvmath-python** allow you to call mathematical functions directly from within custom CUDA kernels. This is fundamentally different from the host APIs we've used in previous notebooks, which are called from Python code and launch GPU kernels internally.\n",
    "\n",
    "**Key Advantages of Device APIs:**\n",
    "1. **Kernel Fusion**: Combine custom logic with library functions in a single kernel, eliminating intermediate memory operations\n",
    "2. **Flexibility**: Implement complex algorithms that aren't directly expressible with host-level APIs\n",
    "3. **Performance**: Reduce kernel launch overhead and memory bandwidth requirements\n",
    "4. **Integration**: Seamlessly integrate with existing [Numba CUDA](https://numba.readthedocs.io/en/stable/cuda/index.html) code\n",
    "\n",
    "This notebook demonstrates device APIs through a computational mathematics example: Monte Carlo simulation of stock prices using the *Geometric Brownian Motion* (GBM) model. We'll use `nvmath.device.random` to generate random numbers directly within a custom CUDA kernel that computes the entire simulation path.\n",
    "\n",
    "**Prerequisites:** To use this notebook, you will need:\n",
    "- A computer equipped with an NVIDIA GPU\n",
    "- Completion of previous notebooks (recommended)\n",
    "- Understanding of Numba CUDA and basic CUDA programming concepts\n",
    "- Familiarity with stochastic processes (helpful but not required)\n",
    "\n",
    "For detailed installation instructions, please refer to the [nvmath-python documentation](https://docs.nvidia.com/cuda/nvmath-python/latest/installation.html#install-nvmath-python).\n",
    "\n",
    "---\n",
    "## Setup\n",
    "\n",
    "This notebook uses the same benchmarking helper function from previous notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aed9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupyx as cpx\n",
    "\n",
    "\n",
    "# Helper function to benchmark two implementations F and (optionally) F_alternative\n",
    "# When F_alternative is provided, in addition to raw performance numbers (seconds)\n",
    "# speedup of F relative to F_alternative is reported\n",
    "def benchmark(\n",
    "    F, F_name=\"Implementation\", F_alternative=None, F_alternative_name=\"Alternative implementation\", n_repeat=10, n_warmup=1\n",
    "):\n",
    "    # warm-up + repeated runs\n",
    "    timing = cpx.profiler.benchmark(F, n_repeat=n_repeat, n_warmup=n_warmup)\n",
    "    # best time from repeated runs\n",
    "    perf = np.min(timing.gpu_times)\n",
    "    print(f\"{F_name} performance = {perf:0.4f} sec\")\n",
    "\n",
    "    if F_alternative is not None:\n",
    "        timing_alt = cpx.profiler.benchmark(F_alternative, n_repeat=n_repeat, n_warmup=n_warmup)\n",
    "        perf_alt = np.min(timing_alt.gpu_times)\n",
    "        print(f\"{F_alternative_name} performance = {perf_alt:0.4f} sec\")\n",
    "        print(f\"Speedup = {perf_alt / perf:0.4f}x\")\n",
    "    else:\n",
    "        perf_alt = None\n",
    "\n",
    "    return perf, perf_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca95a5b4",
   "metadata": {},
   "source": [
    "---\n",
    "## Background: Stochastic Processes\n",
    "\n",
    "Before diving into the implementation, let's review the mathematical concepts we'll be using.\n",
    "\n",
    "### Arithmetic Brownian Motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac528a6",
   "metadata": {},
   "source": [
    "*Arithmetic Brownian motion* (also called *simple Brownian motion* or the *Wiener process*) is one of the most important stochastic processes in mathematics and finance.\n",
    "\n",
    "In its normalized form, the process $ B_t $ has the following properties:\n",
    "\n",
    "1. **Initial Condition**: $ B_0 = 0 $\n",
    "2. **Normal Increments**: At any two time moments $ t $ and $ s $ where $ t > s $, the increment $ B_t - B_s $ is normally distributed:\n",
    "   \\[ B_t - B_s \\sim \\mathcal{N}(0, t-s) \\]\n",
    "3. **Independent Increments**: Any two non-overlapping increments are independent\n",
    "4. **Continuous Paths**: The process has continuous sample paths\n",
    "\n",
    "The process evolves from $ t = 0 $ to $ t = T $ with zero mean and standard deviation $ \\sqrt{T} $.\n",
    "\n",
    "Let's visualize a sample of Brownian motion paths using [NumPy](https://numpy.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33384734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brownian_motion(nsteps, npaths):\n",
    "    dBt = np.random.randn(npaths, nsteps - 1)\n",
    "    dBt = np.insert(dBt, 0, 0.0, axis=1)  # The process starts at 0\n",
    "    Bt = np.cumsum(dBt, axis=1)\n",
    "    return Bt\n",
    "\n",
    "\n",
    "RNG_SEED = 77777  # Random seed\n",
    "N_STEPS = 100  # Number of time steps\n",
    "N_PATHS = 500  # Number of simulated paths\n",
    "\n",
    "np.random.seed(RNG_SEED)\n",
    "paths = brownian_motion(N_STEPS, N_PATHS)\n",
    "t = np.arange(N_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c7279",
   "metadata": {},
   "source": [
    "The plot below shows multiple sample paths of Brownian motion, along with theoretical bounds at \\( \\pm\\sqrt{t} \\), \\( \\pm 2\\sqrt{t} \\), and \\( \\pm 3\\sqrt{t} \\):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "LIGHT_GREY = \"#AAA\"\n",
    "GREY = \"#777\"\n",
    "BLACK = \"#000\"\n",
    "PRIMARY_GREEN = \"#76B900\"\n",
    "DARK_GREEN = \"#619900\"\n",
    "\n",
    "fig = plt.figure(figsize=(13, 6))\n",
    "ax0 = plt.subplot2grid((1, 4), (0, 0), colspan=3)\n",
    "\n",
    "ax0.grid(True, linestyle=\"--\")\n",
    "ax0.axvline(x=0, color=\"k\")\n",
    "for i in range(1, paths.shape[0]):\n",
    "    ax0.plot(t, paths[i], color=PRIMARY_GREEN, linewidth=1)\n",
    "ax0.plot(t, paths[0], color=DARK_GREEN, linewidth=2)\n",
    "ax0.plot(t, np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, -np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, 2 * np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, -2 * np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, 3 * np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, -3 * np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.annotate(r\"$\\sqrt{t}$\", xy=(50, 9), fontsize=16, fontweight=\"bold\", rotation=6, ha=\"center\", va=\"center\")\n",
    "ax0.annotate(r\"$2\\sqrt{t}$\", xy=(50, 16), fontsize=16, fontweight=\"bold\", rotation=10, ha=\"center\", va=\"center\")\n",
    "ax0.annotate(r\"$3\\sqrt{t}$\", xy=(50, 24), fontsize=16, fontweight=\"bold\", rotation=12, ha=\"center\", va=\"center\")\n",
    "ax0.set_xlabel(\"Time Steps\")\n",
    "ax0.set_title(\"Brownian motion\")\n",
    "ax0.axis(\"on\")\n",
    "ax0.set_ylim(-30, 30)\n",
    "\n",
    "x = np.linspace(-30, 30)\n",
    "ax1 = plt.subplot2grid((1, 4), (0, 3), colspan=1)\n",
    "ax1.hist(paths[:, -1], bins=29, density=True, orientation=\"horizontal\", color=PRIMARY_GREEN, edgecolor=DARK_GREEN)\n",
    "ax1.plot(norm.pdf(x, loc=0, scale=math.sqrt(N_STEPS)), x, color=BLACK)\n",
    "ax1.set_ylim(-30, 30)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax1.set_title(f\"Histogram at $t={N_STEPS}$\")\n",
    "ax1.annotate(r\"$\\mathcal{N}{\\left(0, t\\right)}$\", xy=(0.04, 0), va=\"center\", rotation=-90, fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d6c8d",
   "metadata": {},
   "source": [
    "---\n",
    "## Geometric Brownian Motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757419fe",
   "metadata": {},
   "source": [
    "Geometric Brownian Motion (GBM) is a continuous-time stochastic process derived from arithmetic Brownian motion. It is particularly useful for modeling non-negative quantities that grow exponentially over time, such as stock prices.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "The GBM process $ S_t $ is defined as:\n",
    "\n",
    "$$\n",
    "S_t = S_0 \\exp \\left(\\left( \\mu - \\frac{\\sigma^2}{2} \\right) t + \\sigma B_t \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ S_0 $ is the initial value (e.g., initial stock price)\n",
    "- $ \\mu $ is the *drift* parameter (expected return rate)\n",
    "- $ \\sigma $ is the *volatility* parameter (measure of randomness)\n",
    "- $ B_t $ is a standard Brownian motion\n",
    "\n",
    "**Differential Form:**\n",
    "\n",
    "It is often more convenient to express GBM in differential form using a stochastic differential equation (SDE):\n",
    "\n",
    "$$\n",
    "dS_t = \\mu S_t dt + \\sigma S_t dB_t\n",
    "$$\n",
    "\n",
    "**Properties:**\n",
    "- Starts at $ S_0 $ (unlike simple Brownian motion which starts at $ 0 $)\n",
    "- Never goes below $ 0 $ (log-normal distribution)\n",
    "- Commonly used as a first-order approximation for stock price dynamics\n",
    "- Used extensively in options pricing (Black-Scholes model)\n",
    "\n",
    "Let's implement and visualize GBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709aebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = 100.0  # Initial stock price\n",
    "MU = 0.003\n",
    "SIGMA = 0.027\n",
    "\n",
    "RNG_SEED = 77777  # Random seed\n",
    "N_STEPS = 252  # Number of time steps\n",
    "N_PATHS = 500  # Number of simulated paths\n",
    "\n",
    "\n",
    "def brownian_motion(nsteps, npaths, mu, sigma):\n",
    "    # Differential form of the Brownian motion\n",
    "    dBt = np.random.randn(npaths, nsteps - 1) * sigma + mu\n",
    "    dBt = np.insert(dBt, 0, 0.0, axis=1)  # The process starts at 0\n",
    "\n",
    "    # Integral form of the Brownian motion\n",
    "    Bt = np.cumsum(dBt, axis=1)\n",
    "\n",
    "    return Bt\n",
    "\n",
    "\n",
    "np.random.seed(RNG_SEED)\n",
    "b_t = brownian_motion(N_STEPS, N_PATHS, MU, SIGMA)\n",
    "s_t = S0 * np.exp(b_t)\n",
    "\n",
    "print(f\"Mean stock price at t=T: {s_t[:, -1].mean():0.2f}\")\n",
    "print(f\"Standard deviation of stock price at t=T: {s_t[:, -1].std():0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4533e7c",
   "metadata": {},
   "source": [
    "The plot below shows sample paths of stock prices following Geometric Brownian Motion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "for i in range(1, s_t.shape[0]):\n",
    "    ax.plot(s_t[i], color=PRIMARY_GREEN, linewidth=1)\n",
    "ax.plot(s_t[0], color=DARK_GREEN, linewidth=2)\n",
    "ax.set_title(\"Stock price simulated as GBM\")\n",
    "ax.set_xlabel(\"Time Steps\")\n",
    "ax.set_ylabel(\"Stock Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c7cf4",
   "metadata": {},
   "source": [
    "---\n",
    "## GPU Implementation with CuPy\n",
    "\n",
    "Now let's create a GPU-accelerated version using [CuPy](https://cupy.dev/). This implementation uses array operations similar to the NumPy version but executes on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41662f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvmath # noqa: F811\n",
    "import cupy as cp\n",
    "\n",
    "RNG_SEED = 777777  # Random seed\n",
    "N_STEPS = 252  # Number of time steps (trading days in a year)\n",
    "N_PATHS = 800000  # Number of simulated paths (large number to get a reliable estimate)\n",
    "\n",
    "S0 = 100.0  # Initial stock price\n",
    "MU = 0.003  # Drift with upward trend\n",
    "SIGMA = 0.027  # Volatility\n",
    "\n",
    "\n",
    "def brownian_motion(nsteps, npaths, mu, sigma):\n",
    "    # Differential form of the Brownian motion\n",
    "    dBt = cp.empty((npaths, nsteps), dtype=cp.float32, order=\"F\")\n",
    "    dBt[:, 0] = 0.0  # The process starts at 0\n",
    "    dBt[:, 1:] = cp.random.randn(npaths, nsteps - 1) * sigma + mu\n",
    "\n",
    "    # Integral form of the Brownian motion\n",
    "    Bt = cp.cumsum(dBt, axis=1)\n",
    "\n",
    "    return Bt\n",
    "\n",
    "\n",
    "def generate_gbm_paths_cupy(npaths, nsteps, mu, sigma, s0):\n",
    "    b_t = brownian_motion(nsteps, npaths, mu, sigma)\n",
    "    paths = s0 * cp.exp(b_t)\n",
    "    return paths\n",
    "\n",
    "\n",
    "cp.random.seed(RNG_SEED)\n",
    "s_t = generate_gbm_paths_cupy(N_PATHS, N_STEPS, MU, SIGMA, S0)\n",
    "\n",
    "print(f\"Mean stock price at t=T: {s_t[:, -1].mean():0.2f}\")\n",
    "print(f\"Standard deviation of stock price at t=T: {s_t[:, -1].std():0.2f}\")\n",
    "print(type(s_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfef5ed4",
   "metadata": {},
   "source": [
    "### Performance Analysis of CuPy Implementation\n",
    "\n",
    "The CuPy implementation above consists of a chain of primitive operations with very low arithmetic intensity. Each primitive operation processes an array of shape `(N_PATHS, N_STEPS)`, which makes the overall workload heavily memory-bound:\n",
    "\n",
    "1. Random number generation creates a large array\n",
    "2. Cumulative sum creates another large intermediate array\n",
    "3. Exponential operation reads and writes the full array\n",
    "\n",
    "**Optimization Strategy:**\n",
    "\n",
    "To improve arithmetic intensity and reduce memory bandwidth requirements, we can implement a custom CUDA kernel using Numba CUDA. In this approach:\n",
    "- Each GPU thread handles an entire Monte Carlo path from $ t=0 $ to $ t=T $\n",
    "- Random numbers are generated on-the-fly as needed, not stored in memory\n",
    "- The total number of threads equals `N_PATHS`\n",
    "- No intermediate arrays are allocated\n",
    "\n",
    "---\n",
    "## Device API Implementation with nvmath-python\n",
    "\n",
    "The **nvmath-python** library provides device APIs for *random number generation* that can be used within Numba CUDA kernels for efficient on-device random number generation. The following code illustrates the implementation of GBM using Numba CUDA and `nvmath.device.random`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "from nvmath.device import random\n",
    "import cupy as cp\n",
    "\n",
    "RNG_SEED = 777777  # Random seed\n",
    "N_STEPS = 252  # Number of time steps (trading days in a year)\n",
    "N_PATHS = 800000  # Number of simulated paths (large number to get a reliable estimate)\n",
    "\n",
    "S0 = 100.0  # Initial stock price\n",
    "MU = 0.003  # Drift with upward trend\n",
    "SIGMA = 0.027  # Volatility\n",
    "\n",
    "# Pre-compile the random number generator into IR to use alongside other device code\n",
    "compiled_rng = random.Compile(cc=None)\n",
    "\n",
    "# Set up CUDA kernel launch configuration\n",
    "threads_per_block = 32\n",
    "blocks = N_PATHS // threads_per_block\n",
    "nthreads = threads_per_block * blocks + bool(N_PATHS % threads_per_block)\n",
    "print(f\"blocks: {blocks}, threads_per_block: {threads_per_block}, nthreads: {nthreads}\")\n",
    "\n",
    "# Allocate space for random states\n",
    "states = random.StatesPhilox4_32_10(nthreads)\n",
    "\n",
    "\n",
    "# RNG initialization kernel\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def init_rng_gpu(states, seed):\n",
    "    idx = cuda.grid(1)\n",
    "    random.init(seed, idx, 0, states[idx])\n",
    "\n",
    "\n",
    "# GBM path generation kernel. Note that the random numbers are generated\n",
    "# as they are needed, unlike for the NumPy/CuPy implementation where they are\n",
    "# generated upfront and stored.\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def generate_gbm_paths_nvmath(states, paths, nsteps, mu, sigma, s0):\n",
    "    mu = paths.dtype.type(mu)\n",
    "    sigma = paths.dtype.type(sigma)\n",
    "    s0 = paths.dtype.type(s0)\n",
    "\n",
    "    # Get the thread index\n",
    "    idx = cuda.grid(1)\n",
    "\n",
    "    # If the thread index is out of bounds, return\n",
    "    if idx >= paths.shape[0]:\n",
    "        return\n",
    "\n",
    "    # Each thread generates one path in the time domain\n",
    "    paths[idx, 0] = s0\n",
    "\n",
    "    # Consume a single normal variate at a time\n",
    "    for i in range(1, nsteps):\n",
    "        z = random.normal(states[idx])\n",
    "        z = mu + sigma * z\n",
    "        paths[idx, i] = paths[idx, i - 1] * math.exp(z)\n",
    "\n",
    "\n",
    "# Allocate space for paths\n",
    "paths_gpu = cp.empty((N_PATHS, N_STEPS), dtype=cp.float32)\n",
    "\n",
    "# Initialize RNG states\n",
    "init_rng_gpu[blocks, threads_per_block](states, RNG_SEED)\n",
    "\n",
    "# Generate GBM paths on GPU\n",
    "generate_gbm_paths_nvmath[blocks, threads_per_block](states, paths_gpu, N_STEPS, MU, SIGMA, S0)\n",
    "\n",
    "print(f\"Mean stock price at t=T: {paths_gpu[:, -1].mean():0.2f}\")\n",
    "print(f\"Standard deviation of stock price at t=T: {paths_gpu[:, -1].std():0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407111ad",
   "metadata": {},
   "source": [
    "### Performance Benchmarking\n",
    "\n",
    "Now let's benchmark the **nvmath-python** device API implementation and compare it to the CuPy implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd57a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    lambda: generate_gbm_paths_nvmath[blocks, threads_per_block](states, paths_gpu, N_STEPS, MU, SIGMA, S0),\n",
    "    \"nvmath-python\",\n",
    "    lambda: generate_gbm_paths_cupy(N_PATHS, N_STEPS, MU, SIGMA, S0),\n",
    "    \"CuPy\",\n",
    "    n_repeat=5,\n",
    "    n_warmup=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a525e68",
   "metadata": {},
   "source": [
    "### Optimization: Vectorized Random Number Generation\n",
    "\n",
    "Major performance inefficiency in the above implementation is the layout of `paths_gpu`. For best performance, paths at each time step should exhibit thread block locality, whereas in the above implementation they are contiguous in time.\n",
    "\n",
    "Further kernel optimization will leverage the fact that the Philox4_32_10 random number generator returns 4 variates at a time. This allows us to produce 4 time steps in a single loop iteration, reducing the number of RNG calls.\n",
    "\n",
    "**Key Optimization:**\n",
    "- Re-arrange `paths_gpu` to exhibit thread block locality by using Fortran (column) order layout\n",
    "- Use `random.normal4()` instead of `random.normal()` to get 4 random numbers at once\n",
    "- Process 4 time steps per loop iteration\n",
    "- To avoid unnecessary type conversions at each time step, ensure GBM parameters' type is aligned with `paths_gpu.dtype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "from nvmath.device import random\n",
    "import cupy as cp\n",
    "\n",
    "RNG_SEED = 777777  # Random seed\n",
    "N_STEPS = 252  # Number of time steps (trading days in a year)\n",
    "N_PATHS = 800000  # Number of simulated paths (large number to get a reliable estimate)\n",
    "\n",
    "S0 = 100.0  # Initial stock price\n",
    "MU = 0.003  # Drift with upward trend\n",
    "SIGMA = 0.027  # Volatility\n",
    "\n",
    "# Pre-compile the random number generator into IR to use alongside other device code\n",
    "compiled_rng = random.Compile(cc=None)\n",
    "\n",
    "# Set up CUDA kernel launch configuration\n",
    "threads_per_block = 32\n",
    "blocks = N_PATHS // threads_per_block\n",
    "nthreads = threads_per_block * blocks + bool(N_PATHS % threads_per_block)\n",
    "print(f\"blocks: {blocks}, threads_per_block: {threads_per_block}, nthreads: {nthreads}\")\n",
    "\n",
    "# Allocate space for random states\n",
    "states = random.StatesPhilox4_32_10(nthreads)\n",
    "\n",
    "\n",
    "# RNG initialization kernel\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def init_rng_gpu(states, seed):\n",
    "    idx = cuda.grid(1)\n",
    "    random.init(seed, idx, 0, states[idx])\n",
    "\n",
    "\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def generate_gbm_paths_gpu(states, paths, nsteps, mu, sigma, s0):\n",
    "    # Make sure the parameters are aligned with the paths array dtype\n",
    "    mu = paths.dtype.type(mu)\n",
    "    sigma = paths.dtype.type(sigma)\n",
    "    s0 = paths.dtype.type(s0)\n",
    "\n",
    "    # Get the thread index\n",
    "    idx = cuda.grid(1)\n",
    "\n",
    "    # If the thread index is out of bounds, return\n",
    "    if idx >= paths.shape[0]:\n",
    "        return\n",
    "\n",
    "    # Each thread generates one path in the time domain\n",
    "    paths[idx, 0] = s0\n",
    "\n",
    "    # Consume 4 normal variates at a time for better throughput\n",
    "    for i in range(1, nsteps, 4):\n",
    "        v = random.normal4(states[idx])  # Returned as float32x4 type\n",
    "        vals = v.x, v.y, v.z, v.w  # Decompose into a tuple of float32\n",
    "        # Process a chunk of 4 time steps, use min() to avoid out-of-bounds access\n",
    "        for j in range(i, min(i + 4, nsteps)):\n",
    "            paths[idx, j] = paths[idx, j - 1] * math.exp(mu + sigma * vals[j - i])\n",
    "\n",
    "\n",
    "# Allocate space for paths\n",
    "paths_gpu = cp.empty((N_PATHS, N_STEPS), dtype=cp.float32, order=\"F\")\n",
    "\n",
    "# Initialize RNG states\n",
    "init_rng_gpu[blocks, threads_per_block](states, RNG_SEED)\n",
    "\n",
    "# Generate GBM paths on GPU\n",
    "generate_gbm_paths_nvmath[blocks, threads_per_block](states, paths_gpu, N_STEPS, MU, SIGMA, S0)\n",
    "\n",
    "print(f\"Mean stock price at t=T: {paths_gpu[:, -1].mean():0.2f}\")\n",
    "print(f\"Standard deviation of stock price at t=T: {paths_gpu[:, -1].std():0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    lambda: generate_gbm_paths_nvmath[blocks, threads_per_block](states, paths_gpu, N_STEPS, MU, SIGMA, S0),\n",
    "    \"nvmath-python\",\n",
    "    lambda: generate_gbm_paths_cupy(N_PATHS, N_STEPS, MU, SIGMA, S0),\n",
    "    \"CuPy\",\n",
    "    n_repeat=5,\n",
    "    n_warmup=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ef06e",
   "metadata": {},
   "source": [
    "## Exercise: Implement numba-cuda kernel for Monte Carlo simulation of American Option call and put option cashflows\n",
    "\n",
    "In this exercise you will do the following:\n",
    "1. Familiarize yourself with the definitions of the call and put American options.\n",
    "2. Take GBM implementation as a baseline for implementing call/put cashflows simulation. Additionally use the CuPy implementation below as a reference implementation of the entire workflow. \n",
    "3. Compare nvmath-python/numba-cuda vs. CuPy implementations for correctness. \n",
    "4. Benchmark nvmath-python/numba-cuda implementation vs. CuPy and explain the performance difference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0321a",
   "metadata": {},
   "source": [
    "### American Options: Call and Put Definitions\n",
    "\n",
    "**American Call Option:**\n",
    "An American call option gives the holder the **right, but not the obligation**, to **buy** an underlying asset (such as a stock) at a predetermined strike price **at any time before or on the expiration date** `T`. The key feature that distinguishes American options from European options is this ability to exercise early. The holder profits when the asset price exceeds the strike price, with the payoff being `max(S - K, 0) - Premium`, where `S` is the spot price, `K` is the strike price, and `Premium` is the initial cost paid for the option.\n",
    "\n",
    "**American Put Option:**\n",
    "An American put option gives the holder the **right, but not the obligation**, to **sell** an underlying asset at a predetermined strike price **at any time before or on the expiration date** `T`. Similar to the call option, it can be exercised at any point during its lifetime. The holder profits when the asset price falls below the strike price, with the payoff being `max(K - S, 0) - Premium`.\n",
    "\n",
    "**Key Characteristics:**\n",
    "- **Flexibility**: Can be exercised at any time up to expiration (unlike European options which can only be exercised at expiration)\n",
    "- **Premium**: The upfront cost paid to acquire the option\n",
    "- **Strike Price**: The predetermined price at which the transaction can occur\n",
    "- **Intrinsic Value**: The immediate profit if exercised now (can be zero if out-of-the-money)\n",
    "- **Time Value**: Additional value due to the possibility of favorable price movements before expiration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985a0fc",
   "metadata": {},
   "source": [
    "The following charts illustrate call and put option *payoff functions* relative to the spot price `S`. Note horizontal negative areas representing the fact that the holder has the right to quit without exercising the contract with a small penalty, which is equal to `Premium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LIGHT_GREY = \"#AAA\"\n",
    "GREY = \"#777\"\n",
    "BLACK = \"#000\"\n",
    "PRIMARY_GREEN = \"#76B900\"\n",
    "DARK_GREEN = \"#619900\"\n",
    "PRIMARY_BLUE = '#88f'\n",
    "DARK_BLUE = '#55a'\n",
    "PRIMARY_RED = '#eb7734'\n",
    "DARK_RED = '#ba5012'\n",
    "\n",
    "def call_payoff(x, strike, premium):\n",
    "    return np.maximum(x - strike, 0.0) - premium\n",
    "\n",
    "def put_payoff(x, strike, premium):\n",
    "    return np.maximum(strike - x, 0.0) - premium\n",
    "\n",
    "\n",
    "strike_price = 100.0\n",
    "premium = 5.0\n",
    "stock_price = np.linspace(70.0, 130.0, 100)\n",
    "cpay = call_payoff(stock_price, strike_price, premium)\n",
    "ppay = put_payoff(stock_price, strike_price, premium)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6, 8))\n",
    "axs[0].plot(stock_price, cpay, label=\"Call option\", color=PRIMARY_BLUE)\n",
    "axs[1].plot(stock_price, ppay, label=\"Put option\", color=PRIMARY_RED)\n",
    "axs[0].annotate(\"Strike\", xy=(strike_price, -premium), xytext=(94, -2), arrowprops = dict(arrowstyle='-|>', color=GREY), color=GREY )\n",
    "axs[0].annotate(\"Premium\", xy=(80, -premium), xytext=(75.58, 0.8), arrowprops = dict(arrowstyle='<|-|>', color=GREY), color=GREY )\n",
    "axs[1].annotate(\"Strike\", xy=(strike_price, -premium), xytext=(100, -2), arrowprops = dict(arrowstyle='->', color=GREY), color=GREY )\n",
    "axs[1].annotate(\"Premium\", xy=(120, -premium), xytext=(115.58, 0.8), arrowprops = dict(arrowstyle='<|-|>', color=GREY), color=GREY )\n",
    "axs[0].set_title(\"Call option payoff function\")\n",
    "axs[1].set_title(\"Put option payoff function\")\n",
    "axs[1].set_xlabel(\"Stock price\")\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylabel(\"Payoff\")\n",
    "    ax.grid(True, linestyle='--')\n",
    "    ax.legend()\n",
    "    ax.axhline(y=0, color='k')\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f21f1",
   "metadata": {},
   "source": [
    "The following code is a reference implementation of the American call and put option cashflows using CuPy. It is based on the respective GBM CuPy code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvmath # noqa: F401, F811\n",
    "import cupy as cp\n",
    "\n",
    "RNG_SEED = 777777  # Random seed\n",
    "N_STEPS = 252  # Number of time steps (trading days in a year)\n",
    "N_PATHS = 800000  # Number of simulated paths (large number to get a reliable estimate)\n",
    "\n",
    "S0 = 100.0  # Initial stock price\n",
    "MU = 0.003  # Drift with upward trend\n",
    "SIGMA = 0.027  # Volatility\n",
    "STRIKE = 110.0  # Strike price\n",
    "PREMIUM = 5.0  # Premium\n",
    "\n",
    "def brownian_motion(nsteps, npaths, mu, sigma):\n",
    "    # Differential form of the Brownian motion\n",
    "    dBt = cp.empty((npaths, nsteps), dtype=cp.float32)\n",
    "    dBt[:, 0] = 0.0\n",
    "    dBt[:, 1:] = cp.random.randn(npaths, nsteps - 1) * sigma + mu\n",
    "\n",
    "    # Integral form of the Brownian motion\n",
    "    Bt = cp.cumsum(dBt, axis=1)\n",
    "\n",
    "    return Bt\n",
    "\n",
    "\n",
    "def generate_call_put_payoffs_cupy(nsteps, npaths, mu, sigma, s0, strike, premium):\n",
    "    b_t = brownian_motion(nsteps, npaths, mu, sigma)\n",
    "    s_t = s0 * cp.exp(b_t)\n",
    "    call_paths = cp.maximum(s_t - STRIKE, 0.0) - PREMIUM  # Call option cashflows\n",
    "    put_paths = cp.maximum(STRIKE - s_t, 0.0) - PREMIUM  # Put option cashflows\n",
    "    return call_paths, put_paths\n",
    "\n",
    "np.random.seed(RNG_SEED)\n",
    "# Allocate space for paths\n",
    "call_cashflow = cp.empty((N_PATHS, N_STEPS), dtype=cp.float32, order=\"F\")\n",
    "put_cashflow = cp.empty((N_PATHS, N_STEPS), dtype=cp.float32, order=\"F\")\n",
    "\n",
    "call_cashflow, put_cashflow = generate_call_put_payoffs_cupy(N_STEPS, N_PATHS, MU, SIGMA, S0, STRIKE, PREMIUM)\n",
    "\n",
    "print(f\"Mean call option cashflow at t=T: {call_cashflow[:, -1].mean():0.2f}\")\n",
    "print(f\"Mean put option cashflow at t=T: {put_cashflow[:, -1].mean():0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416c8db",
   "metadata": {},
   "source": [
    "Take a note that call option cashflow at $ t = T $ is positive due to stock upward trend $ \\mu > 0$. Respective put option cashflow is negative for the same reason but is very small. Call and put options are the great ways to *hedge* possible losses in the *bear market* and the *bull market* respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c126992",
   "metadata": {},
   "source": [
    "Now it is your turn. Implement CUDA kernel using **numba-cuda** and **nvmath-python**. Feel free to refer to the respective GBM CUDA kernel we implemented earlier in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed8d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "from nvmath.device import random\n",
    "import cupy as cp\n",
    "import math\n",
    "\n",
    "# Pre-compile the random number generator into IR to use alongside other device code\n",
    "# TODO: Implement this\n",
    "\n",
    "# Set up CUDA kernel launch configuration\n",
    "# TODO: Implement threads_per_block, blocks, and nthreads configurationlogic\n",
    "\n",
    "# Allocate space for random states\n",
    "# TODO: Implement this\n",
    "\n",
    "\n",
    "# RNG initialization kernel\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def init_rng_gpu(states, seed):\n",
    "    idx = cuda.grid(1)\n",
    "    random.init(seed, idx, 0, states[idx])\n",
    "\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def generate_call_put_payoffs_nvmath(states, call_paths, put_paths, nsteps, mu, sigma, s0, strike, premium):\n",
    "    # Make sure the parameters are aligned with the call/put payoff arrays dtype\n",
    "    # TODO: Allocate necessary local variables here. Make sure their types match input arrays dtype\n",
    "\n",
    "    # Get the thread index\n",
    "    # TODO: Implement thread index logic here\n",
    "\n",
    "    # Each thread generates one path in the time domain\n",
    "    # Consume 4 normal variates at a time for better throughput\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "\n",
    "\n",
    "# Allocate space for paths\n",
    "call_cashflow = cp.empty((N_PATHS, N_STEPS), dtype=cp.float32, order=\"F\")\n",
    "put_cashflow = cp.empty((N_PATHS, N_STEPS), dtype=cp.float32, order=\"F\")\n",
    "\n",
    "# Initialize RNG states\n",
    "init_rng_gpu[blocks, threads_per_block](states, RNG_SEED)\n",
    "\n",
    "# Generate GBM paths on GPU\n",
    "generate_call_put_payoffs_nvmath[blocks, threads_per_block](states, call_cashflow, put_cashflow, N_STEPS, MU, SIGMA, S0, STRIKE, PREMIUM)\n",
    "\n",
    "print(f\"Mean call option cashflow at t=T: {call_cashflow[:, -1].mean():0.2f}\")\n",
    "print(f\"Mean put option cashflow at t=T: {put_cashflow[:, -1].mean():0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways_device_api",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "\n",
    "- **nvmath-python** device APIs allow direct integration within custom Numba CUDA kernels, dramatically reducing implementation complexity for math-intensive algorithms.\n",
    "- Kernel fusion eliminates intermediate array allocations and memory transfers, significantly improving overall arithmetic intensity.\n",
    "- Device-side random number generation is more efficient than generating random numbers on the host or in a separate kernel.\n",
    "- Vectorized RNG calls (e.g., `normal4()`) provide additional performance improvements.\n",
    "\n",
    "---\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored **nvmath-python**'s device APIs, which enable the use of high-performance mathematical functions directly within custom CUDA kernels. Through a practical Monte Carlo simulation example (Geometric Brownian Motion for stock price modeling), we demonstrated how device APIs can dramatically improve performance.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Device APIs allow calling **nvmath-python** functions from within Numba CUDA kernels\n",
    "- This enables kernel fusion, combining custom logic with optimized library functions in a single kernel\n",
    "- Kernel fusion eliminates intermediate memory allocations and reduces memory bandwidth requirements\n",
    "- Device-side random number generation is particularly powerful for Monte Carlo simulations\n",
    "- The Philox4_32_10 generator can produce 4 random numbers at once, enabling further optimization\n",
    "- For the GBM simulation example, device APIs provide significant speedup over array-based CuPy implementations\n",
    "- Device APIs are essential for implementing complex algorithms that aren't expressible with host-level APIs\n",
    "\n",
    "**Practical Applications:**\n",
    "- Monte Carlo simulations (finance, physics, engineering)\n",
    "- Custom iterative algorithms requiring mathematical functions\n",
    "- Performance-critical code where kernel launch overhead is significant\n",
    "- Integration of library functions into existing CUDA code\n",
    "\n",
    "**Series Conclusion:**\n",
    "\n",
    "Congratulations on completing the **nvmath-python** tutorial series! You've learned about:\n",
    "1. Kernel fusion for composite operations (notebook 01)\n",
    "2. Memory and execution spaces (notebook 02)\n",
    "3. Stateful APIs and autotuning (notebook 03)\n",
    "4. FFT callbacks (notebook 04)\n",
    "5. Device APIs for custom CUDA kernels (notebook 05)\n",
    "\n",
    "These advanced features make **nvmath-python** a powerful tool for high-performance scientific computing on NVIDIA GPUs.\n",
    "\n",
    "---\n",
    "## References\n",
    "\n",
    "- NVIDIA nvmath-python documentation, \"Device API Reference,\" https://docs.nvidia.com/cuda/nvmath-python/, Accessed: October 23, 2025.\n",
    "- NVIDIA, \"cuRAND Library,\" https://docs.nvidia.com/cuda/curand/, Accessed: October 23, 2025.\n",
    "- Numba Documentation, \"CUDA Python with Numba,\" https://numba.readthedocs.io/en/stable/cuda/index.html, Accessed: October 23, 2025.\n",
    "- Black, Fischer, and Myron Scholes, \"The pricing of options and corporate liabilities,\" Journal of Political Economy, 81(3), 637-654, 1973.\n",
    "- Glasserman, Paul, \"Monte Carlo Methods in Financial Engineering,\" Springer, 2004.\n",
    "\n",
    "- Williams, Samuel, et al., \"Roofline: An Insightful Visual Performance Model for Multicore Architectures,\" Communications of the ACM, 52(4), 65-76, 2009.\n",
    "\n",
    "- Cormen, Thomas H., et al., \"Introduction to Algorithms,\" 3rd Edition, MIT Press, 2009."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
