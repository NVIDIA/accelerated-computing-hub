{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0 AND CC-BY-NC-4.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea0ff1",
   "metadata": {},
   "source": [
    "<img src=\"./images/nvmath_head_panel@0.5x.png\" alt=\"nvmath-python\" />\n",
    "\n",
    "# Getting Started with nvmath-python: Direct Sparse Solver\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook illustrates **nvmath-python**'s *direct sparse solver* (DSS), used for solving large linear systems where most coefficients are zeros. Backed by [NVIDIA's cuDSS library](https://developer.nvidia.com/cudss), the `nvmath.sparse.advanced` module is designed for solving linear equations of the form $ A \\cdot X = B $, where:\n",
    "* $A$, the *left-hand side* (LHS), is a known sparse matrix in [CSR format](https://docs.nvidia.com/nvpl/latest/sparse/storage_format/sparse_matrix.html#compressed-sparse-row-csr). All major types of matrices are supported, such as *general*, *symmetric*, *Hermitian*, *symmetric positive definite* (SPD), and *Hermitian positive definite* (HPD).\n",
    "* $B$, the *right-hand side* (RHS), is either a known dense vector or matrix.\n",
    "* $X$ is the unknown solution provided by the direct sparse solver.\n",
    "\n",
    "**Learning Objectives:**\n",
    "* Understand when and why to use sparse direct solvers for large linear systems\n",
    "* Download real-world sparse matrices from the [SuiteSparse Matrix Collection](https://sparse.tamu.edu/)\n",
    "* Apply `nvmath.sparse.advanced.direct_solver` to solve sparse linear systems\n",
    "* Work with sparse matrices in CSR (Compressed Sparse Row) format using CuPy\n",
    "* Configure solver options for optimal performance using hybrid CPU-GPU execution\n",
    "* Validate the accuracy of numerical solutions using residual norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495b737",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction\n",
    "\n",
    "Many real-world problems in scientific computing, engineering, and data science involve solving large systems of linear equations. When these systems have coefficient matrices where most elements are zero (sparse matrices), specialized algorithms become essential for efficient computation. \n",
    "\n",
    "A *sparse direct solver* uses factorization techniques (such as LU or Cholesky decomposition) specifically optimized for sparse matrices to find exact solutions to linear systems. Unlike iterative methods that approximate solutions, direct solvers provide accurate results in a predictable number of operations, making them ideal for applications requiring high precision.\n",
    "\n",
    "**nvmath-python**'s sparse solver module (`nvmath.sparse.advanced`) provides GPU-accelerated direct solving capabilities through NVIDIA's [cuDSS library](https://developer.nvidia.com/cudss). The solver supports:\n",
    "- CSR (Compressed Sparse Row) format for the $A$ matrix representation\n",
    "- Various matrix types: general, symmetric, Hermitian, SPD, and HPD matrices\n",
    "- GPU-only and hybrid CPU-GPU execution spaces for optimal performance on different problem sizes\n",
    "- Interoperability with Python's scientific computing and AI ecosystems (SciPy, CuPy, PyTorch)\n",
    "\n",
    "This notebook demonstrates how to use **nvmath-python** to solve sparse linear systems using real-world data from the [SuiteSparse Matrix Collection](https://sparse.tamu.edu/), a widely-used repository of sparse matrices from diverse application domains.\n",
    "\n",
    "**Prerequisites:** To use this notebook, you will need:\n",
    "- A computer equipped with an NVIDIA GPU\n",
    "- Basic understanding of linear algebra and matrix operations\n",
    "- Familiarity with sparse matrix representations (CSR format)\n",
    "- Understanding of linear system solving concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed10e6",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "This notebook requires the following Python libraries:\n",
    "- `nvmath`: NVIDIA's mathematical library for Python (with sparse solver support)\n",
    "- `cupy`: For GPU array operations and sparse matrix handling\n",
    "- `scipy`: For CPU sparse matrix operations and Matrix Market file reading\n",
    "- `ssgetpy`: For downloading matrices from the SuiteSparse Matrix Collection\n",
    "- `cuda-pathfinder`: For locating installed NVIDIA shared and header-only libraries\n",
    "\n",
    "If you completed previous notebooks, the only additional library you will need to install is:\n",
    "\n",
    "```bash\n",
    "pip install ssgetpy\n",
    "```\n",
    "\n",
    "For detailed installation instructions, please refer to the [nvmath-python documentation](https://docs.nvidia.com/cuda/nvmath-python/latest/installation.html#install-nvmath-python).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf4755b",
   "metadata": {},
   "source": [
    "---\n",
    "## Downloading Sparse Matrices from SuiteSparse\n",
    "\n",
    "The [SuiteSparse Matrix Collection](https://sparse.tamu.edu/) (formerly known as the University of Florida Sparse Matrix Collection) is a comprehensive repository containing thousands of sparse matrices from real-world applications spanning fields such as:\n",
    "- Structural engineering and finite element analysis\n",
    "- Circuit simulation\n",
    "- Computational fluid dynamics\n",
    "- Graph theory and social networks\n",
    "- Optimization problems\n",
    "\n",
    "The `ssgetpy` library provides a convenient Python interface for browsing and downloading matrices from this collection. Let's start by searching for a suitable sparse matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e383f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssgetpy\n",
    "\n",
    "mtx_obj = ssgetpy.search()[2] # 2 is the index of the matrix in the SuiteSparse Matrix Collection\n",
    "mtx_obj # Display the matrix object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c933de",
   "metadata": {},
   "source": [
    "### Loading the Matrix into Memory\n",
    "\n",
    "Once we've identified a suitable matrix, we can download it and load it into memory using SciPy's Matrix Market reader. The Matrix Market format (`.mtx` files) is a standard format for storing sparse matrices, and most matrices in the SuiteSparse Collection are available in this format.\n",
    "\n",
    "The matrix will initially be loaded as a COO (Coordinate) format sparse matrix, which stores the non-zero elements as `(row, column, value)` triplets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "path, _ = mtx_obj.download(extract=True) # Download selected matrix and unpack it\n",
    "spm_coo = scipy.io.mmread(f\"{path}/{path.split('/')[-1]}.mtx\") # Read the unpacked Matrix Market file into COO matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4c77a",
   "metadata": {},
   "source": [
    "---\n",
    "## Solving Sparse Linear Systems with nvmath-python\n",
    "\n",
    "Now that we have our sparse matrix loaded, we can use **nvmath-python**'s direct solver to solve the linear system $ A \\cdot x = b $. The process involves:\n",
    "\n",
    "1. **Converting to CSR format**: The solver expects matrices in CSR (Compressed Sparse Row) format, which is more efficient for matrix-vector operations than COO format.\n",
    "2. **Transferring to GPU**: We'll use CuPy to create GPU-resident sparse matrices and vectors.\n",
    "3. **Defining the right-hand side**: For this example, we'll use a simple vector of ones.\n",
    "4. **Solving the system**: Call `nvmath.sparse.advanced.direct_solver` to compute the solution.\n",
    "5. **Validating the result**: Check the accuracy by computing the residual $ \\|A \\cdot x - b\\| $.\n",
    "\n",
    "Let's implement this workflow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988ecdf-8e68-4e37-85b3-4058b7e3bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvmath\n",
    "import cupy as cp\n",
    "import cupyx as cpx\n",
    "\n",
    "# Transfer sparse matrix to GPU using CuPy\n",
    "# CuPy can directly convert from SciPy sparse matrices\n",
    "a = cpx.scipy.sparse.csr_matrix(spm_coo)\n",
    "\n",
    "# Create the right-hand side vector (a dense vector of ones)\n",
    "b = cp.ones(a.shape[1])\n",
    "\n",
    "# Solve the linear system A * x = b using nvmath-python's direct solver\n",
    "x = nvmath.sparse.advanced.direct_solver(a, b)\n",
    "\n",
    "# Validate the solution by computing the residual norm ||A * x - b||\n",
    "# A small residual indicates an accurate solution\n",
    "residual = cp.linalg.norm(a @ x - b)\n",
    "print(f\"Solution computed successfully!\")\n",
    "print(f\"Residual L2 norm ||A*x - b|| = {residual:.2e}\")\n",
    "print(f\"Matrix size: {a.shape[0]} Ã— {a.shape[1]}\")\n",
    "print(f\"Number of non-zero elements: {a.nnz}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df7d11",
   "metadata": {},
   "source": [
    "**Understanding the Residual:**\n",
    "\n",
    "The residual norm $ \\|A \\cdot x - b\\| $ measures how close our computed solution $ x $ is to the exact solution. A very small residual (close to machine precision) indicates that the solver successfully found an accurate solution. For double-precision floating-point arithmetic, residuals on the order of $ 10^{-10} $ to $ 10^{-15} $ are typical for well-conditioned problems.\n",
    "\n",
    "**Note on Performance Warning:**\n",
    "\n",
    "You may see a warning about \"`No multithreading interface library was specified`.\" This indicates that the solver is not using multi-threading for CPU operations during the planning phase. While this doesn't affect the GPU computation performance significantly, it can slow down the initial setup. We'll address this in the next section by configuring hybrid execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d9468",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuring Hybrid CPU-GPU Execution\n",
    "\n",
    "The **nvmath-python** sparse solver supports *hybrid execution*, which intelligently distributes work between the CPU and GPU for optimal performance. During the solving process, certain operations (like symbolic factorization and pivoting) may benefit from CPU execution, while the bulk of numerical computations are performed on the GPU.\n",
    "\n",
    "To enable hybrid execution with multi-threading support, we need to:\n",
    "1. **Create a cuDSS handle**: This is a low-level handle to the cuDSS library.\n",
    "2. **Load a suitable cuDSS multithreading interface library**: We will use a pre-built GNU OpenMP interface library shipped with cuDSS.\n",
    "3. **Configure solver options**: Pass these settings to the solver via `DirectSolverOptions`.\n",
    "\n",
    "Let's configure and run the solver with hybrid execution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuda.pathfinder import load_nvidia_dynamic_lib\n",
    "import os\n",
    "\n",
    "# Locate the cuDSS library and find the OpenMP multithreading layer\n",
    "loaded_dl = load_nvidia_dynamic_lib(\"cudss\")\n",
    "gomp_lib_path = os.path.dirname(loaded_dl.abs_path) + \"/libcudss_mtlayer_gomp.so.0\"\n",
    "\n",
    "# Create a cuDSS handle for low-level library access\n",
    "h = nvmath.bindings.cudss.create()\n",
    "\n",
    "# Configure solver options with the handle and multithreading library\n",
    "o = nvmath.sparse.advanced.DirectSolverOptions(\n",
    "    handle=h,\n",
    "    multithreading_lib=gomp_lib_path\n",
    ")\n",
    "\n",
    "# Solve the linear system with hybrid CPU-GPU execution\n",
    "x = nvmath.sparse.advanced.direct_solver(a, b, options=o, execution=\"hybrid\")\n",
    "\n",
    "# Validate the solution\n",
    "residual = cp.linalg.norm(a @ x - b)\n",
    "print(f\"Hybrid execution completed successfully!\")\n",
    "print(f\"Residual L2 norm ||A*x - b|| = {residual:.2e}\")\n",
    "\n",
    "# Clean up: destroy the cuDSS handle\n",
    "nvmath.bindings.cudss.destroy(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c69b8c4",
   "metadata": {},
   "source": [
    "**Key Observations:**\n",
    "\n",
    "- With hybrid execution configured, you should no longer see the multithreading warning.\n",
    "- The residual remains very small, confirming the solution accuracy is maintained.\n",
    "- Hybrid execution can provide performance benefits, especially during the planning and symbolic factorization phases.\n",
    "- The `execution` parameter accepts values like `\"hybrid\"` (GPU-CPU), or `\"device\"` (GPU-only)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9921714",
   "metadata": {},
   "source": [
    "## Exercise: Implement a sparse solver for multiple RHS using nvmath-python\n",
    "\n",
    "**nvmath-python** supports batched operands in the sparse solver. We distinguish explicit batching, where the samples of a batch are a sequence of matrices (or vectors for the RHS), and implicit batching, where the samples are inferred from 3D or higher-dimensional tensors for the LHS and RHS. The batching for the LHS and RHS can be independent - the LHS can be batched explicitly while the RHS can be batched implicitly and *vice-versa*. Each sample in an explicitly batched system can be of different size (number of equations), resulting in a flexible user interface.\n",
    "\n",
    "In this exercise you will implement an implicit batching for multiple RHS, represented as a matrix. For simplicity you will use randomly generated RHS. To control the correctness you will compute the L2-norm residual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f603bcfe",
   "metadata": {},
   "source": [
    "### 1. Load matrix object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssgetpy\n",
    "\n",
    "mtx_obj = ssgetpy.search()[2] # 2 is the index of the matrix in the SuiteSparse Matrix Collection\n",
    "mtx_obj # Display the matrix object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c8e83",
   "metadata": {},
   "source": [
    "### 2. Download Matrix Market file as COO matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e887006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "path, _ = mtx_obj.download(extract=True) # Download selected matrix and unpack it\n",
    "spm_coo = scipy.io.mmread(f\"{path}/{path.split('/')[-1]}.mtx\") # Read the unpacked Matrix Market file into COO matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204291b1",
   "metadata": {},
   "source": [
    "### 3. Transfer to GPU and run the solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvmath\n",
    "import cupy as cp\n",
    "import cupyx as cpx\n",
    "from cuda.pathfinder import load_nvidia_dynamic_lib\n",
    "import os\n",
    "\n",
    "\n",
    "# Locate the cuDSS library and find the OpenMP multithreading layer\n",
    "loaded_dl = load_nvidia_dynamic_lib(\"cudss\")\n",
    "gomp_lib_path = os.path.dirname(loaded_dl.abs_path) + \"/libcudss_mtlayer_gomp.so.0\"\n",
    "\n",
    "# Create a cuDSS handle for low-level library access\n",
    "h = nvmath.bindings.cudss.create()\n",
    "\n",
    "# Configure solver options with the handle and multithreading library\n",
    "o = nvmath.sparse.advanced.DirectSolverOptions(\n",
    "    handle=h,\n",
    "    multithreading_lib=gomp_lib_path\n",
    ")\n",
    "\n",
    "\n",
    "# Transfer sparse matrix to GPU using CuPy\n",
    "# CuPy can directly convert from SciPy sparse matrices\n",
    "# TODO: Convert COO matrix to CSR format (more efficient for the solver)\n",
    "\n",
    "# Create the right-hand side vectors for implicit batching. Note that the RHS must be a column-major array\n",
    "# TODO: Create a random RHS matrix with the same number of columns as the number of unknowns in the matrix\n",
    "\n",
    "# Solve the linear system with GPU-only execution\n",
    "# TODO: Solve the linear system with GPU-only execution. Do not forget to pass the options to the solver.\n",
    "\n",
    "# Validate the solution\n",
    "# TODO: Compute the L2-norm residual\n",
    "\n",
    "# Clean up: destroy the cuDSS handle\n",
    "# TODO: Destroy the cuDSS handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eac08f",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored **nvmath-python**'s sparse direct solver capabilities for solving large linear systems with sparse matrices. We demonstrated how to work with real-world sparse matrices from the SuiteSparse Matrix Collection and leverage GPU acceleration for efficient computation.\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "- **Sparse direct solvers** are essential for efficiently solving linear systems where the coefficient matrix is sparse (mostly zeros).\n",
    "- **nvmath-python** provides a high-level interface to NVIDIA's cuDSS library through `nvmath.sparse.advanced.direct_solver`.\n",
    "- The solver seamlessly integrates with Python's scientific computing ecosystem, accepting **SciPy**, **CuPy**, and **PyTorch** sparse matrices.\n",
    "- **CSR (Compressed Sparse Row)** format is the primary sparse matrix format for the solver, offering efficient storage and computation.\n",
    "- **Hybrid CPU-GPU execution** can optimize performance by distributing work intelligently between CPU and GPU.\n",
    "- Solution accuracy can be validated by computing the **residual norm** $ \\|A \\cdot x - b\\| $, which should be close to machine precision for well-conditioned problems.\n",
    "- The solver supports various matrix types including general, symmetric, Hermitian, SPD, and HPD matrices.\n",
    "\n",
    "**Practical Applications:**\n",
    "\n",
    "Sparse direct solvers are widely used in:\n",
    "- Finite element analysis and structural engineering\n",
    "- Circuit simulation and electronic design automation\n",
    "- Computational fluid dynamics\n",
    "- Optimization problems with sparse constraints\n",
    "- Graph algorithms and network analysis\n",
    "- Image processing and computer graphics\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "- Explore other nvmath-python tutorials:\n",
    "  - [01_kernel_fusion.ipynb](01_kernel_fusion.ipynb) - Learn about kernel fusion optimization\n",
    "  - [02_mem_exec_spaces.ipynb](02_mem_exec_spaces.ipynb) - Understanding memory and execution spaces\n",
    "  - [03_stateful_api.ipynb](03_stateful_api.ipynb) - Stateful APIs and autotuning\n",
    "  - [04_callbacks.ipynb](04_callbacks.ipynb) - FFT callbacks\n",
    "  - [05_device_api.ipynb](05_device_api.ipynb) - Device APIs\n",
    "- Try solving different types of sparse systems from the SuiteSparse Collection\n",
    "- Experiment with different execution modes (`\"device\"`, `\"hybrid\"`) and measure performance\n",
    "- Explore advanced solver options for specialized matrix types (symmetric, positive definite, etc.)\n",
    "\n",
    "---\n",
    "## References\n",
    "\n",
    "- NVIDIA nvmath-python documentation, \"Sparse Solver\", https://docs.nvidia.com/cuda/nvmath-python/latest/. Accessed: November 4, 2025.\n",
    "- NVIDIA cuDSS library, \"Direct Sparse Solver\", https://developer.nvidia.com/cudss. Accessed: November 4, 2025.\n",
    "- Davis, Timothy A., et al., \"The SuiteSparse Matrix Collection\", ACM Transactions on Mathematical Software, 45(2), 1-25, 2019.\n",
    "- Saad, Yousef, \"Iterative Methods for Sparse Linear Systems\", 2nd Edition, SIAM, 2003.\n",
    "- Davis, Timothy A., \"Direct Methods for Sparse Linear Systems\", SIAM, 2006.\n",
    "- Amestoy, Patrick R., et al., \"A Fully Asynchronous Multifrontal Solver Using Distributed Dynamic Scheduling\", SIAM Journal on Matrix Analysis and Applications, 23(1), 15-41, 2001.\n",
    "- Matrix Market format specification, https://math.nist.gov/MatrixMarket/formats.html. Accessed: November 4, 2025.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
