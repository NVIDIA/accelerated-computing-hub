{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0 AND CC-BY-NC-4.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d1a30",
   "metadata": {},
   "source": [
    "<img src=\"./images/nvmath_head_panel@0.5x.png\" alt=\"nvmath-python\" />\n",
    "\n",
    "# Getting Started with nvmath-python: FFT Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc7412",
   "metadata": {},
   "source": [
    "## Exercise: Applying Sepia and Gaussian blur filters to an image\n",
    "\n",
    "In this exercise you will perform the following steps:\n",
    "1. Load the color image using `PIL`.\n",
    "2. Create and compile the *Sepia* filter for the R2C FFT prolog \n",
    "3. Create and compile the *Gaussian Blur* filter for the C2R FFT prolog.\n",
    "4. Perform forward FFT with the compiled Sepia filter prolog.\n",
    "5. Perform backward C2R FFT with the compiled Gaussian Blur filter prolog.\n",
    "6. Display the processed image using `matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db740be",
   "metadata": {},
   "source": [
    "The following NumPy implementation is a reference code for you to follow while implementing nvmath-python variant with forward FFT prolog and epilog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Load the color image using PIL\n",
    "# Load the color image and convert it to NumPyarray normalized to [0, 1]\n",
    "asset_path = \"./images/\"\n",
    "original_image = np.array(Image.open(asset_path + \"dog.jpg\")) / 255.0\n",
    "\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(original_image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "original_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46049168",
   "metadata": {},
   "source": [
    "Note the shape of the array: spatial data goes in dimensions 0 and 1, followed by color channels data.\n",
    "\n",
    "The following code is a reference implementation of the Sepia filter, which is a color matrix transformation applied to original pixels capped by 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEPIA_FILTER_MATRIX = np.array([\n",
    "    [0.393, 0.769, 0.189],\n",
    "    [0.349, 0.686, 0.168],\n",
    "    [0.272, 0.534, 0.131]\n",
    "]).T\n",
    "\n",
    "\n",
    "def sepia_filter(image):\n",
    "    \"\"\"\n",
    "    Apply sepia filter to the image.\n",
    "    Image shape: (height, width, 3)\n",
    "    Returns: (height, width, 3)\n",
    "    \"\"\"\n",
    "    # Apply filter: (height*width, 3) @ (3, 3) = (height*width, 3)\n",
    "    return np.minimum(1.0, image @ SEPIA_FILTER_MATRIX)\n",
    "\n",
    "\n",
    "sepia_image = sepia_filter(original_image)\n",
    "\n",
    "# Display the sepia image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(sepia_image)\n",
    "plt.title(\"Sepia Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed72b47",
   "metadata": {},
   "source": [
    "Finally we apply Gaussian Blur filter implemented through R2C and C2R FFTs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553fe7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 20.0\n",
    "fy = np.fft.fftfreq(sepia_image.shape[0])[:, None]  # column vector\n",
    "fx = np.fft.rfftfreq(sepia_image.shape[1])[None, :]  # row vector for R2C (only positive frequencies)\n",
    "h = np.exp(-2.0 * np.pi * np.pi * sigma * sigma * (fx * fx + fy * fy)).astype(np.complex64)\n",
    "print(h.shape)\n",
    "\n",
    "\n",
    "def gaussian_filter_numpy(image):\n",
    "    # Apply FFT on spatial dimensions (axes 0 and 1), leaving color channel intact\n",
    "    image_fft = np.fft.rfft2(image, axes=(0, 1))  # Real to complex FFT\n",
    "    blurred = np.fft.irfft2(image_fft * h[..., None], axes=(0, 1))  # Complex to real FFT\n",
    "    return blurred\n",
    "\n",
    "blurred_image = gaussian_filter_numpy(sepia_image)\n",
    "\n",
    "# Display the blurred image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(blurred_image)\n",
    "plt.title(\"Sepia & Blurred Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faeb401",
   "metadata": {},
   "source": [
    "Note the shape of `h`: for R2C FFT we neeed only positive frequences, hence the size in `fx` dimension is `image.shape[1] // 2 + 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d284cc",
   "metadata": {},
   "source": [
    "Now porting the NumPy implementation to GPU with CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd589303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvmath # Workaround for CuPy: CTK shared objects preload from wheels\n",
    "import cupy as cp\n",
    "\n",
    "image_gpu = cp.asarray(original_image, dtype=cp.float32)\n",
    "SEPIA_FILTER_MATRIX_GPU = cp.asarray(SEPIA_FILTER_MATRIX).astype(cp.float32)\n",
    "\n",
    "\n",
    "def sepia_filter(image):\n",
    "    return cp.minimum(1.0, image @ SEPIA_FILTER_MATRIX_GPU)\n",
    "\n",
    "\n",
    "sepia_image = sepia_filter(image_gpu)\n",
    "\n",
    "# Display the sepia image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(sepia_image.get())\n",
    "plt.title(\"Sepia Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 20.0\n",
    "fy = cp.fft.fftfreq(sepia_image.shape[0])[:, None].astype(cp.float32)  # column vector\n",
    "fx = cp.fft.rfftfreq(sepia_image.shape[1])[None, :].astype(cp.float32)  # row vector for R2C (only positive frequencies)\n",
    "h = cp.exp(-2.0 * np.pi * np.pi * sigma * sigma * (fx * fx + fy * fy)).astype(cp.complex64)\n",
    "\n",
    "\n",
    "def gaussian_filter_cupy(image):\n",
    "    # Apply FFT on spatial dimensions (axes 0 and 1), leaving color channel intact\n",
    "    image_fft = cp.fft.rfft2(image, axes=(0, 1))  # Real to complex FFT\n",
    "    blurred = cp.fft.irfft2(image_fft * h[..., None], axes=(0, 1))  # Complex to real FFT\n",
    "    return blurred\n",
    "\n",
    "blurred_image = gaussian_filter_cupy(sepia_image)\n",
    "\n",
    "# Display the blurred image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(blurred_image.get())\n",
    "plt.title(\"Sepia & Blurred Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba30fa",
   "metadata": {},
   "source": [
    "Finally, we get to implement the above code using nvmath-python with compiled prolog and epilog functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions over which FFT is performed must be contiguous in memory\n",
    "image_gpu = cp.asarray(original_image, dtype=cp.float32).transpose(2, 0, 1)\n",
    "wh = image_gpu.shape[1] * image_gpu.shape[2]\n",
    "h_size = h.size\n",
    "\n",
    "def sepia_prolog_impl(data_in, offset, user_info, unused):\n",
    "    channel_idx = offset % 3\n",
    "    pixel_idx = offset - channel_idx\n",
    "    r = data_in[pixel_idx]\n",
    "    g = data_in[pixel_idx + 1]\n",
    "    b = data_in[pixel_idx + 2]\n",
    "    if channel_idx == 0:\n",
    "        new_r = r * 0.393 + g * 0.769 + b * 0.189\n",
    "        return min(1.0, new_r)\n",
    "    elif channel_idx == 1:\n",
    "        new_g = r * 0.349 + g * 0.686 + b * 0.168\n",
    "        return min(1.0, new_g)\n",
    "    else:\n",
    "        new_b = r * 0.272 + g * 0.534 + b * 0.131\n",
    "        return min(1.0, new_b)\n",
    "\n",
    "\n",
    "def blur_prolog_impl(data_in, offset, filter_data, unused):\n",
    "    # Offset is a flattened index of the three (R, G, B) FFTs. Each FFT has size h.size \n",
    "    return data_in[offset] * filter_data[offset % h_size] / wh  # Normalize by the image area\n",
    "\n",
    "sepia_prolog = nvmath.fft.compile_prolog(sepia_prolog_impl, \"float32\", \"float32\")\n",
    "blur_prolog = nvmath.fft.compile_prolog(blur_prolog_impl, \"complex64\", \"complex64\")\n",
    "\n",
    "fft_image = nvmath.fft.rfft(image_gpu, axes=(1, 2), prolog={\"ltoir\": sepia_prolog, \"data\": None})\n",
    "filtered_image = nvmath.fft.irfft(fft_image, axes=(1, 2), prolog={\"ltoir\": blur_prolog, \"data\": h.data.ptr})\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.imshow(filtered_image.transpose(1, 2, 0).get())\n",
    "plt.title(\"Sepia & Blurred Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
