{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 1: DAXPY - Accelerating portable HPC Applications with Standard C++\n",
    "===\n",
    "\n",
    "This tutorial familiarizes you with the C++ parallel algorithms. We'll parallelize Double-precision $Y = A \\cdot X + Y$, also known as `DAXPY, one of the main algorithms in the standard Basic Linear Algebra Subroutines (BLAS) library. It scales double-precision elements of the vector $X$ with the scalar $A$, and adds its result to the vector $Y$.\n",
    "\n",
    "The vectors are initialized with `x[i] = i` and `y[i] = 2`, and all exercises validate your implementation by checking that `y = 2 + a * i`.\n",
    "\n",
    "## Sequential implementation\n",
    "\n",
    "A working sequential implementation is provided in [starting_point.cpp]. All exercises focus on the following two main functions:\n",
    "\n",
    "```c++\n",
    "/// Intialize vectors `x` and `y`: raw loop sequential version\n",
    "void initialize(std::vector<double> &x, std::vector<double> &y) {\n",
    "  for (std::size_t i = 0; i < x.size(); ++i) {\n",
    "    x[i] = (double)i;\n",
    "    y[i] = 2.;\n",
    "  }\n",
    "}\n",
    "\n",
    "/// DAXPY: AX + Y: raw loop sequential version\n",
    "void daxpy(double a, std::vector<double> const &x, std::vector<double> &y) {\n",
    "  for (std::size_t i = 0; i < y.size(); ++i)\n",
    "    y[i] += a * x[i];\n",
    "}\n",
    "```\n",
    "\n",
    "[starting_point.cpp]: ./starting_point.cpp\n",
    "\n",
    "Let's start by checking the version of some of the compilers installed in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ --version\n",
    "!clang++ --version\n",
    "!nvc++ --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now let's define a size for all problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compile and run the starting point with that size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -std=c++23 -o daxpy starting_point.cpp && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the `-std=c++23` selects the C++ language standard.\n",
    "\n",
    "Let's enable optimizations with `-Ofast`, disabling debug checks `-DNDEBUG`, and compiling for the current CPU using `-march=native`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -std=c++23 -Ofast -march=native -DNDEBUG -o daxpy starting_point.cpp && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance with optimizations is much higher.\n",
    "\n",
    "We'll use these exact same flags for all compilers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=\"-std=c++23 -Ofast -march=native -DNDEBUG -o daxpy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: From raw DAXPY loop to sequential C++ `std::for_each_n` algorithm\n",
    "\n",
    "The goal of this first exercise is to re-write the raw DAXPY loop by combining:\n",
    "- the C++ standard library [std::for_each_n] algorithm, and\n",
    "- [std::views::iota] to create an iterator over a range of integers.\n",
    "\n",
    "You can click on the C++ API name links (e.g. on [std::for_each_n]) to access their documentation. \n",
    "\n",
    "In this exercise, we'll use [std::views::iota] to get an iterator over a range of integers starting at zero as follows:\n",
    "\n",
    "```c++\n",
    "auto range = std::views::iota(0); // Range of integers: [0, int_max).\n",
    "auto it    = range.begin();       // Iterator to first element of range (0).\n",
    "```\n",
    "\n",
    "and pass it to the [std::for_each_n] algorithm, whose API is:\n",
    "\n",
    "```c++\n",
    "std::for_each_n(\n",
    "    Iterator begin,      // Iterator to the first element of the range.\n",
    "    size_t length,   // Number of range elements to process.\n",
    "    UnaryFunction op // Operation applied to each element in the range: op(e) . \n",
    "); \n",
    "```\n",
    "\n",
    "to replace the sequential raw loop in the implementation of `daxpy` with [std::for_each_n] as follows:\n",
    "\n",
    "```c++\n",
    "// [Before] Raw-loop: \n",
    "for (std::size_t i = 0; i < y.size(); ++i) {\n",
    "    ...\n",
    "}\n",
    "    \n",
    "// [After] Algorithm:\n",
    "std::for_each_n(std::views::iota(0).begin(), y.size(), [](int i) {\n",
    "    ...\n",
    "});\n",
    "\n",
    "```\n",
    "\n",
    "The top folder of this notebook provides templates for implementing the solution.\n",
    "These contains `// TODO` comments to help you focus on the parts of the file that need to be modified.\n",
    "There is no need to modify any other place in the program. \n",
    "Please use these templates when working on the exercises.\n",
    "\n",
    "A template for the solution is provided in the [exercise1.cpp] file.\n",
    "We need to fix the `TODO`s in the template:\n",
    "\n",
    "```c++\n",
    "#include <chrono>\n",
    "// TODO: add C++ standard library includes as necessary\n",
    "// #include <algorithm>\n",
    "// #include <ranges>\n",
    "\n",
    "/// DAXPY: AX + Y: sequential algorithm version\n",
    "void daxpy(double a, std::vector<double> const &x, std::vector<double> &y) {\n",
    "  // TODO: replace this raw loop with an algorithm:\n",
    "  // for (std::size_t i = 0; i < y.size(); ++i) {\n",
    "  //   y[i] += a * x[i];\n",
    "  // }\n",
    "  // Using: \n",
    "  // - std::views::iota(0).begin() iterator\n",
    "  // - std::for_each_n algorithm\n",
    "  // std::for_each_n(std::views::iota(0).begin(), x.size(), [&](int i) {\n",
    "  //  y[i] += a * x[i];\n",
    "  // });\n",
    "}\n",
    "```\n",
    "\n",
    "This next cell compiles and runs the template to test your solution. Without modifications, the template compiles, but produces incorrect results because the `daxpy` implementation is empty. Once you fix it, the following cells should compile and run correctly.\n",
    "\n",
    "[exercise1.cpp]: ./exercise1.cpp\n",
    "[std::for_each_n]: https://en.cppreference.com/w/cpp/algorithm/for_each_n\n",
    "[std::views::iota]: https://en.cppreference.com/w/cpp/ranges/iota_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]     \" && rm -f daxpy && g++     {flags} exercise1.cpp && ./daxpy {N}\n",
    "!echo -n \"[clang++] \" && rm -f daxpy && clang++ {flags} exercise1.cpp && ./daxpy {N}\n",
    "!echo -n \"[nvc++]   \" && rm -f daxpy && nvc++   {flags} exercise1.cpp && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions Exercise 1\n",
    "\n",
    "The solutions for each example are available in the [solutions/] sub-directory.\n",
    "\n",
    "The following block compiles and run the solutions at [solutions/exercise1.cpp] using different compilers:\n",
    "\n",
    "[solutions/]: ./solutions\n",
    "[solutions/exercise1.cpp]: ./solutions/exercise1.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]     \" && rm -f daxpy && g++     {flags} solutions/exercise1.cpp && ./daxpy {N}\n",
    "!echo -n \"[clang++] \" && rm -f daxpy && clang++ {flags} solutions/exercise1.cpp && ./daxpy {N}\n",
    "!echo -n \"[nvc++]   \" && rm -f daxpy && nvc++   {flags} solutions/exercise1.cpp && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Parallelizing DAXPY with execution policies\n",
    "\n",
    "To run DAXPY in parallel, we need to:\n",
    "- obtain access to the execution policies by `#include <execution>` header,\n",
    "- pass the [std::execution::par] policy as the first argument of the [std::for_each_n] algorithm,\n",
    "- enable the parallel algorithms via compiler options.\n",
    "\n",
    "A template for the solution is provided in the [exercise2.cpp] file.\n",
    "We need to fix the `TODO`s in the template:\n",
    "\n",
    "```c++\n",
    "#include <algorithm>\n",
    "// TODO: add C++ standard library includes as necessary\n",
    "// #include <execution>\n",
    "\n",
    "/// DAXPY: AX + Y: parallel algorithm version\n",
    "void daxpy(double a, std::vector<double> const &x, std::vector<double> &y) {\n",
    "  std::for_each_n(// TODO: pass std::execution::par, as first argument \n",
    "                  std::views::iota(0).begin(), x.size(), [&](int i) {\n",
    "    y[i] += a * x[i];\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "This next cell compiles and runs the template to test your solution.\n",
    "It already contains the right compilation options to enable the parallel algorithms in the different compilers: \n",
    "- `clang` and `gcc`: need to link with the TBB library using the `-ltbb` flag, because their parallel algorithms implementation depends on it.\n",
    "- `nvc++`: need to use the `-stdpar=multicore` or `-stdpar=gpu` flags, to enable the parallel algorithm and select where they'll run.\n",
    "\n",
    "Once you make the changes, you should see the performance increase while the tests still pass.\n",
    "\n",
    "[exercise2.cpp]: ./exercise2.cpp\n",
    "[std::for_each_n]: https://en.cppreference.com/w/cpp/algorithm/for_each_n\n",
    "[std::execution::par]: https://en.cppreference.com/w/cpp/algorithm/execution_policy_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} exercise2.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} exercise2.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} exercise2.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} exercise2.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions Exercise 2\n",
    "\n",
    "The following block compiles and run the solutions at [solutions/exercise2.cpp] using different compilers:\n",
    "\n",
    "[solutions/exercise2.cpp]: ./solutions/exercise2.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} solutions/exercise2.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} solutions/exercise2.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise2.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise2.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Improving lambda captures for GPU performance\n",
    "\n",
    "In the previous execise, our parallel implementation captures everything in the lambda by reference, i.e., with a `[&](...) { ... }` capture clause. This only works on heterogeneous platforms that are coherent, like the one this notebook is running on. On hardware-coherent platforms, like Grace Hopper, it works really well, but in software-coherent platforms, it does not deliver the best performance.\n",
    "\n",
    "In this exercise, we will learn how to write code that works on non-coherent platforms, and performs well on all platforms. \n",
    "The solution to both issues is the same: modify our lambda's to capture all arguments by value. So instead of `[&]` we need to use `[a, x = x.data(), y = y.data()]`, where:\n",
    "- `[a]`: captures `a` by value, i.e., copies the scalar `a` into the lambda.\n",
    "- `[x = x.data(), y = y.data()]`: captures pointers to the data of `x` and `y` by value (i.e., this does not make a copy of the vectors, like `[x, y]` would do).\n",
    "\n",
    "A template for the solution is provided in the [exercise3.cpp] file.\n",
    "We need to fix the `TODO`s in the template:\n",
    "\n",
    "```c++\n",
    "void daxpy(double a, std::vector<double> const &x, std::vector<double> &y) {\n",
    "  std::for_each_n(std::execution::par,\n",
    "                  std::views::iota(0).begin(), x.size(),  \n",
    "    // TODO: instead of by reference [&], capture by value using:\n",
    "    // [a, x = x.data(), y = y.data()]\n",
    "    [&](int i) {\n",
    "        y[i] += a * x[i];\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "This next cell compiles and runs the template to test your solution.\n",
    "Once you make the changes, you should see the performance increase while the tests still pass.\n",
    "\n",
    "[exercise3.cpp]: ./exercise3.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} exercise3.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} exercise3.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} exercise3.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} exercise3.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions Exercise 3\n",
    "\n",
    "The following block compiles and run the solutions at [solutions/exercise3.cpp] using different compilers:\n",
    "\n",
    "[solutions/exercise3.cpp]: ./solutions/exercise3.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} solutions/exercise3.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} solutions/exercise3.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise3.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise3.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Know your algorithms: `transform_reduce`\n",
    "\n",
    "In this exercise, we'll parallelize a variant of `daxpy` called `daxpy_sum` that, on top of applying daxpy, also adds all elements of `y` up, i.e., also performs a reduction: \n",
    "\n",
    "```c++\n",
    "/// DAXPY: AX + Y and returns sum(Y)\n",
    "double daxpy_sum(double a, std::vector<double> const &x, std::vector<double> &y) {\n",
    "  auto ints = std::views::iota(0, (int)x.size());\n",
    "  double sum = 0.;\n",
    "  for (auto i : ints) {\n",
    "    y[i] += a * x[i];\n",
    "    sum += y[i];\n",
    "  }\n",
    "  return sum;\n",
    "}\n",
    "```\n",
    "\n",
    "Since C++ does not allow multiple threads to mutate a single shared value without extra synchronization (like the one provided by locks or atomic operations), we **cannot** easily solve this exercise by just using [std::for_each_n] like we did above, and directly updating `sum` concurrently from within the lambda:\n",
    "\n",
    "```c++\n",
    "void daxpy(double a, std::vector<double> const &x, std::vector<double> &y) {\n",
    "  double sum = 0.;\n",
    "  std::for_each_n(std::execution::par,\n",
    "                  std::views::iota(0).begin(), x.size(),    \n",
    "    [&sum, a, x = x.data(), y = y.data()](int i) {\n",
    "        y[i] += a * x[i];\n",
    "        sum += y[i]; // ERROR (undefined behavior): concurrent accesses to \"sum\".\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "The [std::transform_reduce] algorithm from the `<numeric>` header provides a simple and efficient way to solve this problem. It iterates over all elements of the range, and:\n",
    "- applies a function `map` that _transforms_ a range element `e` of type `T` into a different value of type `U`: `map(T e) -> U;`,\n",
    "- returns the combination of multiple transformations into a single value via a binary _reduction_ operation `red(U a, U b) -> U`,\n",
    "- guarantees that `map` is called _exactly once_ per range element.\n",
    "\n",
    "For a three element range: `[e0, e1, e2]`, the final result is `U res = red(red(map(e0), map(e1)), map(e2));`.\n",
    "\n",
    "The [std::transform_reduce] algorithm is available via `#include <numeric>`.\n",
    "The API of [std::transform_reduce] we will be using is the (3)rd overload in its API documentation:\n",
    "\n",
    "```c++\n",
    "template <typename Iter, typename T, typename BinaryReduction, typename UnaryFunction>\n",
    "T transform_reduce(std::execution::par,       // Execution policy.\n",
    "                   Iter begin, Iter end,      // [begin, end) range.\n",
    "                   U init,                    // Inital value for reduction.\n",
    "                   BinaryReduction red,       // Binary reduction: r(U x, U y) -> U above.\n",
    "                   UnaryFunction   map);      // Unary function m(T e) -> U applied to every element in [begin, end).\n",
    "```\n",
    "\n",
    "For `daxpy_sum` we need to:\n",
    "- Perform the daxpy update `y[i] += a * x[i]` as part of the transform; this relies on the transform operation being called exactly once per range element.\n",
    "- Return the updated value `y[i]` after the update from the transformation.\n",
    "- Add all the updated values with the binary reduction operation [std::plus] from the `#include <functional>`.\n",
    "\n",
    "A template for the solution is provided in the [exercise4.cpp] file.\n",
    "We need to fix the `TODO`s in the template:\n",
    "\n",
    "```c++\n",
    "// TODO: add C++ standard library includes as necessary\n",
    "// #include <numeric> // std::transform_reduce is in the <numeric> header!\n",
    "double daxpy_sum(double a, std::vector<double> const &x, std::vector<double> &y) {\n",
    "  // TODO: create a range of integers [0, x.size()).\n",
    "  // NOTE: iota(begin, end) takes integers of the same type!\n",
    "  auto ints = std::views::iota(0, (int)x.size());\n",
    "  // TODO: call transform_reduce on the integer range, using:\n",
    "  // - \"0.\" as the initial value, and\n",
    "  // - `std::plus{}` as the binary reduction:\n",
    "  return std::transform_reduce(std::execution::par, ints.begin(), ints.end(), /* 0. */, /* std::plus{} */, \n",
    "    [a, x = x.data(), y = y.data()](int i) {\n",
    "        // TODO: perform saxpy update:\n",
    "        // y[i] += a * x[i];\n",
    "        // TODO: return the updated value:\n",
    "        return /* y[i] */;\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "This next cell compiles and runs the template to test your solution.\n",
    "Once you make the changes, you should see the performance increase while the tests still pass.\n",
    "\n",
    "[exercise4.cpp]: ./exercise4.cpp\n",
    "[std::for_each_n]: https://en.cppreference.com/w/cpp/algorithm/for_each_n\n",
    "[std::transform_reduce]: https://en.cppreference.com/w/cpp/algorithm/transform_reduce\n",
    "[std::plus]: https://en.cppreference.com/w/cpp/utility/functional/plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} exercise4.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} exercise4.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} exercise4.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} exercise4.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions Exercise 4\n",
    "\n",
    "The following block compiles and run the [`solutions/exercise4.cpp`]:\n",
    "\n",
    "[`solutions/exercise4.cpp`]: ./solutions/exercise4.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} solutions/exercise4.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} solutions/exercise4.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise4.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise4.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Exercise 5: Know your algorithms: `fill_n`\n",
    "\n",
    "In this exercise, we are going to parallelize the `initialize` function as follows: \n",
    "- Initialize `x[i] = i;` using [std::for_each_n] with [std::views::iota], just like in the previous exercise.\n",
    "- Initialize `y[i] = 2.;` using the [std::fill_n] algorithm, which writes the same value to all elements of a range.\n",
    "\n",
    "```c++\n",
    "/// Intialize vectors `x` and `y`: parallel algorithm version\n",
    "void initialize(std::vector<double> &x, std::vector<double> &y) {\n",
    "  // TODO: parallelize the initialization using\n",
    "  //  - for_each_n + views::iota to initialize x\n",
    "  //  - fill_n to initialize y\n",
    "  // for (std::size_t i = 0; i < x.size(); ++i) {\n",
    "  //   x[i] = (double)i;\n",
    "  //   y[i] = 2.;\n",
    "  // }\n",
    "}\n",
    "```\n",
    "\n",
    "The API of [std::fill_n] is:\n",
    "\n",
    "```c++\n",
    "std::fill_n(std::execution::par, // Execution policy\n",
    "            iterator,            // Iterator to the elements, e.g., a pointer\n",
    "            number_of_elements,  // Number of elements\n",
    "            value);              // Value to initialize all elements to\n",
    "```\n",
    "\n",
    "A template for the solution is provided in [exercise5.cpp]; it compiles and runs as provided, but produces incorrect results due to the incomplete implementation of the `initialize` function. Once you fix it, the following block should compile and run correctly.\n",
    "\n",
    "[std::fill_n]: https://en.cppreference.com/w/cpp/algorithm/fill_n \n",
    "[std::for_each_n]: https://en.cppreference.com/w/cpp/algorithm/for_each_n \n",
    "[std::views::iota]: https://en.cppreference.com/w/cpp/ranges/iota_view\n",
    "[exercise5.cpp]: ./exercise5.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} exercise5.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} exercise5.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} exercise5.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} exercise5.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions Exercise 5\n",
    "\n",
    "The following block compiles and run the solutions at [solutions/exercise5.cpp] using different compilers:\n",
    "\n",
    "[solutions/exercise5.cpp]: ./solutions/exercise5.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} solutions/exercise5.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} solutions/exercise5.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise5.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise5.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are done quickly, please continue with the optional [Lab 1: Select](../lab1_select/select.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Exercise 6: Process multiple elements per iteration with multi-dimensional span\n",
    "\n",
    "Until now, we've looked at the following 1D version of parallel `daxpy`:\n",
    "\n",
    "```c++\n",
    "/// 1D DAXPY: AX + Y: raw loop sequential version\n",
    "void daxpy(double a, std::vector<double> const &x, std::vector<double> &y) {\n",
    "  std::for_each_n(std::execution::par,\n",
    "                  std::views::iota(0).begin(), x.size(), \n",
    "                  [a, x = x.data(), y = y.data()](int i) { \n",
    "      y[i] += a * x[i]; \n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "In this exercise, we'll improve the following 2D version of `daxpy`, which processes multiple elements per \"task\" by _tiling_ the 1D vectors as 2D matrices:\n",
    "\n",
    "```c++\n",
    "void daxpy(double a, std::vector<double> const &x, std::vector<double> &y, size_t ncol = 2) {\n",
    "  assert(x.size() == y.size());\n",
    "  if (x.size() % ncols != 0) { \n",
    "      std::cerr << \"ERROR: size \" << x.size() << \" not divisible by \" << ncols << std::endl; \n",
    "      std::abort(); \n",
    "  }\n",
    "  size_t nrows = x.size() / ncols;\n",
    "\n",
    "  // Number of rows:\n",
    "  size_t N = x.size() / ncol;\n",
    "\n",
    "  // Parallel loop over rows:\n",
    "  double* xs = x.data();\n",
    "  double* ys = y.data();\n",
    "  std::for_each_n(std::execution::par,\n",
    "                  std::views::iota(0).begin(), N, [=](int i) { \n",
    "      // Sequential loop over columns:\n",
    "      for (size_t j = 0; j < ncol; ++j) {\n",
    "          // TODO: update to use mdspan\n",
    "          ys[j + i * ncol] += a * xs[j + i * ncol];\n",
    "      }\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "When performing this two-dimensional iteration over the 1D vectors, `xs` and `ys`, we need to manually map the two-dimensional indices, `i` and `j`, to one-dimensional indices, e.g., `j + i * ncol`. There are multiple choices of mappings we could pick, e.g., [row- vs col-major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order). Since the choice significantly impacts application performance, we want to be able to quickly change it throughout our applications, without introducing programmer errors, e.g., due to picking one mapping in one place, and a different one in another.\n",
    "\n",
    "[std::mdspan] provides a multi-dimensional view of 1D data-structures with a customizable mapping, ensuring the same mapping is used by all accesses, and allowing us to change the mapping safely in one single place of our application.\n",
    "\n",
    "A template for the solution is provided in [exercise6.cpp]: \n",
    "\n",
    "```c++\n",
    "/// 2D DAXPY: AX + Y: parallel algorithm version\n",
    "void daxpy(double a, std::vector<double> &x, std::vector<double> &y, size_t ncols = 2) {\n",
    "  assert(x.size() == y.size());\n",
    "  if (x.size() % ncols != 0) { \n",
    "      std::cerr << \"ERROR: size \" << x.size() << \" not divisible by \" << ncols << std::endl; \n",
    "      std::abort(); \n",
    "  }\n",
    "  size_t nrows = x.size() / ncols;\n",
    "\n",
    "  // TODO: use mdspan instead of raw pointers and manual indexing:\n",
    "  // std::mdspan xs { x.data(), nrows, ncols };\n",
    "  // std::mdspan ys { y.data(), nrows, ncols };\n",
    "  double* xs = x.data();\n",
    "  double* ys = y.data();\n",
    "  std::for_each_n(std::execution::par,\n",
    "                  std::views::iota(0).begin(), nrows, [=](int row) {\n",
    "        for (size_t col = 0; col < ncols; ++col) {\n",
    "            // TODO: use mdspan instead of raw pointers and manual indexing: \n",
    "            // ys(row, col) += a * xs(row, col);\n",
    "            size_t idx = row * ncols + col;\n",
    "            ys[idx] += a * xs[idx];\n",
    "        }\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "[std::mdspan]: https://en.cppreference.com/w/cpp/container/mdspan\n",
    "[exercise6.cpp]: ./exercise6.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} exercise6.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} exercise6.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} exercise6.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} exercise6.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions Exercise 6\n",
    "\n",
    "The following block compiles and run the solutions at [solutions/exercise6.cpp] using different compilers:\n",
    "\n",
    "[solutions/exercise6.cpp]: ./solutions/exercise6.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} solutions/exercise6.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} solutions/exercise6.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise6.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise6.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Exercise 7: Configuring `std::mdspan` layout\n",
    "\n",
    "Example 6 showed that the performance of the 2D DAXPY implementation is a bit lower than that of the 1D DAXPY implementations in the prior examples, even though they are all doing the same amount of work.\n",
    "\n",
    "In this example we'll learn how to recover the performance, by configuring the `std::mdspan` layout.\n",
    "\n",
    "In the previous example, we constructed the `std::mdspan` from the lengths of each dimension, called _extents_, as follows:\n",
    "\n",
    "```c++\n",
    "auto xs = stde::mdspan{x.data(), N, ncol};\n",
    "auto ys = stde::mdspan{y.data(), N, ncol};\n",
    "```\n",
    "\n",
    "This constructs the `std::mdspan` with the default layout mapping policy, [std::layout_right].\n",
    "We can constructing the `std::mdspan` from a different layout mapping policy, e.g., the one from [std::layout_left], as follows:\n",
    "\n",
    "```c++\n",
    "auto extents = ...;\n",
    "auto xs = stde::mdspan{x.data(), std::layout_left::mapping(extents)};\n",
    "auto ys = stde::mdspan{y.data(), std::layout_left::mapping(extents)};\n",
    "\n",
    "```\n",
    "\n",
    "To do so we need to construct a extents object describing the array's extents. Since both of our extents are _dynamic_ runtime values, we use [std::dextents]:\n",
    "\n",
    "```c++\n",
    "auto extents = std::dextents<size_t, 2>(N, ncol);\n",
    "auto xs = stde::mdspan{x.data(), std::layout_left::mapping(extents)};\n",
    "auto ys = stde::mdspan{y.data(), std::layout_left::mapping(extents)};\n",
    "\n",
    "```\n",
    "\n",
    "A template for the solution is provided in [exercise7.cpp]:\n",
    "\n",
    "```c++\n",
    "/// 2D DAXPY: AX + Y: parallel algorithm version\n",
    "void daxpy(double a, std::vector<double> &x, std::vector<double> &y, size_t ncols = 1) {\n",
    "  assert(x.size() == y.size());\n",
    "  if (x.size() % ncols != 0) { \n",
    "      std::cerr << \"ERROR: size \" << x.size() << \" not divisible by \" << ncols << std::endl; \n",
    "      std::abort(); \n",
    "  }\n",
    "  size_t nrows = x.size() / ncols;\n",
    "\n",
    "  // TODO: construct extents object.\n",
    "  // std::dextents<size_t, 2> extents(nrows, ncols);\n",
    "  // TODO: construct the layout mapping object:\n",
    "  // auto mapping = std::layout_left::mapping(extents);\n",
    "  // TODO: construct the mdspans from the mapping:\n",
    "  // std::mdspan xs { x.data(), mapping };\n",
    "  // std::mdspan ys { y.data(), mapping };\n",
    "  std::mdspan xs { x.data(), nrows, ncols };\n",
    "  std::mdspan ys { y.data(), nrows, ncols };\n",
    "  std::for_each_n(std::execution::par,\n",
    "                  std::views::iota(0).begin(), nrows, [=](int row) {\n",
    "        for (size_t col = 0; col < ncols; ++col) {\n",
    "            ys(row, col) += a * xs(row, col);\n",
    "        }\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "[exercise7.cpp]: ./exercise7.cpp\n",
    "[std::layout_right]: https://en.cppreference.com/w/cpp/container/mdspan/layout_right\n",
    "[std::dextents]: https://en.cppreference.com/w/cpp/container/mdspan/extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} exercise7.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} exercise7.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} exercise7.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} exercise7.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions Exercise 7\n",
    "\n",
    "The following block compiles and run the [`solutions/exercise7.cpp`]:\n",
    "\n",
    "[`solutions/exercise7.cpp`]: ./solutions/exercise7.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} solutions/exercise7.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} solutions/exercise7.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise7.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise7.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Multi-dimensional iteration with `std::views::cartesian_product`\n",
    "\n",
    "In this exercise, we'll learn how to use [std::views::cartesian_product] to iterate over multi-dimensional data such as the two-dimensional [std::mdspan] we've used Exercises 6 and 7. We've been using the [std::for_each_n] algorithm with an iterator and a count, combined with a sequential loop as follows:\n",
    "\n",
    "```c++\n",
    "  std::for_each_n(std::execution::par,\n",
    "                  std::views::iota(0).begin(), nrows, [=](int row) {\n",
    "        for (size_t col = 0; col < ncols; ++col) {\n",
    "            ys(row, col) += a * xs(row, col);\n",
    "        }\n",
    "  });\n",
    "```\n",
    "\n",
    "The goal of this exercise is to convert the above to use the [std::for_each] algorithm (without the `_n`), to iterate in parallel over a  [std::views::cartesian_product] view and, within the loop, obtain the indices for each dimension.\n",
    "\n",
    "A template for the solution is provided in [exercise8.cpp]:\n",
    "\n",
    "```c++\n",
    "/// 2D DAXPY: AX + Y: parallel algorithm version\n",
    "void daxpy(double a, std::vector<double> &x, std::vector<double> &y, int ncols = 1) {\n",
    "  assert(x.size() == y.size());\n",
    "  if (x.size() % ncols != 0) { \n",
    "      std::cerr << \"ERROR: size \" << x.size() << \" not divisible by \" << ncols << std::endl; \n",
    "      std::abort(); \n",
    "  }\n",
    "  int nrows = x.size() / ncols;\n",
    "\n",
    "  std::mdspan xs { x.data(), nrows, ncols };\n",
    "  std::mdspan ys { y.data(), nrows, ncols };\n",
    "  // TODO: Create a std::views::cartesian_product range spanning (0, nrows)x(0, ncols):\n",
    "  // auto is = std::views::cartesian_product(\n",
    "  //  std::views::iota(0, nrows),\n",
    "  //  std::views::iota(0, ncols)\n",
    "  // );\n",
    "  // TODO: Use the std::for_each (without _n) algorithm to iterate in parallel over the cartesian_product range:\n",
    "  // std::for_each(std::execution::par, is.begin(), is.end(), [=](auto i) {\n",
    "    // Each element of the cartesian_product range is a tuple containing one index per dimension.\n",
    "    // TODO: Extract the individual indices using structured bindings:\n",
    "    // auto [row, col] = i;\n",
    "    // ys(row, col) += a * xs(row, col);\n",
    "  // });\n",
    "}\n",
    "```\n",
    "\n",
    "[exercise8.cpp]: ./exercise8.cpp\n",
    "[std::views::cartesian_product]: https://en.cppreference.com/w/cpp/ranges/cartesian_product_view\n",
    "[std::mdspan]: https://en.cppreference.com/w/cpp/container/mdspan\n",
    "[std::for_each_n]: https://en.cppreference.com/w/cpp/algorithm/for_each_n\n",
    "[std::for_each]: https://en.cppreference.com/w/cpp/algorithm/for_each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} exercise8.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} exercise8.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} exercise8.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} exercise8.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions Exercise 8\n",
    "\n",
    "The following block compiles and run the [solutions/exercise8.cpp]:\n",
    "\n",
    "[solutions/exercise8.cpp]: ./solutions/exercise8.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -n \"[g++]       \" && rm -f daxpy && g++     {flags} solutions/exercise8.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[clang++]   \" && rm -f daxpy && clang++ {flags} solutions/exercise8.cpp -ltbb             && ./daxpy {N}\n",
    "!echo -n \"[nvc++ CPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise8.cpp -stdpar=multicore && ./daxpy {N}\n",
    "!echo -n \"[nvc++ GPU] \" && rm -f daxpy && nvc++   {flags} solutions/exercise8.cpp -stdpar=gpu       && ./daxpy {N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More optional exercises\n",
    "\n",
    "For more optional exercises, check out [Lab 1: Select](../lab1_select/select.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
