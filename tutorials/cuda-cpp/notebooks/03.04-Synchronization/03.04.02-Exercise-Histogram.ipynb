{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Fix Data Race\n",
    "\n",
    "You can use `__syncthreads()` to synchronize threads within a block:\n",
    "\n",
    "<img src=Images/sync.png alt=\"Sync\" width=800>\n",
    "\n",
    "Fix the data race using thread-block synchronization.\n",
    "Optionally, switch to `cuda::atomic_ref` to reduce the scope of communication:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Original code if you need to refer back to it.</summary>\n",
    "\n",
    "```c++\n",
    "%%writefile Sources/sync.cpp\n",
    "#include \"ach.cuh\"\n",
    "\n",
    "constexpr float bin_width = 10;\n",
    "\n",
    "// 1. Use `__syncthreads()` to synchronize threads within a block and avoid data race\n",
    "__global__ void histogram_kernel(\n",
    "  cuda::std::span<float> temperatures, \n",
    "  cuda::std::span<int> block_histograms, \n",
    "  cuda::std::span<int> histogram) \n",
    "{\n",
    "  cuda::std::span<int> block_histogram = \n",
    "    block_histograms.subspan(blockIdx.x * histogram.size(), \n",
    "                             histogram.size());\n",
    "\n",
    "  int cell = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int bin = static_cast<int>(temperatures[cell] / bin_width);\n",
    "\n",
    "  cuda::std::atomic_ref<int> block_ref(block_histogram[bin]);\n",
    "  block_ref.fetch_add(1);\n",
    "\n",
    "  if (threadIdx.x < histogram.size()) {\n",
    "    // 2. Reduce scope of atomic operation using `cuda::atomic_ref`\n",
    "    cuda::std::atomic_ref<int> ref(histogram[threadIdx.x]);\n",
    "    ref.fetch_add(block_histogram[threadIdx.x]);\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "void histogram(\n",
    "  cuda::std::span<float> temperatures, \n",
    "  cuda::std::span<int> block_histograms, \n",
    "  cuda::std::span<int> histogram,\n",
    "  cudaStream_t stream) \n",
    "{\n",
    "  int block_size = 256;\n",
    "  int grid_size = cuda::ceil_div(temperatures.size(), block_size);\n",
    "  histogram_kernel<<<grid_size, block_size, 0, stream>>>(\n",
    "    temperatures, block_histograms, histogram);\n",
    "}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"): # If running in Google Colab:\n",
    "  !mkdir -p Sources\n",
    "  !wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/tutorials/cuda-cpp/notebooks/03.04-Synchronization/Sources/ach.cuh -nv -O Sources/ach.cuh\n",
    "  !wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/tutorials/cuda-cpp/notebooks/03.04-Synchronization/Sources/__init__.py -nv -O Sources/__init__.py\n",
    "  !wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/tutorials/cuda-cpp/notebooks/03.04-Synchronization/Sources/ach.py -nv -O Sources/ach.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/sync.cpp\n",
    "#include \"ach.cuh\"\n",
    "\n",
    "constexpr float bin_width = 10;\n",
    "\n",
    "__global__ void histogram_kernel(\n",
    "  cuda::std::span<float> temperatures,\n",
    "  cuda::std::span<int> block_histograms,\n",
    "  cuda::std::span<int> histogram)\n",
    "{\n",
    "  // TODO: Find where to use `__syncthreads()` to synchronize threads within a\n",
    "  // block and avoid data race\n",
    "  cuda::std::span<int> block_histogram =\n",
    "    block_histograms.subspan(blockIdx.x * histogram.size(),\n",
    "                             histogram.size());\n",
    "\n",
    "  int cell = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int bin = static_cast<int>(temperatures[cell] / bin_width);\n",
    "\n",
    "  cuda::std::atomic_ref<int> block_ref(block_histogram[bin]);\n",
    "  block_ref.fetch_add(1);\n",
    "\n",
    "  if (threadIdx.x < histogram.size()) {\n",
    "    // TODO: Reduce scope of atomic operation using `cuda::atomic_ref`\n",
    "    cuda::std::atomic_ref<int> ref(histogram[threadIdx.x]);\n",
    "    ref.fetch_add(block_histogram[threadIdx.x]);\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "void histogram(\n",
    "  cuda::std::span<float> temperatures,\n",
    "  cuda::std::span<int> block_histograms,\n",
    "  cuda::std::span<int> histogram,\n",
    "  cudaStream_t stream)\n",
    "{\n",
    "  int block_size = 256;\n",
    "  int grid_size = cuda::ceil_div(temperatures.size(), block_size);\n",
    "  histogram_kernel<<<grid_size, block_size, 0, stream>>>(\n",
    "    temperatures, block_histograms, histogram);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Sources.ach\n",
    "Sources.ach.run(\"Sources/sync.cpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re unsure how to proceed, consider expanding this section for guidance. Use the hint only after giving the problem a genuine attempt.\n",
    "\n",
    "<details>\n",
    "  <summary>Hints</summary>\n",
    "  \n",
    "  - You can synchronize threads within a thread block using `__syncthreads()`\n",
    "  - You need to synchronize after all threads have incorporated their changes to the block histogram\n",
    "  - `cuda::atomic_ref` has exactly the same interface as `cuda::std::atomic_ref` with a difference of accepting thread scope as a second template parameter\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open this section only after you’ve made a serious attempt at solving the problem. Once you’ve completed your solution, compare it with the reference provided here to evaluate your approach and identify any potential improvements.\n",
    "\n",
    "<details>\n",
    "  <summary>Solution</summary>\n",
    "\n",
    "  Key points:\n",
    "\n",
    "  - Synchronize before reading the block histogram\n",
    "\n",
    "  Solution:\n",
    "  ```c++\n",
    "  cuda::std::span<int> block_histogram =\n",
    "    block_histograms.subspan(blockIdx.x * histogram.size(), histogram.size());\n",
    "\n",
    "  int cell = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int bin = static_cast<int>(temperatures[cell] / bin_width);\n",
    "\n",
    "  cuda::atomic_ref<int, cuda::thread_scope_block> \n",
    "    block_ref(block_histogram[bin]);\n",
    "  block_ref.fetch_add(1);\n",
    "  __syncthreads();\n",
    "\n",
    "  if (threadIdx.x < histogram.size()) \n",
    "  {\n",
    "    cuda::atomic_ref<int, cuda::thread_scope_device> \n",
    "      ref(histogram[threadIdx.x]);\n",
    "    ref.fetch_add(block_histogram[threadIdx.x]);\n",
    "  }\n",
    "  ```\n",
    "\n",
    "  You can find full solution [here](Solutions/sync.cpp).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Great job!  Move on to the [next section](../03.05-Shared-Memory/03.05.01-Shared.ipynb)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
