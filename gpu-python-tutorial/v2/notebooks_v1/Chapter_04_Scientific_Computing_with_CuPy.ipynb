{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d57565e-f93f-4878-bebc-deb6ca2fc195",
   "metadata": {},
   "source": [
    "# Chapter 4: Scientific Computing with CuPy\n",
    "\n",
    "<img src=\"images/chapter-04/cupy_title.png\" style=\"width:600px;\"/>\n",
    "\n",
    "CuPy is a NumPy and SciPy-compatible array library for GPU-accelerated computing with Python. CuPy acts as a drop-in replacement to run existing NumPy and SciPy code on NVIDIA CUDA or AMD ROCm platforms.\n",
    "\n",
    "CuPy is part of the Chainer project but has maintainers from many organisations including NVIDIA. CuPy implements the familiar Numpy API but with the backend written in CUDA C++. This allows folks who are already familiar with Numpy to get GPU acceleration out of the box quickly by just switching out an import.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f30728-3612-4d9f-a3d8-5b0053759f24",
   "metadata": {},
   "source": [
    "## CuPy Basics\n",
    "\n",
    "CuPy is a NumPy/SciPy-compatible array library for GPU-accelerated computing with\n",
    " Python. CuPy acts as a drop-in replacement to run existing NumPy/SciPy code on NVIDIA CUDA or AMD ROCm platforms.\n",
    "\n",
    "CuPy provides a multidimensional array, sparse matrices, and the associated routines for GPU devices, all having the same API as NumPy and SciPy.\n",
    "\n",
    "The goal of the CuPy project is to provide Python users GPU acceleration capabilities, without the in-depth knowledge of underlying GPU technologies. The CuPy team focuses on providing:\n",
    "- A complete NumPy and SciPy API coverage to become a full drop-in replacement, as well as advanced CUDA features to maximize the performance.\n",
    "- Mature and quality library as a fundamental package for all projects needing acceleration, from a lab environment to a large-scale cluster.\n",
    "\n",
    "### The N-Dimensional Array / Cupy.ndarray data structure\n",
    "\n",
    "The `cupy.ndarray` is the CuPy counterpart of NumPy `numpy.ndarray`. It provides \n",
    "an intuitive interface for a fixed-size multidimensional array which resides in a\n",
    " CUDA device. \n",
    "\n",
    "This class implements a subset of methods of numpy.ndarray. The difference is that this class allocates the array content on the current GPU device.\n",
    "\n",
    "### Memory Management\n",
    "\n",
    "CuPy uses a memory pool for memory allocation by default.  The memory pool significantly improves the performance by mitigating the overhead of memory allocation \n",
    "and CPU/GPU synchronization.\n",
    "\n",
    "There are two different memory pools in CuPy:\n",
    "- Device (GPU) memory pool - Used for GPU memory allocation.\n",
    "- Pinned (CPU) memory pool - Non-swappable memory used during CPU-to-GPU data tra\n",
    "nsfer.\n",
    "\n",
    "In most cases, CuPy users do not need to be aware of the specifics of memory allocation and deallocation, but it’s important to understand this optimization within CuPy in order to benchmark your application’s performance.  You may not see memory completely deallocated due to caching in the memory pool.\n",
    "\n",
    "CuPy provides both a high-level API to control this memory as well as a low-level API to CUDA memory management functions.  \n",
    "\n",
    "### Current Device\n",
    "\n",
    "CuPy has a concept of a current device, which is the default GPU device on which the allocation, manipulation, calculation, etc., of arrays take place (default id=0). All CuPy operations (except for multi-GPU features and device-to-device copy) are performed on the currently active device.\n",
    "\n",
    "In general, CuPy functions expect that the array is on the same device as the current one. Passing an array stored on a non-current device may work depending on the hardware configuration but is generally discouraged as it may not be performant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6feb576-fb49-487d-b518-f61c3c6dd2cf",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "### Cupy.ndarray\n",
    "\n",
    "`cupy.ndarrays` are the backbone of the CuPy ecosystem providing an intuitive counterpart to `numpy.ndarrays`.  `cupy.ndarrays`, like `numpy.ndarrays`, are a fixed-size multidimensional container of items of the same type and size\n",
    "\n",
    "### Cupy.ufuncs\n",
    "\n",
    "In NumPy, a universal function (or ufunc for short) is defined as a function that operates on ndarrays in an element-by-element fashion, supporting array broadcasting, type casting, and several other standard features.  In other words, a ufunc is a “vectorized” wrapper for a function that takes a fixed number of specific inputs and produces a fixed number of specific outputs.  These functions primarily operate on the NumPy array and constitute one of the most powerful ways to accelerate Python code. (see NumPy Universal Functions: https://numpy.org/doc/stable/reference/ufuncs.html)\n",
    "\n",
    "Similarly, CuPy implements a similar ufunc also supporting broadcasting, type casting, and output type determination.  Users can define `cupy.ufuncs` that mimic NumPy ufuncs on `cupy.ndarray` objects.  \n",
    "\n",
    "### NumPy and SciPy Coverage\n",
    "\n",
    "NumPy routines available: https://docs.cupy.dev/en/stable/reference/routines.html \n",
    "SciPy routines available: https://docs.cupy.dev/en/stable/reference/scipy.html \n",
    "\n",
    "While CuPy is designed to mimic NumPy, there are some limitations of using CuPy:\n",
    "- Not all NumPy and SciPy functions are compatible with CuPy.\n",
    "- CuPy may not always provide significant performance improvements. \n",
    "- Performance is highly dependent on the operations performed and the hardware used.\n",
    "\n",
    "There are also a few differences between CuPy and NumPy that might require adjustments in your code:\n",
    "- Cast behavior from float to integer can be hardware dependent.  This is a result of type conversion limitations within C++.\n",
    "- Random function differences.  The NumPy `random()` function does not support the `dtype` argument, but cuRAND, the random number generator under the hood in CuPy, does.  \n",
    "- CuPy handles out-of-bounds indices differently by default from NumPy when using integer array indexing. NumPy handles them by raising an error, but CuPy wraps around them.\n",
    "- Matrix type (`numpy.matrix`) - SciPy returns `numpy.matrix` (a subclass of `numpy.ndarray`) when dense matrices are computed from sparse matrices (e.g., `coo_matrix + ndarray`). However, CuPy returns `cupy.ndarray` for such operations.\n",
    "- CuPy arrays cannot be non-numeric like strings or objects.\n",
    "- Universal Functions in CuPy only work with CuPy array or scalar. They do not accept other objects (e.g., lists or `numpy.ndarray`).\n",
    "- Like Numpy, CuPy’s RandomState objects accept seeds either as numbers or as full numpy arrays.\n",
    "- NumPy’s reduction functions (e.g. `numpy.sum()`) return scalar values (e.g. `numpy.float32`). However CuPy counterparts return zero-dimensional `cupy.ndarrays`.\n",
    "\n",
    "There are more differences, but these are the most commonly encountered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404aafdc-1e3c-4707-b0d7-f67873f2b049",
   "metadata": {},
   "source": [
    "## Coding Guide\n",
    "\n",
    "### Installation \n",
    "\n",
    "Before setting up your CuPy programming environment, first ensure that you have fulfilled the following prerequisites:\n",
    "- CUDA-compatible GPU.  (see https://developer.nvidia.com/cuda-gpus for a list of NVIDIA GPUs)\n",
    "- CUDA-compatible NVIDIA Drivers.\n",
    "- CUDA Toolkit\n",
    "\n",
    "The version of your CUDA Toolkit will determine the version of NVIDIA Drivers you will need to install.  The CUDA Toolkit is compatible with many operating systems including Windows, Linux, and macOS, but you may need to update your OS version depending on which CUDA Toolkit release you intend to use.\n",
    "\n",
    "See Current Installation Instructions here: https://docs.cupy.dev/en/stable/install.html \n",
    "\n",
    "### Best Practices \n",
    "\n",
    "Before converting your program to CuPy, be sure to optimize its implementation on the CPU using NumPy and SciPy.  Benchmarking your initial implementation will help you determine if you’re accelerating your program when moving to the GPU.  \n",
    "\n",
    "To move your processing to CuPy from NumPy, you will need to \n",
    "- Import CuPy.  \n",
    "- Move all calls in NumPy to CuPy.  \n",
    "  - CuPy covers most of the NumPy API so try this first.\n",
    "- Move NumPy ndarrays to CuPy ndarrays\n",
    "  - Use `cupy.array()` or `cupy.asarray()`\n",
    "- Convert CuPy ndarrays back to NumPy ndarrays after GPU processing\n",
    "  - Use `cupy.asnumpy()` or `cupy.ndarray.get()`\n",
    "\n",
    "For example, this NumPy call:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "x_cpu = np.ones((1000,500,500))\n",
    "```\n",
    "\n",
    "Corresponds to this CuPy call:\n",
    "```python\n",
    "import cupy as cp\n",
    "x_gpu = cp.ones((1000,500,500))\n",
    "x_cpu = cp.asnumpy(x_gpu)\n",
    "```\n",
    "\n",
    "If you are Benchmarking your code, you will need to call `cp.cuda.Stream.null.synchronize()` explicitly for timings to be fair. By default CuPy will run GPU code concurrently and the function will exit before the GPU has finished. Calling `synchronize()` makes us wait for the GPU to finish before returning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88e1c7-85de-4a9a-aa6c-47242c5c4e36",
   "metadata": {},
   "source": [
    "### Going Beyond NumPy and SciPy\n",
    "\n",
    "Unfortunately, NumPy and SciPy don’t necessarily provide all the functionality you will need to develop your software.  In that case, you will need to know a few important patterns within CuPy:\n",
    "\n",
    "#### CuPy Kernel Compilation\n",
    "\n",
    "There are three kernel compilation classes available through CuPy.  The instance of this class defines a CUDA kernel which can be invoked by the `__call__` method of this instance:\n",
    "- ElementwiseKernel - Executes across each element of the array like a for-loop.\n",
    "- ReductionKernel - Executes a map, reduce, and post-reduce function.\n",
    "- RawKernel - Define a kernel with raw CUDA source code with control over grid size, block size, etc.\n",
    "\n",
    "Each of these types can also be defined using the `@cupyx.jit.*` decorator counterpart: `@cupyx.jit.elementwisekernel`, `@cupyx.jit.reductionkernel`, and `@cupy.jit.rawkernel`. \n",
    "\n",
    "#### CuPy Type-Generic Kernels\n",
    "\n",
    "If type information in a kernel function is defined with one character, it is considered a type placeholder.  The same character repeated throughout the function will be inferred as the same type.  This allows the creation of reusable generic kernels.\n",
    "\n",
    "#### Moving Between GPU Devices\n",
    "\n",
    "If you need to move data between GPU’s (from device to another device), use the with statement to create a context.  You may want to do this if you want to switch between the integrated graphics card and a dedicated graphics card in your system for either energy consumption or performance concerns.\n",
    "\n",
    "```python\n",
    "import cupy as cp\n",
    "\n",
    "device_id = 1\n",
    "\n",
    "#Create context for device 1\n",
    "with cp.cuda.Device(device_id):\n",
    "   array_on_device1 = cp.array([1, 2, 3, 4, 5])\n",
    "\n",
    "#Out of scope for context and execute on device 0\n",
    "array_on_device0 = cp.array([1, 2, 3, 4, 5]) \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0f428-3010-43c4-9600-29a480ddde24",
   "metadata": {},
   "source": [
    "### Performance Considerations\n",
    "\n",
    "#### Moving Data from CPU to GPU\n",
    "\n",
    "In order to take advantage of the GPU, we need to move data to the GPU over the PCI bus on your motherboard. This means we need to move data and code to the device and in order to execute that code.  In this way, the PCI bus between the CPU and GPU can become a bottleneck.\n",
    "\n",
    "There is a one-time performance cost to move data from the CPU to the GPU or vice versa.\n",
    "\n",
    "#### Branching\n",
    "\n",
    "Programs with many logic branches require the CPU.  Switching between CPU and GPU will incur a cost that might impact performance.  Programs with a lot of if-then statements might be better suited to the CPU depending on the overhead of switching between the two processors.\n",
    "\n",
    "Make sure your function is vectorized in order to minimize branching.\n",
    "\n",
    "#### Compiling Kernel Functions\n",
    "\n",
    "When a kernel call is required, CuPy compiles a kernel code optimized for the dimensions and dtypes of the given arguments, sends them to the GPU device, and executes the kernel.  CuPy then caches the kernel code sent to the GPU device within the process, which reduces the kernel compilation time on further calls.\n",
    "\n",
    "There is a one-time performance cost to compile your kernel function.  \n",
    "\n",
    "#### Moving Data from Current Device\n",
    "\n",
    "In general, CuPy functions expect that the array is on the same device as the current one. Similar to passing data from CPU to GPU or vice versa, passing an array stored on a non-current device may impact performance negatively depending on the hardware configuration.\n",
    "\n",
    "There is a performance tradeoff when data is moved from one device to another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ada4e-10a5-4bf1-9935-ba085dc77028",
   "metadata": {},
   "source": [
    "## Links to Handy References\n",
    "CuPy User Guide for more information: https://docs.cupy.dev/en/stable/user_guide/index.html \n",
    "\n",
    "CuPy API Reference: https://docs.cupy.dev/en/stable/reference/index.html \n",
    "\n",
    "CuPy Github Repository (includes more examples): https://github.com/cupy/cupy \n",
    "\n",
    "NumPy User Guide: https://numpy.org/doc/stable/user/ \n",
    "\n",
    "NumPy API Guide: https://numpy.org/doc/stable/reference/index.html \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b74393-0393-4d24-be0e-d510b4f23c02",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d290b7-c8de-4b8b-b3f0-6a8ea1c9dd16",
   "metadata": {},
   "source": [
    "## A Simple Conversion from NumPy to CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2393610-8392-4d66-b86b-3c5abc6b2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_cpu = np.ones((1000,500,500))\n",
    "\n",
    "x_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8965c4-ea45-4c68-9c35-b076fa7656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "x_gpu = cp.ones((1000,500,500))\n",
    "x_cpu = cp.asnumpy(x_gpu)\n",
    "\n",
    "x_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16fd541-ab9d-43fa-9810-9e5e50981e3b",
   "metadata": {},
   "source": [
    "## A More Complicated Conversion from NumPy to CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b73208-a9f9-4a2e-b76d-c811bfc56c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_cpu = np.random.random((1000, 1000))\n",
    "x_cpu *= 2 \n",
    "u, s, v = np.linalg.svd(x_cpu)\n",
    "\n",
    "u, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818a469-a984-4cd9-9ebb-2617fe141f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "x_gpu = cp.random.random((1000, 1000))\n",
    "x_gpu *= 2 \n",
    "u, s, v = cp.linalg.svd(x_gpu)\n",
    "\n",
    "u, s, v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99830d2-e277-4de2-b10d-88a044250d0e",
   "metadata": {},
   "source": [
    "## Adding a User-defined Kernel Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90030b7-da4c-44b3-897d-cdfa9828e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "from cupyx import jit\n",
    "\n",
    "\n",
    "@jit.rawkernel()\n",
    "def elementwise_copy(x, y, size):\n",
    "    tid = jit.blockIdx.x * jit.blockDim.x + jit.threadIdx.x\n",
    "    ntid = jit.gridDim.x * jit.blockDim.x\n",
    "    for i in range(tid, size, ntid):\n",
    "        y[i] = x[i]\n",
    "\n",
    "\n",
    "size = cupy.uint32(2 ** 22)\n",
    "x = cupy.random.normal(size=(size,), dtype=cupy.float32)\n",
    "y = cupy.empty((size,), dtype=cupy.float32)\n",
    "\n",
    "elementwise_copy((128,), (1024,), (x, y, size))\n",
    "\n",
    "elementwise_copy[128, 1024](x, y, size)\n",
    "\n",
    "assert (x == y).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
