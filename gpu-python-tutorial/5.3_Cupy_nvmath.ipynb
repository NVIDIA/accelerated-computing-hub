{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d57565e-f93f-4878-bebc-deb6ca2fc195",
   "metadata": {},
   "source": [
    "# CuPy with nvmath-python\n",
    "\n",
    "The **nvmath-python** (Beta) library brings the power of the NVIDIA math libraries to the Python ecosystem. The package aims to provide intuitive pythonic APIs that provide users full access to all the features offered by NVIDIA’s libraries in a variety of execution spaces. nvmath-python works seamlessly with existing Python array/tensor frameworks and focuses on providing functionality that is missing from those frameworks.\n",
    "\n",
    "This library seeks to meet the needs of:​\n",
    "- Researchers seeking productivity, interoperability with other libraries and frameworks, and performance​\n",
    "- Library/Framework developers seeking out-of-the-box performance and better maintainability through Python​\n",
    "- Kernel developers seeking for highest performance without the need to switch to CUDA​\n",
    "\n",
    "Nvmath-python features:​\n",
    "- Low-level bindings to CUDA math libraries​\n",
    "- Pythonic high-level APIs (host and device): ​At this point limited to extended matmul and FFTs​\n",
    "- Device functions callable in Numba kernels​\n",
    "- Interoperability with NumPy, CuPy, and PyTorch tensors​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3e83b-0db7-4bd1-8335-549870987066",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "1. Prototype Your Problem\n",
    "\n",
    "```python\n",
    "# Using NumPy array on CPU for first version\n",
    "import numpy as np\n",
    "import nvmath\n",
    "\n",
    "# NumPy array residing on CPU:\n",
    "a = np.random.rand(128, 1024, 1024)\n",
    "\n",
    "# Execution space is CPU (by default):\n",
    "r = nvmath.fft.fft(a) \n",
    "```\n",
    "\n",
    "Note: nvmath-python runs not only on GPU but also supports CPU execution space via NVPL (aarch64) and MKL (x86)\n",
    "\n",
    "2. Move Prototype to GPU\n",
    "\n",
    "```python\n",
    "# Using CuPy array to move to the GPU\n",
    "import cupy as cp\n",
    "import nvmath\n",
    "\n",
    "# NumPy array residing on CPU:\n",
    "a = cp.random.rand(128, 1024, 1024)\n",
    "\n",
    "# Execution space is CPU (by default):\n",
    "r = nvmath.fft.fft(a) \n",
    "```\n",
    "\n",
    "Note: nvmath-python interoperates with existing tensor libraries (numpy, cupy, pytorch) allowing easy integration with existing CPU and GPU workflows\n",
    "\n",
    "3. Scale\n",
    "\n",
    "```python\n",
    "# Use nvmath.distributed in order to scale to multi-GPU\n",
    "import numpy as np\n",
    "import nvmath\n",
    "\n",
    "# NumPy local array residing on CPU\n",
    "a = np.random.rand(128, 1024, 1024)\n",
    "\n",
    "# Distributed result as a local array\n",
    "r = nvmath.distributed.fft.fft(a)\n",
    "```\n",
    "Note: nvmath-python scales beyond single GPU at peak library performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de48ee-abd0-4c2d-b58b-ebebf3db4f86",
   "metadata": {},
   "source": [
    "# High-Level Modules\n",
    "Provide common out-of-box performant operations without leaving Python.\n",
    "\n",
    "This includes:\n",
    "- Linear Algebra\n",
    "- Fast Fourier Transform\n",
    "\n",
    "The nvmath-python library enables the fusion of epilog operations, offering enhanced performance. Available epilog operations include:\n",
    "- RELU: Applies the Rectified Linear Unit activation function.\n",
    "- GELU: Applies the Gaussian Error Linear Unit activation function.\n",
    "- BIAS: Adds a bias vector.\n",
    "- SIGMOID: Applies the sigmoid function.\n",
    "- TANH: Applies the hyperbolic tangent function.\n",
    "These epilogs can be combined, for example, RELU and BIAS can be fused. Custom epilogs can also be defined as Python functions and compiled using LTO-IR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5baa815-4f85-480a-9db0-9f075cf3c4e2",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "\n",
    "The nvmath-python library offers a specialized matrix multiplication interface to perform scaled matrix-matrix multiplication with predefined epilog operations as a single fused kernel. This kernel fusion can potentially lead to significantly better efficiency.\n",
    "\n",
    "In addition, nvmath-python’s stateful APIs decompose such operations into planning, autotuning, and execution phases, which enables amortization of one-time preparatory costs across multiple executions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d9ed9-c17c-40a1-858b-6ff02612b83c",
   "metadata": {},
   "source": [
    "### Matmul with CuPy Arrays (Stateless)\n",
    "\n",
    "This example demonstrates basic matrix multiplication of CuPy arrays.\n",
    "\n",
    "nvmath-python supports multiple frameworks. The result of each operation is a tensor of the\n",
    "same framework that was used to pass the inputs. It is also located on the same device as\n",
    "the inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562dcc68-0fcb-4aa5-b4c1-3f9d566e91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import nvmath\n",
    "\n",
    "# Prepare sample input data.\n",
    "n, m, k = 123, 456, 789\n",
    "a = cp.random.rand(n, k)\n",
    "b = cp.random.rand(k, m)\n",
    "\n",
    "# Perform the multiplication.\n",
    "result = nvmath.linalg.advanced.matmul(a, b)\n",
    "\n",
    "# Synchronize the default stream, since by default the execution is non-blocking for GPU\n",
    "# operands.\n",
    "cp.cuda.get_current_stream().synchronize()\n",
    "\n",
    "# Check if the result is cupy array as well.\n",
    "print(f\"Inputs were of types {type(a)} and {type(b)} and the result is of type {type(result)}.\")\n",
    "assert isinstance(result, cp.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07484302-fa3f-463a-bc5f-7b9eb4e7e74c",
   "metadata": {},
   "source": [
    "### Matmul with CuPy Arrays (Stateful)\n",
    "\n",
    "This example illustrates the use of stateful matrix multiplication objects. Stateful objects\n",
    "amortize the cost of preparation across multiple executions.\n",
    "\n",
    "The inputs as well as the result are CuPy ndarrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4042bbe9-77d9-4350-944f-23441c090c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import nvmath\n",
    "\n",
    "# Prepare sample input data.\n",
    "m, n, k = 123, 456, 789\n",
    "a = cp.random.rand(m, k)\n",
    "b = cp.random.rand(k, n)\n",
    "\n",
    "# Use the stateful object as a context manager to automatically release resources.\n",
    "with nvmath.linalg.advanced.Matmul(a, b) as mm:\n",
    "    # Plan the matrix multiplication. Planning returns a sequence of algorithms that can be\n",
    "    # configured as we'll see in a later example.\n",
    "    mm.plan()\n",
    "\n",
    "    # Execute the matrix multiplication.\n",
    "    result = mm.execute()\n",
    "\n",
    "    # Synchronize the default stream, since by default the execution is non-blocking for GPU\n",
    "    # operands.\n",
    "    cp.cuda.get_current_stream().synchronize()\n",
    "    print(f\"Input types = {type(a), type(b)}, device = {a.device, b.device}\")\n",
    "    print(f\"Result type = {type(result)}, device = {result.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dccc23-0964-41b9-850c-d09f49994b4a",
   "metadata": {},
   "source": [
    "### Matmul with CuPy Arrays (Stateless with Epilog)\n",
    "\n",
    "This example demonstrates usage of epilogs.\n",
    "\n",
    "Epilogs allow you to execute extra computations after the matrix multiplication in a single\n",
    "fused kernel. In this example we'll use the BIAS epilog, which adds bias to the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a944484-ad57-4ecd-b19c-fce4eba796ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import nvmath\n",
    "\n",
    "# Prepare sample input data.\n",
    "m, n, k = 64, 128, 256\n",
    "a = cp.random.rand(m, k)\n",
    "b = cp.random.rand(k, n)\n",
    "bias = cp.random.rand(m, 1)\n",
    "\n",
    "# Perform the multiplication with BIAS epilog.\n",
    "epilog = nvmath.linalg.advanced.MatmulEpilog.BIAS\n",
    "result = nvmath.linalg.advanced.matmul(a, b, epilog=epilog, epilog_inputs={\"bias\": bias})\n",
    "\n",
    "# Synchronize the default stream, since by default the execution is non-blocking for GPU\n",
    "# operands.\n",
    "cp.cuda.get_current_stream().synchronize()\n",
    "print(f\"Inputs were of types {type(a)} and {type(b)}, the bias type is {type(bias)}, and the result is of type {type(result)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fdf970-d3d6-4df4-b7b6-29db4b1c6d45",
   "metadata": {},
   "source": [
    "## Fast Fourier Transform\n",
    "\n",
    "Backed by the NVIDIA cuFFT library, nvmath-python provides a powerful set of APIs to perform N-dimensional discrete Fourier Transformations. These include forward and inverse transformations for complex-to-complex, complex-to-real, and real-to-complex cases. The operations are available in a variety of precisions, both as host and device APIs.\n",
    "\n",
    "The user can provide callback functions written in Python to selected nvmath-python operations like FFT, which results in a fused kernel and can lead to significantly better performance. Advanced users may benefit from nvmath-python device APIs that enable fusing core mathematical operations like FFT and matrix multiplication into a single kernel, bringing performance close to the theoretical maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04168852-8ed0-445a-ad71-7e9783680ab8",
   "metadata": {},
   "source": [
    "### FFT's with CuPy Arrays\n",
    "\n",
    "The input as well as the result from the FFT operations are CuPy ndarrays, resulting\n",
    "in effortless interoperability between nvmath-python and CuPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47200ee-42f5-4aec-ae98-af9b202aff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import nvmath\n",
    "\n",
    "shape = 512, 256, 512\n",
    "axes = 0, 1\n",
    "\n",
    "a = cp.random.rand(*shape, dtype=cp.float64) + 1j * cp.random.rand(*shape, dtype=cp.float64)\n",
    "\n",
    "# Forward FFT along the specified axes, batched along the complement.\n",
    "b = nvmath.fft.fft(a, axes=axes)\n",
    "\n",
    "# Inverse FFT along the specified axes, batched along the complement.\n",
    "c = nvmath.fft.ifft(b, axes=axes)\n",
    "\n",
    "# Synchronize the default stream\n",
    "cp.cuda.get_current_stream().synchronize()\n",
    "print(f\"Input type = {type(a)}, device = {a.device}\")\n",
    "print(f\"FFT output type = {type(b)}, device = {b.device}\")\n",
    "print(f\"IFFT output type = {type(c)}, device = {c.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de89f2b-e29b-4aea-b6d6-4eb127a67559",
   "metadata": {},
   "source": [
    "### FFT with Callback\n",
    "\n",
    "User-defined functions can be compiled to the LTO-IR format and provided as epilog or prolog to the FFT operation, allowing for Link-Time Optimization and fusing.\n",
    "\n",
    "This example shows how to perform a convolution by providing a Python callback function as prolog to the IFFT operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26268251-a738-412a-9201-8bbf0c2dc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import nvmath\n",
    "\n",
    "# Create the data for the batched 1-D FFT.\n",
    "B, N = 256, 1024\n",
    "a = cp.random.rand(B, N, dtype=cp.float64) + 1j * cp.random.rand(B, N, dtype=cp.float64)\n",
    "\n",
    "# Create the data to use as filter.\n",
    "filter_data = cp.sin(a)\n",
    "\n",
    "# Define the prolog function for the inverse FFT.\n",
    "# A convolution corresponds to pointwise multiplication in the frequency domain.\n",
    "def convolve(data_in, offset, filter_data, unused):\n",
    "    # Note we are accessing `data_out` and `filter_data` with a single `offset` integer,\n",
    "    # even though the input and `filter_data` are 2D tensors (batches of samples).\n",
    "    # Care must be taken to assure that both arrays accessed here have the same memory\n",
    "    # layout.\n",
    "    return data_in[offset] * filter_data[offset] / N\n",
    "\n",
    "# Compile the prolog to LTO-IR.\n",
    "with cp.cuda.Device():\n",
    "    prolog = nvmath.fft.compile_prolog(convolve, \"complex128\", \"complex128\")\n",
    "\n",
    "# Perform the forward FFT, followed by the inverse FFT, applying the filter as a prolog.\n",
    "r = nvmath.fft.fft(a, axes=[-1])\n",
    "r = nvmath.fft.ifft(r, axes=[-1], prolog={\n",
    "        \"ltoir\": prolog,\n",
    "        \"data\": filter_data.data.ptr\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edda3e0-bb7c-4e5f-b3be-4f8d3d9f8f77",
   "metadata": {},
   "source": [
    "# Low-level Modules\n",
    "Provides direct access to CUDA internals and CUDA C math libraries.\n",
    "\n",
    "This includes:\n",
    "- Device API's\n",
    "- Math Library Bindings\n",
    "\n",
    "There is also access to Host API's (and Host API's with callbacks), but we will focus on the Device side here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac6216-22d2-4aa0-bc77-52d28d36d208",
   "metadata": {},
   "source": [
    "## Device API's\n",
    "\n",
    "The device module of nvmath-python `nvmath.device` offers integration with NVIDIA’s high-performance computing libraries through device APIs for cuFFTDx, cuBLASDx, and cuRAND. Detailed documentation for these libraries can be found at [cuFFTDx](https://docs.nvidia.com/cuda/cufftdx/1.2.0/), [cuBLASDx](https://docs.nvidia.com/cuda/cublasdx/0.1.1/), and [cuRAND](https://docs.nvidia.com/cuda/curand/group__DEVICE.html#group__DEVICE) device APIs respectively.\n",
    "\n",
    "Users may take advantage of the device module via the two approaches below:\n",
    "- Numba Extensions: Users can access these device APIs via Numba by utilizing specific extensions that simplify the process of defining functions, querying device traits, and calling device functions.\n",
    "- Third-party JIT Compilers: The APIs are also available through low-level interfaces in other JIT compilers, allowing advanced users to work directly with the raw device code.\n",
    "\n",
    "\n",
    "This example shows how to use the cuRAND to sample a single-precision value from a normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d32e3-02ed-4caa-ace2-581111832487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "from numba import config as numba_config\n",
    "numba_config.CUDA_ENABLE_PYNVJITLINK = True\n",
    "\n",
    "from nvmath.device import random\n",
    "compiled_apis = random.Compile()\n",
    "\n",
    "threads, blocks = 64, 64\n",
    "nthreads = blocks * threads\n",
    "\n",
    "states = random.StatesPhilox4_32_10(nthreads)\n",
    "\n",
    "# Next, define and launch a setup kernel, which will initialize the states using\n",
    "# nvmath.device.random.init function.\n",
    "@cuda.jit(link=compiled_apis.files, extensions=compiled_apis.extension)\n",
    "def setup(states):\n",
    "    i = cuda.grid(1)\n",
    "    random.init(1234, i, 0, states[i])\n",
    "\n",
    "setup[blocks, threads](states)\n",
    "\n",
    "# With your states array ready, you can use samplers such as\n",
    "# nvmath.device.random.normal2 to sample random values in your kernels.\n",
    "@cuda.jit(link=compiled_apis.files, extensions=compiled_apis.extension)\n",
    "def kernel(states):\n",
    "    i = cuda.grid(1)\n",
    "    random_values = random.normal2(states[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e15297-aeda-4eff-8b48-f66dbfd119b8",
   "metadata": {},
   "source": [
    "## Math Library Bindings\n",
    "\n",
    "Low-level Python bindings for C APIs from NVIDIA Math Libraries are exposed under the corresponding modules in nvmath.bindings. To access the Python bindings, use the modules for the corresponding libraries. Under the hood, nvmath-python handles the run-time linking to the libraries for you lazily.\n",
    "\n",
    "The currently supported libraries along with the corresponding module names are listed as follows:\n",
    "- [cuBLAS](https://docs.nvidia.com/cuda/cublas/) (`nvmath.bindings.cublas`)\n",
    "- [cuBLASLt](https://docs.nvidia.com/cuda/cublas/#using-the-cublaslt-api) (`nvmath.bindings.cublasLt`)\n",
    "- [cuFFT](https://docs.nvidia.com/cuda/cufft/) (`nvmath.bindings.cufft`)\n",
    "- [cuRAND](https://docs.nvidia.com/cuda/curand/index.html) (`nvmath.bindings.curand`)\n",
    "- [cuSOLVER](https://docs.nvidia.com/cuda/cusolver/index.html) (`nvmath.bindings.cusolver`)\n",
    "- [cuSOLVERDn](https://docs.nvidia.com/cuda/cusolver/index.html#cusolverdn-dense-lapack) (`nvmath.bindings.cusolverDn`)\n",
    "- [cuSPARSE](https://docs.nvidia.com/cuda/cusparse/) (`nvmath.bindings.cusparse`)\n",
    "\n",
    "Guidance to translate library function names from C to Python are documented here: https://docs.nvidia.com/cuda/nvmath-python/latest/bindings/index.html "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ada4e-10a5-4bf1-9935-ba085dc77028",
   "metadata": {},
   "source": [
    "## Links to References\n",
    "nvmath-python home: https://developer.nvidia.com/nvmath-python \n",
    "\n",
    "nvmath-python documentation: https://docs.nvidia.com/cuda/nvmath-python/latest/index.html \n",
    "\n",
    "nvmath-python GitHub repository: https://developer.nvidia.com/nvmath-python\n",
    "\n",
    "Fusting Epilog Operations with Matrix Multiplication Using nvmath-python blog post: https://developer.nvidia.com/blog/fusing-epilog-operations-with-matrix-multiplication-using-nvmath-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b74393-0393-4d24-be0e-d510b4f23c02",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "A complete set of examples are available in the nvmath-python Github repository: https://github.com/NVIDIA/nvmath-python/tree/main/examples "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
    "gpuType": "T4",
    "provenance": [],
    "toc_visible": true
  },

  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
