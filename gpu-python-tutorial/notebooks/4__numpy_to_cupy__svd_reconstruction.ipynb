{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdnif2_TxAjl"
      },
      "source": [
        "# Exercise - NumPy to CuPy - SVD Reconstruction\n",
        "\n",
        "Let's try another NumPy to CuPy porting exercise, this time with the SVD reconstruction code from before.\n",
        "\n",
        "**TODO: Port this code to CuPy. Here's what you'll have to do:**\n",
        "\n",
        "- **Change `import numpy as xp` to `import cupy as xp`.**\n",
        "- **NumPy arrays are converted to CuPy arrays using `xp.asarray()`.  You'll see errors like `only supports cupy.ndarray` when you have this problem.**\n",
        "- **CuPy arrays are converted back to NumPy arrays (for Matplotlib) using `xp.asarray()`.**\n",
        "\n",
        "First, we need to import the compute vision and plotting stack we're using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLnsPrdx5hP0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as xp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVI52P80xAj5"
      },
      "source": [
        "Next let's download an image of Bryce's dog:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaH1Q3DWFpa4"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\n",
        "  \"https://drive.usercontent.google.com/download?id=1ClKrHt4-SIHaeBJdF0K3MG64jyVnt62L&export=download\",\n",
        "  \"loonie.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFgvt9fHxAkG"
      },
      "source": [
        "Then we read the image in grayscale mode:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcaTYmdpiElb"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"loonie.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "print(f\"nbytes: {image.nbytes}\")\n",
        "print(f\"shape: {image.shape}\")\n",
        "print(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAvIt5iJxAkK"
      },
      "source": [
        "Here we can see the image is 1600x1200 pixels, and each pixel is an unsigned 8-bit value (0-255).  Let's plot it with matplotlib to verify it looks correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8DnT8Ro7L8l"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image, cmap=\"gray\")\n",
        "plt.title(\"Bryce's Dog\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-C5yXn7xAkS"
      },
      "source": [
        "Yes, we can confirm that is a dog (and a very cute one at that).  Now let's start doing some linear algebra!\n",
        "\n",
        "NumPy provides an [implementation of SVD](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html).  By selecting `full_matrices=False`, we get the singular value matrix, `S`, as a 1D vector rather than a 2D diagonal matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U12FLtFU7I0f"
      },
      "outputs": [],
      "source": [
        "U, S, Vt = xp.linalg.svd(image, full_matrices=False)\n",
        "U.shape, S.shape, Vt.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdurZSEmxAkW"
      },
      "source": [
        "Since the image is not square and we've not selected `full_matrices`, NumPy returns `U` as a non-square matrix, `S` as the 1D vector which is the smaller of the two dimensions, and the `Vt` matrix is a square matrix.\n",
        "\n",
        "The singular values are returned in descending order, which we can see if we look at the first 10 elements of `S`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJEM_K7jxAkX"
      },
      "outputs": [],
      "source": [
        "S[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peIZQRlAxAkY"
      },
      "source": [
        "In fact, if we look at the size of the singular values, we see that the first few contribute a lot to the matrix, and then fall off very rapidly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHMliqddxAkY"
      },
      "outputs": [],
      "source": [
        "plt.semilogy(S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1g2UwP1xAkZ"
      },
      "source": [
        "That suggests we can get a pretty good approximation of the original image with a relatively small number of terms.  We can reconstruct the image matrix by slicing the `U`, `S`, and `Vt` matrices and remultiplying them.  We will need to convert `S` back into a 2D matrix for the multiplication as well.  Note that we are using the `@` operator to perform matrix multiplication, because `*` does element-wise multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABIkKrCpxAkZ"
      },
      "outputs": [],
      "source": [
        "# First 3 terms.\n",
        "nterms = 3\n",
        "reconstructed = U[:, :nterms] @ xp.diag(S[:nterms]) @ Vt[:nterms, :]\n",
        "plt.imshow(reconstructed, cmap=\"gray\")\n",
        "plt.title(\"n = 3\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAZDQDIRxAka"
      },
      "source": [
        "That's still pretty fuzzy, so let's check out the image with more terms included:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4ihZ_3_7X_P"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 4))\n",
        "\n",
        "start, end, step = 10, 50, 10\n",
        "for i in range(start, end, step):\n",
        "  plt.subplot(1, (end - start) // step + 1, (i - start) // step + 1)\n",
        "  reconstructed = U[:, :i] @ xp.diag(S[:i]) @ Vt[:i, :]\n",
        "  plt.imshow(reconstructed, cmap=\"gray\")\n",
        "  plt.title(f\"n = {i}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weLC3cKaxAkc"
      },
      "source": [
        "**EXTRA CREDIT: After you port this for loop to CuPy, consider the flow of compute and I/O. Are there any problems with this pattern? How could it be improved?**\n",
        "\n",
        "Now we'll print the compression ratio for the values of `n` used above.  This is the number of bytes of the reduced arrays added together and divided by the size of the original grayscale image array.  It seems we can get significant storage savings with this technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu2lao_KxAkd"
      },
      "outputs": [],
      "source": [
        "for i in range(start, end, step):\n",
        "  compress_ratio = (U[:, :i].nbytes + S[:i].nbytes + Vt[:i, :].nbytes) / image.nbytes\n",
        "  print(f\"n = {i}: compression = {compress_ratio:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1EiUWXKxAkf"
      },
      "source": [
        "Next, we compute and display the difference in the reconstruction for `n = 10` and the original image using `cmap=\"coolwarm\"` to display the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPUpGb37xAkg"
      },
      "outputs": [],
      "source": [
        "delta = image - (U[:,:10] @ xp.diag(S[:10]) @ Vt[:10,:])\n",
        "plt.imshow(delta, cmap=\"coolwarm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ypywm1uxAkh"
      },
      "source": [
        "Now that you have gotten SVD to work on CuPy, let's benchmark it!  To make things clearer, let's reimport NumPy and CuPy with their usual abbreviations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AjBKJuExAki"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import cupyx as cpx # For `cupyx.profiler.benchmark`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJGruJIzxAki"
      },
      "source": [
        "We have to be very careful when benchmarking GPU code. As GPU programming is inherently asynchronous, so it can be tricky to make sure we're measuring the right thing.\n",
        "\n",
        "Imagine you're measuring how long it takes to ship a package to someone, but you only time how long it takes for you to drop it off at the post office, not how long it takes for them to receive it and send you a thank you.\n",
        "\n",
        "Common Pythonic benchmarking tools like `%timeit` are not GPU aware, so it's easy to measure incorrectly with them.  We can only use them when we know the code we're benchmarking will perform the proper synchronization.  It's better to use something like [`cupyx.profiler.benchmark`](https://docs.cupy.dev/en/stable/reference/generated/cupyx.profiler.benchmark.html#cupyx.profiler.benchmark).\n",
        "\n",
        "First, we need a NumPy (CPU) and CuPy (GPU) copy of our image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr2zfGYIxAkj"
      },
      "outputs": [],
      "source": [
        "cpu_image = cv2.imread('loonie.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "gpu_image = cp.asarray(cpu_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNb_Jv88xAkl"
      },
      "source": [
        "Next let's benchmark both CPU and GPU execution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwnvkVsnxAkm"
      },
      "outputs": [],
      "source": [
        "repeat = 10\n",
        "warmup = 1\n",
        "D_np = cpx.profiler.benchmark(n_repeat=repeat, n_warmup=warmup, func=lambda:\n",
        "  np.linalg.svd(cpu_image, full_matrices=False)\n",
        ").cpu_times\n",
        "D_cp = cpx.profiler.benchmark(n_repeat=repeat, n_warmup=warmup, func=lambda:\n",
        "  cp.linalg.svd(gpu_image, full_matrices=False)\n",
        ").cpu_times\n",
        "\n",
        "print(f\"SVD (Host)   = {D_np.mean():.3g} s ± {(D_np.std() / D_np.mean()):.2%} (mean ± relative stdev of {D_np.size} runs)\")\n",
        "print(f\"SVD (Device) = {D_cp.mean():.3g} s ± {(D_cp.std() / D_cp.mean()):.2%} (mean ± relative stdev of {D_cp.size} runs)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE6qPht1xAkm"
      },
      "source": [
        "Depending on your hardware, the CPU and GPU might be close to the same speed, or the GPU might even be slower!  This is because the image is not big enough to fully utilize the GPU.  We can simulate a larger image by tiling the image using `np.tile`.  This duplicates the image both along axis 0 and axis 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-Hl0D5BxAkn"
      },
      "outputs": [],
      "source": [
        "cpu_image_tile = np.tile(cpu_image, (2, 2))\n",
        "gpu_image_tile = cp.asarray(cpu_image_tile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pUnjfzYxAkt"
      },
      "source": [
        "Now we can benchmark again (this will take longer because the matrices are much bigger):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgilXuzbxAku"
      },
      "outputs": [],
      "source": [
        "repeat = 5\n",
        "warmup = 1\n",
        "D_np = cpx.profiler.benchmark(n_repeat=repeat, n_warmup=warmup, func=lambda:\n",
        "  np.linalg.svd(cpu_image_tile, full_matrices=False)\n",
        ").cpu_times\n",
        "D_cp = cpx.profiler.benchmark(n_repeat=repeat, n_warmup=warmup, func=lambda:\n",
        "  cp.linalg.svd(gpu_image_tile, full_matrices=False)\n",
        ").cpu_times\n",
        "\n",
        "print(f\"SVD (Host)   = {D_np.mean():.3g} s ± {(D_np.std() / D_np.mean()):.2%} (mean ± relative stdev of {D_np.size} runs)\")\n",
        "print(f\"SVD (Device) = {D_cp.mean():.3g} s ± {(D_cp.std() / D_cp.mean()):.2%} (mean ± relative stdev of {D_cp.size} runs)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nlgOqkBxAkw"
      },
      "source": [
        "**TODO: Experiment with differ sizes of image by changing the `np.tile` arguments.  When is the GPU faster?**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
     "display_name": "training-pyhpc-2025",
     "language": "python",
     "name": "pyhpc-2025"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
