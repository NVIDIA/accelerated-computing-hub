{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
     "display_name": "training-pyhpc-2025",
     "language": "python",
     "name": "pyhpc-2025"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise - Memory Spaces - Power Iteration\n",
        "\n",
        "Let's learn about memory spaces and transfers! In this exercise, we'll learn:\n",
        "\n",
        "- How to explicitly transfer data between host and device.\n",
        "  - `d = cupy.asarray(h)` to copy from a host array to a device array.\n",
        "  - `h = cupy.asnumpy(d)` to copy from a device array to a host array.\n",
        "- What happens if we mix NumPy and CuPy code.\n",
        "- Some ways in which NumPy and CuPy produce different results.\n",
        "- Some of the limitations of CuPy.\n",
        "- How problem size and compute workload impacts performance.\n",
        "\n",
        "We're going to estimate the dominant eigenvalue of a matrix with the [power iteration algorithm](https://en.wikipedia.org/wiki/Power_iteration).\n",
        "First, we'll randomly generate a dense diagonalizable square matrix."
      ],
      "metadata": {
        "id": "6YkNAlM91iGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ZHpg3aVXSeix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class PowerIterationConfig:\n",
        "  dim: int = 4096 # Number of rows and columns in the square matrix.\n",
        "\n",
        "  # Value from 0 to 1 that controls how much greater the dominant eigenvalue is\n",
        "  # from the rest of the eigenvalues. A higher value means quicker convergence.\n",
        "  dominance: float = 0.1\n",
        "\n",
        "  # Maximum number of steps to perform.\n",
        "  max_steps: int = 400\n",
        "\n",
        "  # Every `check_frequency` steps we save a checkpoint and compute the residual.\n",
        "  check_frequency: int = 10\n",
        "\n",
        "  # Whether the residual should be printed every `check_frequency` steps.\n",
        "  progress: bool = True\n",
        "\n",
        "  # If the residual is below `residual_threshold`, terminate early.\n",
        "  residual_threshold: float = 1e-10"
      ],
      "metadata": {
        "id": "BCToOdVdSONp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ak3mn2hIsKo"
      },
      "outputs": [],
      "source": [
        "def generate_host(cfg=PowerIterationConfig()):\n",
        "  np.random.seed(42)\n",
        "\n",
        "  # Vector with a single 1 & `cfg.dim - 1` values from 0 to `1 - cfg.dominance`.\n",
        "  weak_lam = np.random.random(cfg.dim - 1) * (1.0 - cfg.dominance)\n",
        "  lam = np.random.permutation(np.concatenate(([1.0], weak_lam)))\n",
        "\n",
        "  P = np.random.random((cfg.dim, cfg.dim)) # Random invertible matrix.\n",
        "  D = np.diag(np.random.permutation(lam))  # Diagonal matrix w/ random eigenvalues.\n",
        "  A = ((P @ D) @ np.linalg.inv(P))         # Diagonalizable matrix.\n",
        "  return A\n",
        "\n",
        "A_host = generate_host()\n",
        "\n",
        "with np.printoptions(precision=4):\n",
        "  print(A_host)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we perform the power iteration with NumPy, using a vector of 1s as our initial guess.\n",
        "\n",
        "We'll perform at most `cfg.max_steps`. Every `config.check_frequency` steps, we'll output a checkpoint, compute the absolute residual, check whether it's below a `cfg.residual_threshold`. If it is, then we'll stop early."
      ],
      "metadata": {
        "id": "VHv9uXHI_6e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_host(A, cfg=PowerIterationConfig()):\n",
        "  x = np.ones(A.shape[0], dtype=np.float64)\n",
        "\n",
        "  for i in range(0, cfg.max_steps, cfg.check_frequency):\n",
        "    y = A @ x\n",
        "    lam = (x @ y) / (x @ x)            # Rayleigh quotient.\n",
        "    res = np.linalg.norm(y - lam * x)\n",
        "    x = y / np.linalg.norm(y)          # Normalize for next step.\n",
        "\n",
        "    if cfg.progress:\n",
        "      print(f\"step {i}: residual = {res:.3e}\")\n",
        "\n",
        "    np.savetxt(f\"host_{i}.txt\", x) # Save a checkpoint.\n",
        "\n",
        "    if res < cfg.residual_threshold:\n",
        "      break\n",
        "\n",
        "    for _ in range(cfg.check_frequency - 1):\n",
        "      y = A @ x\n",
        "      x = y / np.linalg.norm(y) # Normalize for next step.\n",
        "\n",
        "  return (x.T @ (A @ x)) / (x.T @ x)\n",
        "\n",
        "lam_est_host = estimate_host(A_host).item()\n",
        "\n",
        "print()\n",
        "print(lam_est_host)"
      ],
      "metadata": {
        "id": "q0x0_p4pvAdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO: In the next cell, port the power iteration function to CuPy. Try leaving some operations as NumPy and see what happens.**"
      ],
      "metadata": {
        "id": "LMtzZzVNBexb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_device(A, cfg=PowerIterationConfig):\n",
        "  x = np.ones(A.shape[0], dtype=np.float64)\n",
        "\n",
        "  for i in range(0, cfg.max_steps, cfg.check_frequency):\n",
        "    y = A @ x\n",
        "    lam = (x @ y) / (x @ x)            # Rayleigh quotient.\n",
        "    res = np.linalg.norm(y - lam * x)\n",
        "    x = y / np.linalg.norm(y)          # Normalize for next step.\n",
        "\n",
        "    if cfg.progress:\n",
        "      print(f\"step {i}: residual = {res:.3e}\")\n",
        "\n",
        "    np.savetxt(f\"device_{i}.txt\", x) # Save a checkpoint.\n",
        "\n",
        "    if res < cfg.residual_threshold:\n",
        "      break\n",
        "\n",
        "    for _ in range(cfg.check_frequency - 1):\n",
        "      y = A @ x\n",
        "      x = y / np.linalg.norm(y) # Normalize for next step.\n",
        "\n",
        "  return (x.T @ (A @ x)) / (x.T @ x)\n",
        "\n",
        "lam_est_device = estimate_device(A_host).item()\n",
        "\n",
        "print()\n",
        "print(lam_est_device)"
      ],
      "metadata": {
        "id": "sulx6gabBd1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO: Now port the matrix generation function to CuPy, and run the power iteration with it. What do you notice about the result?**"
      ],
      "metadata": {
        "id": "ySwpt6ro00pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_device(cfg=PowerIterationConfig):\n",
        "  np.random.seed(42)\n",
        "\n",
        "  # Vector with a single 1 & `cfg.dim - 1` values from 0 to `1 - cfg.dominance`.\n",
        "  weak_lam = np.random.random(cfg.dim - 1) * (1.0 - cfg.dominance)\n",
        "  lam = np.random.permutation(np.concatenate(([1.0], weak_lam)))\n",
        "\n",
        "  P = np.random.random((cfg.dim, cfg.dim)) # Random invertible matrix.\n",
        "  D = np.diag(np.random.permutation(lam))  # Diagonal matrix with random eigenvalues.\n",
        "  A = ((P @ D) @ np.linalg.inv(P))         # Diagonalizable matrix.\n",
        "  return A\n",
        "\n",
        "A_device = generate_device()\n",
        "\n",
        "with np.printoptions(precision=4):\n",
        "  print(\"A_host:\")\n",
        "  print(A_host)\n",
        "  print()\n",
        "  print(\"A_device:\")\n",
        "  print(A_device)\n",
        "  print()\n",
        "\n",
        "lam_est_device_generation = estimate_device(A_device).item()\n",
        "\n",
        "print()\n",
        "print(lam_est_device_generation)"
      ],
      "metadata": {
        "id": "7R96PJqp0zkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's compute the eigenvalues of the matrix with `numpy.linalg.eigvals`. This may take a little while.\n",
        "\n",
        "**TODO: What happens if we port this to CuPy?**"
      ],
      "metadata": {
        "id": "BXXawDcfHSol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lam_ref = np.linalg.eigvals(A_host).real.max()"
      ],
      "metadata": {
        "id": "fL7QYIVesehd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can check whether our power iteration estimation is correct."
      ],
      "metadata": {
        "id": "BF1HHlkOHtw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Solution\")\n",
        "print()\n",
        "print(f\"Power iteration (host)   = {lam_est_host:.6e}\")\n",
        "print(f\"Power iteration (device) = {lam_est_device:.6e}\")\n",
        "print(f\"`eigvals` reference      = {lam_ref:.6e}\")\n",
        "\n",
        "rel_err_host   = abs(lam_est_host - lam_ref) / abs(lam_ref)\n",
        "rel_err_device = abs(lam_est_device - lam_ref) / abs(lam_ref)\n",
        "print()\n",
        "print(f\"Relative error (host)    = {rel_err_host:.3e}\")\n",
        "print(f\"Relative error (device)  = {rel_err_device:.3e}\")\n",
        "\n",
        "np.testing.assert_allclose(lam_est_host, lam_ref, rtol=1e-4)\n",
        "np.testing.assert_allclose(lam_est_device, lam_ref, rtol=1e-4)"
      ],
      "metadata": {
        "id": "7E7MUYsYsjwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's benchmark all three solutions."
      ],
      "metadata": {
        "id": "2UXGSFs2H70q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Execution Time\")\n",
        "print()\n",
        "\n",
        "time_host = %timeit -q -o estimate_host(A_host, PowerIterationConfig(progress=False)).item()\n",
        "print(f\"Power iteration (host)   = {time_host}\")\n",
        "\n",
        "time_device = %timeit -q -o estimate_device(A_host, PowerIterationConfig(progress=False)).item()\n",
        "print(f\"Power iteration (device) = {time_device}\")\n",
        "\n",
        "time_ref = %timeit -q -o -r 1 -n 1 np.linalg.eigvals(A_host).real.max()\n",
        "print(f\"`eigvals` reference      = {time_ref}\")"
      ],
      "metadata": {
        "id": "v_2HmcBFERhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXTRA CREDIT: Explore the impact of changing the problem size (`dim`), the compute workload (`max_steps` and `dominance`), and the check frequency (`check_frequency`).**"
      ],
      "metadata": {
        "id": "8prYSJJprj-Q"
      }
    }
  ]
}
