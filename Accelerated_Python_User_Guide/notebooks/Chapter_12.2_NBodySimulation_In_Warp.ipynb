{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3cebfbd2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# SPDX-License-Identifier: Apache-2.0 AND CC-BY-NC-4.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b41de3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Chapter 12.2: N-body Simulation using Single Instruction, Multiple Threads (SIMT) and Tile-based Approach in Warp\n",
    "\n",
    "![Example output](images/chapter-12.2/nbody_animation.gif)\n",
    "\n",
    "## Overview\n",
    "\n",
    "In the previous two notebooks, we introduced NVIDIA Warp as a framework for writing high-performance GPU code in Python and implemented a GPU-accelerated 2-D Ising model simulation. Through this parallel GPU implementation, we learned the importance of developing correct parallelization algorithms to faithfully reproduce the underlying physics of any physical system that we are modeling.\n",
    "\n",
    "Following the theme of simulating physical systems to learn the basics of NVIDIA Warp for parallel computing, in this chapter we will implement an N-body simulation in NVIDIA Warp, first using the single instruction, multiple thread (SIMT) model and then using the tile-based model (both in Warp).\n",
    "\n",
    "Through this implementation, you will learn the following:\n",
    "\n",
    "* The simulation of another physical system using Warp, building on the previous notebook on the 2-D Ising model\n",
    "* How to characterize code performance and use some code profiling tools available in Warp\n",
    "* An introduction to the tile-based programming method in Warp\n",
    "\n",
    "By the end of this chapter, you will have two variants of code for N-body simulation, one based on the SIMT paradigm and another based on the tile-based programming model. You will also have learned about tools available in Python and Warp to benchmark your code's time performance in greater detail.\n",
    "\n",
    "It is strongly recommended to work through the [notebook on introduction to NVIDIA Warp](Chapter_12_Intro_to_NVIDIA_Warp.ipynb) and [GPU-Accelerated Ising Model Simulation in NVIDIA Warp](Chapter_12.1_IsingModel_In_Warp.ipynb) before proceeding with this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d431841",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "Before we begin this tutorial, let us ensure we have all the necessary packages installed.\n",
    "\n",
    "First, we will install NVIDIA Warp if it is not already available:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaea329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NVIDIA Warp\n",
    "%pip install warp-lang\n",
    "\n",
    "# Install Matplotlib for plotting/animation\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292eb53a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Now let us import the necessary libraries and initialize Warp to check if GPU support is available:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import warp as wp\n",
    "\n",
    "# Check for GPU availability\n",
    "if wp.get_cuda_device_count() > 0:\n",
    "    print(\"✓ GPU detected successfully\")\n",
    "else:\n",
    "    print(\"No GPU detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5750b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "## Introduction: Exploring avenues for further speed up of already GPU accelerated code\n",
    "\n",
    "In the last notebook, we went through an example of how to correctly model a physical system (2-D Ising model) using Warp.\n",
    "\n",
    "Now, we will go a step beyond the correctness of the model and explore how to profile our code and accelerate an already GPU-accelerated implementation.\n",
    "\n",
    "Similar to the 2-D Ising model, we choose the N-body simulation for its simplicity while also having underlying physics that makes it amenable to a tile-based programming model.\n",
    "\n",
    "Like the previous notebook, let us begin by understanding the physics behind the N-body simulation, then progressively build our GPU implementation, profile it, analyze potential avenues for further speedup, and finally explore the tile-based programming model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76672792",
   "metadata": {},
   "source": [
    "---\n",
    "## Background: The N-body simulation in physics and its numerical implementation \n",
    "\n",
    "### What is an N-body simulation?\n",
    "\n",
    "An [N-body simulation](https://en.wikipedia.org/wiki/N-body_simulation) models the temporal evolution of a system of particles, typically under the influence of physical forces such as gravity. N-body simulations are widely used in astrophysics to study the dynamics of systems of planets, stars, and galaxies. Readers are strongly encouraged to go through section 31.1 of the [Fast N-Body Simulation with CUDA](https://developer.nvidia.com/gpugems/gpugems3/part-v-physics-simulation/chapter-31-fast-n-body-simulation-cuda) webpage for additional context on why we care about speeding up the N-body simulation.\n",
    "\n",
    "### Numerical setup\n",
    "\n",
    "The N-body simulation in this tutorial evolves a system of particles interacting with each other through gravity. Each particle exerts an attractive gravitational force on every other particle in the system. For a particle given by index $i$ and mass $m_i$, we approximate the net force on the particle $\\mathbf{F}_i$ as:\n",
    "\n",
    "$$\n",
    "\\mathbf{F}_i \\approx G m_i \\sum_{j=1}^{N} \\frac{ m_j \\mathbf{r}_{ij} }{ \\left(\\mathbf{r}_{ij} \\cdot \\mathbf{r}_{ij}  + \\epsilon^2 \\right)^{3/2} },\n",
    "$$\n",
    "where $\\mathbf{r}_{ij} = \\mathbf{x}_j - \\mathbf{x}_i$, $\\mathbf{x}_j$ and $\\mathbf{x}_i$ are the position vectors of particles indexed $j$ and $i$, respectively. $\\epsilon$ is a *softening factor* to prevent numerical instabilities when two particles are very close to each other. For convenience and without any loss of generality, we set $G=1$ and do not explicitly use it in the code.\n",
    "\n",
    "\n",
    "### How to calculate the position of any particle in the system as a function of time?\n",
    "\n",
    "1. For any particle $i$, we can calculate its acceleration at a given time $t_n$ as:\n",
    "$$\n",
    "\\mathbf{a}_i^{n} = \\frac{\\mathbf{F}_i^{n}}{m_{i}} = G \\sum_{j=1}^{N} \\frac{ m_j \\mathbf{r}_{ij} }{ \\left(\\mathbf{r}_{ij} \\cdot \\mathbf{r}_{ij}  + \\epsilon^2 \\right)^{3/2} }.\n",
    "$$\n",
    "\n",
    "In the formula above and subsequent formulae, superscript $n$ refers to the values of variables (forces, positions, accelerations, velocities) at time $t_n$.\n",
    "\n",
    "2. We obtain the velocity of the given particle at time $t_{n+1}$ as:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_i^{n+1} = \\mathbf{v}_i^{n} + \\mathbf{a}_i^{n}\\Delta t.\n",
    "$$\n",
    "\n",
    "3. Thereafter, the position of the particle is updated at time $t_{n+1}$ as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i^{n+1} = \\mathbf{x}_i^{n} + \\mathbf{v}_i^{n+1}\\Delta t.\n",
    "$$\n",
    "\n",
    "Interested readers can also take a look at the appendix of [Swope et al. 1981](https://apps.dtic.mil/sti/tr/pdf/ADA103095.pdf) (page 53 onward).\n",
    "\n",
    "**Exercise**: Starting with equations 1 to 3, show that the above-mentioned method can equivalently be expressed as\n",
    "$$\n",
    "\\frac{d^2 \\mathbf{x}_i}{d t^{2}} = \\mathbf{a}_i \\approx  \\frac{\\mathbf{x}_i^{n+1} -2 \\mathbf{x}_{i}^n + \\mathbf{x}_{i}^{n-1}}{\\Delta t^{2}} = \\mathbf{a}_i^{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next sections, we will first implement a baseline simulation in Warp using a single instruction, multiple threads (SIMT) approach. We will then benchmark the SIMT code and delve into a tile-based paradigm for an even more performant code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49981536",
   "metadata": {},
   "source": [
    "---\n",
    "## A baseline SIMT implementation\n",
    "\n",
    "The baseline implementation consists of mainly these N steps:\n",
    "\n",
    "1. Initialize the N-body simulation parameters and arrays using `def initi_problem (num_bodies)` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38354bda",
   "metadata": {},
   "source": [
    "### Initializing the simulation using NumPy and Warp\n",
    "\n",
    "The cell below implements the `def init_problem(num_bodies)` function to initialize positions and velocities of particles using NumPy. The following arrays are allocated on the GPU:\n",
    "\n",
    "- **Position arrays**: We use two position arrays to avoid race conditions in the Warp kernel. These arrays are swapped at each time step.\n",
    "  - Data type: Three-component float vector (`wp.vec3`)\n",
    "  - Shape: `(N,)`\n",
    "  - Initial values: Random positions uniformly distributed in space\n",
    "\n",
    "- **Velocity array**: Stores the velocity of each particle.\n",
    "  - Data type: Three-component float vector (`wp.vec3`)\n",
    "  - Shape: `(N,)`\n",
    "  - Initial values: Random velocities uniformly distributed in [-1, 1]\n",
    "\n",
    "- **Mass array**: While not strictly necessary for this basic example, including masses makes it easier to extend the code to handle variable particle masses.\n",
    "  - Data type: Float (`wp.float32`)\n",
    "  - Shape: `(N,)`\n",
    "  - Initial values: 1.0 (unit mass for all particles)\n",
    "\n",
    "For convenience, we first initialize the arrays on the CPU using NumPy, then transfer them to Warp arrays on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a27f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_problem(num_bodies):\n",
    "    \"\"\"Initialize N-body simulation parameters and arrays.\n",
    "\n",
    "    Creates initial positions, velocities, and masses for a system of particles\n",
    "    that will be used in the N-body gravitational simulation. Positions are\n",
    "    uniformly distributed in a cube with size scaled by particle count to\n",
    "    maintain constant density.\n",
    "\n",
    "    Args:\n",
    "        num_bodies (int): Number of particles in the simulation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pos_array_0 (wp.array): Initial position array on GPU (shape: [num_bodies, 3]).\n",
    "            - pos_array_1 (wp.array): Empty position array for double buffering.\n",
    "            - vel_array (wp.array): Initial velocity array on GPU (shape: [num_bodies, 3]).\n",
    "            - mass_array (wp.array): Mass array on GPU (all particles have unit mass).\n",
    "            - scale (float): Scale factor for the simulation domain.\n",
    "            - init_pos_np (np.ndarray): Initial positions on CPU for visualization.\n",
    "\n",
    "    Note:\n",
    "        Uses a fixed random seed (42) for reproducible results.\n",
    "    \"\"\"\n",
    "    # Initialize random number generator with fixed seed for reproducibility.\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    # Calculate scale factor to maintain constant particle density as N increases.\n",
    "    # The cube root scaling ensures constant density in 3D space.\n",
    "    scale = 10.0 * (num_bodies / 1024) ** (1 / 3)\n",
    "\n",
    "    # Generate initial conditions on CPU using NumPy.\n",
    "    # Positions are uniformly distributed within a cube of size [-scale, scale]^3.\n",
    "    init_pos_np = rng.uniform(low=-scale, high=scale, size=(num_bodies, 3))\n",
    "\n",
    "    # Velocities are uniformly distributed in [-1, 1]^3 for initial random motion.\n",
    "    init_vel_np = rng.uniform(low=-1.0, high=1.0, size=(num_bodies, 3))\n",
    "\n",
    "    # All particles have unit mass for simplicity.\n",
    "    mass_array_np = np.ones(num_bodies)\n",
    "\n",
    "    # Transfer data from CPU (NumPy) to GPU (Warp).\n",
    "    pos_array_0 = wp.array(init_pos_np, dtype=wp.vec3)\n",
    "\n",
    "    # Create second position array for double buffering technique.\n",
    "    # This avoids race conditions when updating positions in parallel.\n",
    "    pos_array_1 = wp.empty_like(pos_array_0)\n",
    "\n",
    "    # Transfer velocity and mass data to GPU.\n",
    "    vel_array = wp.array(init_vel_np, dtype=wp.vec3)\n",
    "    mass_array = wp.array(mass_array_np, dtype=wp.float32)\n",
    "\n",
    "    return pos_array_0, pos_array_1, vel_array, mass_array, scale, init_pos_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now set the key simulation parameters for the problem at hand.\n",
    "\n",
    "- `dt`: Timestep for the numerical setup\n",
    "- `num_bodies`: Total number of bodies we are interested in simulating\n",
    "- `SOFTENING_SQ`: Softening term to avoid blow-up in $\\mathbf{F}_i$ if two particles are very close to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "num_bodies = 1024\n",
    "SOFTENING_SQ = 0.1**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e8b52",
   "metadata": {},
   "source": [
    "Let us know initialize the simulation and visualize the initial distribution of particles in the 3-D cartesian coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warp as wp\n",
    "\n",
    "# Call to initialize the position, velocity and mass arrays\n",
    "pos_array_0, pos_array_1, vel_array, mass_array, scale, init_pos_np = init_problem(\n",
    "    num_bodies\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above initializes the position, velocity, and mass arrays for particles for a given number of `num_bodies` particles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the initial positions are set, let us visualize the system before moving to the implementation of the numerical scheme. Based on how initial position is set in `def init_problem(num_bodies)`, we should visually see an uniform distribution of particles in a cubical box of length 20 with centered at origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with a dark background\n",
    "plt.style.use(\"dark_background\")\n",
    "fig = plt.figure(figsize=(8, 6), dpi=150)\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Calculate distance of all particles from origin for color mapping\n",
    "distances = np.linalg.norm(init_pos_np, axis=1)\n",
    "\n",
    "# Create a scatter plot\n",
    "scatter_plot = ax.scatter(\n",
    "    init_pos_np[:, 0],\n",
    "    init_pos_np[:, 1],\n",
    "    init_pos_np[:, 2],\n",
    "    c=distances,  # Color by distance from origin\n",
    "    cmap=\"plasma\",  # Set colormap to plasma\n",
    "    s=50,  # Set point size\n",
    "    edgecolors=\"white\",  # White edges for contrast\n",
    "    linewidth=0.5,  # Thin edge lines\n",
    "    marker=\"o\",  # Round markers\n",
    ")\n",
    "\n",
    "# Add a colorbar with label\n",
    "cbar = plt.colorbar(scatter_plot, ax=ax, pad=0.1, shrink=0.8)\n",
    "cbar.set_label(\"Distance from Origin\", rotation=270, labelpad=20, fontsize=12)\n",
    "\n",
    "# Set axis labels with custom fonts\n",
    "ax.set_xlabel(\"X Position\", fontsize=12, fontweight=\"bold\", labelpad=10)\n",
    "ax.set_ylabel(\"Y Position\", fontsize=12, fontweight=\"bold\", labelpad=10)\n",
    "ax.set_zlabel(\"Z Position\", fontsize=12, fontweight=\"bold\", labelpad=10)\n",
    "\n",
    "# Set axis limits with some padding\n",
    "padding = scale * 0.1\n",
    "ax.set_xlim(-scale - padding, scale + padding)\n",
    "ax.set_ylim(-scale - padding, scale + padding)\n",
    "ax.set_zlim(-scale - padding, scale + padding)\n",
    "\n",
    "# Customize the grid\n",
    "ax.grid(True, alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Set a viewing angle\n",
    "ax.view_init(elev=20, azim=45)\n",
    "\n",
    "# Add pane colors for depth perception\n",
    "ax.xaxis.pane.fill = False\n",
    "ax.yaxis.pane.fill = False\n",
    "ax.zaxis.pane.fill = False\n",
    "\n",
    "# Customize tick labels\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=10)\n",
    "\n",
    "# Add a subtle box around the plot region\n",
    "ax.set_box_aspect([1, 1, 1])  # Equal aspect ratio\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warp kernel for timestepping and updating the positions of the particles\n",
    "\n",
    "Since we are working with the SIMT paradigm, it makes sense to launch a Warp kernel with a total number of threads equal to `num_bodies`. Each thread then takes care of updating the position of a single particle for a single timestep. We call this Warp kernel $N$ times, with each iteration from $0$ to $N$ corresponding to timesteps $t_1 = \\Delta t$ to $t_{N} = N\\Delta t$ (starting from $t_0=0$).\n",
    "\n",
    "The Warp kernel we are about to implement needs to perform the following steps on each thread for a single particle, given the positions and velocities at time $t_n$:\n",
    "\n",
    "- Calculate the acceleration of the particle $\\mathbf{a}_i^{n}$ at time $t_n$ using the formula described in the Numerical setup section\n",
    "- Update the velocity of the particle: $\\mathbf{v}_{i}^{n+1} = \\mathbf{v}_{i}^{n} + \\mathbf{a}_{i}^{n}\\Delta t$\n",
    "- Calculate the updated position: $\\mathbf{x}_{i}^{n+1} = \\mathbf{x}_{i}^{n} + \\mathbf{v}_{i}^{n+1}\\Delta t$\n",
    "\n",
    "**Exercise**: Stop here and try to implement this Warp kernel and all the corresponding steps yourself. You can then compare your implementation with ours to see similarities and differences. Remember that the same algorithm can be implemented in different ways. In the final time-stepping loop, you can replace our kernel implementation with yours and observe whether the results change or remain similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below implements two key components: (a) a Warp function named `def body_body_interaction(...)` that calculates the net gravitational acceleration of a particle, and (b) a Warp kernel named `def integrate_bodies(...)` that implements the time-stepping algorithm described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wp.func\n",
    "def body_body_interaction(\n",
    "    num_bodies: int,\n",
    "    masses: wp.array(dtype=float),\n",
    "    body_position: wp.vec3,\n",
    "    positions: wp.array(dtype=wp.vec3),\n",
    "):\n",
    "    \"\"\"Calculate gravitational acceleration on a particle due to all other particles.\n",
    "\n",
    "    Computes the net gravitational acceleration on a particle at the given position\n",
    "    by summing the gravitational forces from all other particles in the system.\n",
    "    Uses a softening factor to prevent numerical instabilities when particles are\n",
    "    very close together.\n",
    "\n",
    "    Args:\n",
    "        num_bodies: Total number of particles in the system.\n",
    "        masses: Array of particle masses indexed by particle ID.\n",
    "        body_position: Position vector of the particle for which acceleration is computed.\n",
    "        positions: Array of position vectors for all particles in the system.\n",
    "\n",
    "    Returns:\n",
    "        wp.vec3: Net acceleration vector acting on the particle.\n",
    "\n",
    "    Note:\n",
    "        The acceleration is computed using Newton's law of gravitation with G=1:\n",
    "        a_i = Σ_j (m_j * r_ij / |r_ij + ε²|^(3/2))\n",
    "        where r_ij is the vector from particle i to particle j, and ε is the\n",
    "        softening factor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize acceleration vector to zero.\n",
    "    acc = wp.vec3(0.0, 0.0, 0.0)\n",
    "\n",
    "    # Sum gravitational contributions from all other particles.\n",
    "    for body_index in range(num_bodies):\n",
    "        # Calculate displacement vector from current particle to other particle.\n",
    "        r = positions[body_index] - body_position\n",
    "\n",
    "        # Add softening factor to squared distance to avoid singularities.\n",
    "        # This prevents blow-up when two particles get close to each other.\n",
    "        dist_sq = wp.length_sq(r) + SOFTENING_SQ\n",
    "\n",
    "        # Calculate inverse distance cubed for gravitational force formula.\n",
    "        inv_dist = 1.0 / wp.sqrt(dist_sq)\n",
    "        inv_dist_cubed = inv_dist * inv_dist * inv_dist\n",
    "\n",
    "        # Accumulate acceleration contribution from this particle.\n",
    "        # Force is proportional to mass and inverse square of distance.\n",
    "        acc = acc + masses[body_index] * inv_dist_cubed * r\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "@wp.kernel\n",
    "def integrate_bodies(\n",
    "    num_bodies: int,\n",
    "    dt: float,\n",
    "    masses: wp.array(dtype=float),\n",
    "    old_position: wp.array(dtype=wp.vec3),\n",
    "    velocity: wp.array(dtype=wp.vec3),\n",
    "    new_position: wp.array(dtype=wp.vec3),\n",
    "):\n",
    "    \"\"\"Integrate N-body system forward one timestep.\n",
    "\n",
    "    Updates particle velocities and positions for one timestep using the\n",
    "    gravitational forces between all particles. Each thread handles one particle,\n",
    "    computing its acceleration, updating its velocity, and calculating its new\n",
    "    position.\n",
    "\n",
    "    Args:\n",
    "        num_bodies: Total number of particles in the system.\n",
    "        dt: Timestep size for integration.\n",
    "        masses: Array of particle masses (shape: [num_bodies]).\n",
    "        old_position: Current particle positions (shape: [num_bodies]).\n",
    "        velocity: Current particle velocities, updated in-place (shape: [num_bodies]).\n",
    "        new_position: Output array for updated positions (shape: [num_bodies]).\n",
    "\n",
    "    Note:\n",
    "        This kernel uses the SIMT paradigm where each thread processes one particle.\n",
    "        The kernel should be launched with num_bodies threads.\n",
    "\n",
    "        Integration scheme:\n",
    "        1. a_i(t) = F_i(t) / m_i  (compute acceleration)\n",
    "        2. v_i(t+dt) = v_i(t) + a_i(t) * dt  (update velocity)\n",
    "        3. x_i(t+dt) = x_i(t) + v_i(t+dt) * dt  (update position)\n",
    "\n",
    "        Double buffering is used for positions to avoid race conditions during\n",
    "        parallel updates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get thread ID - each thread handles one particle.\n",
    "    i = wp.tid()\n",
    "\n",
    "    # Calculate gravitational acceleration on this particle from all others.\n",
    "    accel = body_body_interaction(num_bodies, masses, old_position[i], old_position)\n",
    "\n",
    "    # Update velocity using forward Euler integration.\n",
    "    # v(t+dt) = v(t) + a(t) * dt\n",
    "    velocity[i] = velocity[i] + accel * dt\n",
    "\n",
    "    # Update position using the newly computed velocity.\n",
    "    # x(t+dt) = x(t) + v(t+dt) * dt\n",
    "    # Note: We use new_position array to avoid race conditions.\n",
    "    new_position[i] = old_position[i] + dt * velocity[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warp kernel launch and timestepping\n",
    "\n",
    "At this point, we have finished writing the only Warp kernel we need for this simulation.\n",
    "\n",
    "The remaining task is to write a loop that repeatedly launches the Warp kernel and swaps the position arrays for the next iteration so that the updated positions become the current positions.\n",
    "\n",
    "For the latter task, we can use this trick:\n",
    "\n",
    "```python\n",
    "(pos_array_0, pos_array_1) = (pos_array_1, pos_array_0)\n",
    "```\n",
    "If you worked through the 2-D Ising model in Warp notebook, you would remember that the above trick was used there as well but for updating the lattice site spins as the Monte Carlo simulation progressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below performs the steps mentioned above. We re-initialize the inital state of the system using `def init_problem(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "dt = 0.01  # Time step for numerical integration\n",
    "num_bodies = 1024  # Number of particles in the N-body system\n",
    "SOFTENING_SQ = (\n",
    "    0.1**2\n",
    ")  # Softening parameter squared to prevent division by a very small number if two particles come closer\n",
    "\n",
    "# Initialize problem with particle positions, velocities, and masses\n",
    "pos_array_0, pos_array_1, vel_array, mass_array, scale, init_pos_np = init_problem(\n",
    "    num_bodies\n",
    ")\n",
    "\n",
    "# Main simulation loop that integrates particle motion over time\n",
    "for _step_index in range(1000):\n",
    "    # Launch GPU kernel with one thread per particle\n",
    "    wp.launch(\n",
    "        integrate_bodies,\n",
    "        dim=(num_bodies,),  # Launch num_bodies threads\n",
    "        inputs=[num_bodies, dt, mass_array, pos_array_0, vel_array, pos_array_1],\n",
    "    )\n",
    "    # Swap position buffers for next iteration (double buffering)\n",
    "    pos_array_0, pos_array_1 = pos_array_1, pos_array_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Animating the simulation\n",
    "\n",
    "The cell below mainly contains the boilerplate code for animating the N-body simulation built until now. Let's see how the simulation evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "# Initialize problem with particle positions, velocities, and masses\n",
    "pos_array_0, pos_array_1, vel_array, mass_array, scale, init_pos_np = init_problem(\n",
    "    num_bodies\n",
    ")\n",
    "\n",
    "# Create a figure with a dark background\n",
    "plt.style.use(\"dark_background\")\n",
    "fig = plt.figure(figsize=(8, 6), dpi=150)\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Calculate distance of all particles from origin for color mapping\n",
    "distances = np.linalg.norm(init_pos_np, axis=1)\n",
    "\n",
    "# Create a scatter plot\n",
    "scatter_plot = ax.scatter(\n",
    "    init_pos_np[:, 0],\n",
    "    init_pos_np[:, 1],\n",
    "    init_pos_np[:, 2],\n",
    "    c=distances,  # Color by distance from origin\n",
    "    cmap=\"plasma\",  # Set colormap to plasma\n",
    "    s=50,  # Set point size\n",
    "    edgecolors=\"white\",  # White edges for contrast\n",
    "    linewidth=0.5,  # Thin edge lines\n",
    "    marker=\"o\",  # Round markers\n",
    ")\n",
    "\n",
    "# Add a colorbar with label\n",
    "cbar = plt.colorbar(scatter_plot, ax=ax, pad=0.1, shrink=0.8)\n",
    "cbar.set_label(\"Distance from Origin\", rotation=270, labelpad=20, fontsize=12)\n",
    "\n",
    "# Set axis labels with custom fonts\n",
    "ax.set_xlabel(\"X Position\", fontsize=12, fontweight=\"bold\", labelpad=10)\n",
    "ax.set_ylabel(\"Y Position\", fontsize=12, fontweight=\"bold\", labelpad=10)\n",
    "ax.set_zlabel(\"Z Position\", fontsize=12, fontweight=\"bold\", labelpad=10)\n",
    "\n",
    "# Set axis limits with some padding\n",
    "padding = scale * 0.1\n",
    "ax.set_xlim(-scale - padding, scale + padding)\n",
    "ax.set_ylim(-scale - padding, scale + padding)\n",
    "ax.set_zlim(-scale - padding, scale + padding)\n",
    "\n",
    "# Customize the grid\n",
    "ax.grid(True, alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Set a viewing angle\n",
    "ax.view_init(elev=20, azim=45)\n",
    "\n",
    "# Add pane colors for depth perception\n",
    "ax.xaxis.pane.fill = False\n",
    "ax.yaxis.pane.fill = False\n",
    "ax.zaxis.pane.fill = False\n",
    "\n",
    "# Customize tick labels\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=10)\n",
    "\n",
    "# Add a subtle box around the plot region\n",
    "ax.set_box_aspect([1, 1, 1])  # Equal aspect ratio\n",
    "\n",
    "\n",
    "def update_plot(frame):\n",
    "    \"\"\"Update function for animation with proper time stepping.\"\"\"\n",
    "    global pos_array_0, pos_array_1\n",
    "\n",
    "    # Perform integration step using direct kernel launch\n",
    "    wp.launch(\n",
    "        integrate_bodies,\n",
    "        dim=(num_bodies,),\n",
    "        inputs=[num_bodies, dt, mass_array, pos_array_0, vel_array, pos_array_1],\n",
    "    )\n",
    "\n",
    "    # Swap position arrays (double buffering)\n",
    "    pos_array_0, pos_array_1 = pos_array_1, pos_array_0\n",
    "\n",
    "    # Copy updated positions to CPU for visualization\n",
    "    positions_cpu = pos_array_0.numpy()\n",
    "\n",
    "    # Calculate new distances for color mapping\n",
    "    distances = np.linalg.norm(positions_cpu, axis=1)\n",
    "\n",
    "    # Update scatter plot positions\n",
    "    scatter_plot._offsets3d = (\n",
    "        positions_cpu[:, 0],\n",
    "        positions_cpu[:, 1],\n",
    "        positions_cpu[:, 2],\n",
    "    )\n",
    "\n",
    "    # Update colors based on new distances\n",
    "    scatter_plot.set_array(distances)\n",
    "\n",
    "    return scatter_plot\n",
    "\n",
    "\n",
    "# Create animation with optimized settings\n",
    "anim = FuncAnimation(\n",
    "    fig,\n",
    "    update_plot,\n",
    "    frames=1000,\n",
    "    interval=25,\n",
    "    blit=True,\n",
    "    repeat=True,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6eecf",
   "metadata": {},
   "source": [
    "### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79595acc",
   "metadata": {},
   "source": [
    "---\n",
    "## Benchmarking SIMT paradigm\n",
    "\n",
    "Now that we have established our baseline CPU implementation, let us leverage NVIDIA Warp to accelerate our simulation.\n",
    "\n",
    "### Parallel Monte Carlo strategy\n",
    "\n",
    "Our first approach uses a straightforward parallelization strategy:\n",
    "\n",
    "1. Launch a GPU kernel across a $N \\times N$ grid where each thread processes one lattice site\n",
    "2. Use a double-buffer approach to avoid race conditions:\n",
    "   - `lattice_0`: Contains the current state (read-only during update)\n",
    "   - `lattice_1`: Stores the updated state after parallel processing\n",
    "3. After each Monte Carlo step, swap `lattice_0` and `lattice_1` arrays before proceeding to the Monte Carlo step\n",
    "\n",
    "### Main update logic\n",
    "\n",
    "The main update logic would then look something like this:\n",
    "\n",
    "```python\n",
    "def update_sites_in_parallel(i, j, lattice_0, lattice_1, L, beta):\n",
    "    # Read current spin value; current values are stored in lattice_0\n",
    "    spin_ij = lattice_0[i, j]\n",
    "    \n",
    "    # Calculate nearest neighbor sum with periodic boundary conditions\n",
    "    # Use the current state of neighboring spins, i.e., spins taken from lattice_0\n",
    "    nn_sum = (\n",
    "        lattice_0[(i - 1 + L) % L, j] + # Top neighbor\n",
    "        lattice_0[(i + 1) % L, j] +     # Bottom neighbor  \n",
    "        lattice_0[i, (j - 1 + L) % L] + # Left neighbor\n",
    "        lattice_0[i, (j + 1) % L]       # Right neighbor\n",
    "    )\n",
    "    \n",
    "    # Calculate acceptance probability using Metropolis criterion\n",
    "    acceptance_probability = wp.exp(-2.0 * beta * spin_ij * nn_sum)\n",
    "    \n",
    "    # Generate random number and decide whether to flip\n",
    "    if wp.randf() < acceptance_probability:\n",
    "        lattice_1[i, j] = -lattice_0[i, j] # Flip the spin and save to lattice_1\n",
    "```\n",
    "\n",
    "\n",
    "Let us implement this approach and examine its performance and results. We will first write the different Warp kernels needed for this approach. Thereafter, we will assemble all these kernels to simulate the Metropolis algorithm and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad518b01",
   "metadata": {},
   "source": [
    "### GPU memory allocation for the 2-D lattice\n",
    "\n",
    "To implement this on a GPU, we need to allocate memory storage for our 2-D lattice. We will use a 2-D Warp array to store the spin configuration. We use `wp.int8` as our data type since each spin only needs to store values of +1 or -1.\n",
    "\n",
    "### Random number generation in Warp\n",
    "\n",
    "For the Monte Carlo acceptance decisions, each GPU thread needs to generate independent random numbers. Warp provides a built-in random number generator that can be called directly from within kernels.\n",
    "\n",
    "The key components of Warp's random number generator (RNG) are:\n",
    "\n",
    "1. **Initialization**: Create an RNG state using `state = wp.rand_init(seed, offset)`\n",
    "   - `seed`: Common value shared across all threads\n",
    "   - `offset`: Unique value per thread\n",
    "\n",
    "2. **Generation**: Use `wp.randf(state, 0, 1)` to generate random floats in [0,1)\n",
    "\n",
    "This approach ensures that:\n",
    "- Each thread generates independent random numbers\n",
    "- The simulation is reproducible when using the same seed\n",
    "- Random number generation happens efficiently on the GPU without CPU-GPU transfers\n",
    "\n",
    "Now let us implement the lattice initialization using Warp in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e6e48",
   "metadata": {},
   "source": [
    "**Exercise:** In the cell above, change `LATTICE_SIZE` to $128, 64, 32, 16, 8$, then re-run the cell. For smaller `LATTICE_SIZES` of $16$ and $8$, verify that the pattern remains consistent when using the same `rng_seed` but changes when you modify the seed value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ab41c",
   "metadata": {},
   "source": [
    "### Implementing the Monte Carlo update kernel on GPU\n",
    "\n",
    "Now we will implement the core of our GPU-accelerated Ising model simulation: a Warp kernel that performs the Metropolis-Hastings algorithm across the entire lattice in parallel.\n",
    "\n",
    "#### Kernel input parameters\n",
    "\n",
    "Our `update_lattice` kernel requires four key inputs:\n",
    "\n",
    "1. **`lattice_in`**: The 2-D spin configuration array that serves as input\n",
    "2. **`lattice_out`**: The 2-D spin configuration array that serves as output and will be modified in place\n",
    "3. **`rng_seed`**: Random number seed for generating acceptance probabilities  \n",
    "4. **`beta`**: Inverse temperature $\\beta = 1/(k_B T)$, we assume $k_B = 1$\n",
    "\n",
    "#### Parallel execution strategy\n",
    "\n",
    "Each GPU thread will:\n",
    "1. Calculate the energy change $\\Delta E$ from flipping its assigned spin\n",
    "2. Compute the acceptance ratio\n",
    "3. Generate a random number and accept/reject the flip accordingly\n",
    "4. Update the lattice site in `lattice_out` array\n",
    "\n",
    "This approach allows us to evaluate $N^2$ spin flip proposals in parallel, achieving speedup over sequential CPU implementations that you will see in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d051124",
   "metadata": {},
   "source": [
    "The `update_lattice(...)` kernel is called at the beginning of every Monte Carlo step. Once the kernel executes, `lattice_1` contains the updated state of spins. Right after the execution of the `update_lattice(...)` kernel, we swap `lattice_0` and `lattice_1` for the next Monte Carlo step. Hence, a single Monte Carlo step for the current GPU implementation would look something like this:\n",
    "\n",
    "```python\n",
    "# Execute update_lattice kernel to update all lattice sites in parallel\n",
    "# lattice_1 contains the most updated lattice state\n",
    "wp.launch(update_lattice, \n",
    "          dim=(lattice_size, lattice_size),\n",
    "          inputs=[beta, random_seed, lattice_0, lattice_1])\n",
    "    \n",
    "# Swap lattice_1 and lattice_0 for next Monte Carlo step\n",
    "lattice_0, lattice_1 = lattice_1, lattice_0     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86139f9",
   "metadata": {},
   "source": [
    "### First set of results\n",
    "\n",
    "In the cell below, we put together all the building blocks from the previous cells to examine the performance and behavior of our parallelization approach. \n",
    "\n",
    "The implementation we have created mirrors our earlier CPU-based Python version, with the key difference being the use of a buffer to avoid race conditions while trying to update spins in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d47fd",
   "metadata": {},
   "source": [
    "#### Performance gains but unexpected results\n",
    "\n",
    "Running the same lattice size and number of Monte Carlo steps as in the baseline Python implementation reveals significant performance improvements:\n",
    "\n",
    "- **CPU implementation**: ~5.0 seconds for 200 Monte Carlo steps on a 256×256 lattice\n",
    "- **GPU implementation**: ~0.2 seconds for the same workload\n",
    "\n",
    "This represents a **25x speedup** - a significant improvement that demonstrates the power of GPU parallelization for this simulation. The acceleration comes from processing all 65,536 lattice sites in parallel rather than sequentially.\n",
    "\n",
    "However, the results are not correct! At the low temperature $T = 0.02$, the 2-D Ising model should exhibit strong ordering - we should see large domains of aligned spins with well-defined boundaries. Even at high temperatures, the results appear incorrect and differ significantly from our baseline Python implementation. This highlights the importance of maintaining a reference implementation when developing complex algorithms — it provides a reliable benchmark for validating correctness.\n",
    "\n",
    "The lattice configuration appears unusually fragmented and disordered. This unexpected behavior suggests that our seemingly straightforward parallelization approach may have introduced subtle but significant algorithmic issues.\n",
    "\n",
    "#### Investigating the discrepancy\n",
    "\n",
    "The dramatic speedup is certainly encouraging, but the incorrect physics behavior indicates that raw performance gains mean nothing if the underlying algorithm produces wrong results. This observation leads us to an important question:\n",
    "\n",
    "**What could be causing this discrepancy between the expected and the observed behavior? Try thinking about what could be the fundamental differences between the sequential Python implementation and the GPU implementation.**\n",
    "\n",
    "In the next section, we will explore why our naive parallelization fails and introduce the checkerboard approach that correctly preserves the physics while maintaining GPU acceleration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a78493",
   "metadata": {},
   "source": [
    "---\n",
    "## Tile-based programming approach\n",
    "\n",
    "### Why did our parallel trick fail?\n",
    "\n",
    "The problem with our double-buffered approach is that it breaks a core rule of the Metropolis algorithm: **the system must evolve sequentially**. Each update needs to depend on the result of the step that came immediately before it. This one-at-a-time process is what guarantees that the physics comes out right.\n",
    "\n",
    "In our baseline sequential Python implementation, this rule is followed correctly: when a spin at a randomly selected site was flipped, its four neighbors immediately saw the new value for any subsequent calculations. This ensures information flows through the lattice in a sequential fashion.\n",
    "\n",
    "The parallel double-buffered approach breaks this flow. Instead of using the most current information, it forces every spin update to be based on a single, old snapshot of the lattice taken at the beginning of the Monte Carlo step.\n",
    "\n",
    "Because it lacks this essential sequential dependency, the double-buffered method is no longer running the Metropolis algorithm. It is executing a fundamentally different process, which is why it is fast but fails to produce the correct physical results.\n",
    "\n",
    "### The checkerboard approach\n",
    "\n",
    "The algorithm described below takes care of this potential inconsistency during the update process within a single Monte Carlo step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c09baf",
   "metadata": {},
   "source": [
    "Now, we need to allocate separate arrays for the black and white populations.\n",
    "\n",
    "They will be of size $N$ by $N/2$. We assume $N$ is even.\n",
    "\n",
    "We will also allocate a $N$ by $N$ array for the combined lattice. This is not needed for the computation, but\n",
    "it does help with visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14794595",
   "metadata": {},
   "source": [
    "Let us see how this works. We will set all values of `lattice_w` to 1 and all values of `lattice_b` to -1, and then combine the two arrays by running the `combine_lattices` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8f020",
   "metadata": {},
   "source": [
    "**Exercise**: Re-run the above cell with different values of `LATTICE_SIZE`, such as 16, 32, 64, and so on. Verify that the black and white spins maintain their proper checkerboard orientation for all lattice sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212a022",
   "metadata": {},
   "source": [
    "Based on the checkerboard decomposition approach, we will now write an updated version of `update_lattice` kernel. Pay close attention to the inputs of the kernel and the update algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33820a08",
   "metadata": {},
   "source": [
    "Let us run and benchmark the checkerboard algorithm. The code snippet below is similar to the baseline Python implementation, except the lattice updates are performed using Warp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885787b",
   "metadata": {},
   "source": [
    "The output GIFs from the cell above at different `TEMPERATURE` values look visually similar to those generated by the sequential Python implementation at the beginning of the tutorial. The code still runs almost $25\\times$ faster than the sequential Python implementation, despite requiring an extra kernel call per Monte Carlo step to combine the black and white lattice grids and the sequential nature of the black and white lattice updates.\n",
    "\n",
    "While the visual similarity with the sequential Python implementation is reassuring, we need to quantitatively ensure that the underlying physics is faithfully reproduced. Fortunately, as mentioned at the beginning of this tutorial, the 2-D Ising model in zero external magnetic field has an analytical solution when $T < T_{\\mathrm{crit}}$. In the final section of this tutorial, we will compare the results obtained from the Warp-accelerated simulation of the 2-D Ising model with the exact solution to verify the accuracy of our final Warp implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f34104",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparison with analytical solution\n",
    "\n",
    "Finally, we can write some code that plots the steady-state absolute value of magnetization across a range of temperatures.\n",
    "\n",
    "For $T < T_{\\mathrm{crit}}$, there is actually an analytic solution discovered by Onsager in 1944 for the spontaneous magnetization of a 2-D Ising model in zero external magnetic field for temperatures below the critical temperature.\n",
    "\n",
    "\\begin{align}\n",
    "    M = \\left[1 - \\frac{1}{\\left(\\sinh \\left( \\frac{2 J}{k_B T} \\right) \\right)^4}\\right]^{1/8}\n",
    "\\end{align}\n",
    "\n",
    "For $T > T_c$, the system is in a paramagnetic state with no net magnetization ($M = 0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c0bc6",
   "metadata": {},
   "source": [
    "Let us write a kernel that calculates the total magnetization of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670093f8",
   "metadata": {},
   "source": [
    "In the cell below, we build the `calculate_steady_state_magnetization` function. This function executes the following steps for any given temperature and lattice size:\n",
    "\n",
    "1. Initialize the black and white sublattices as in previous cells\n",
    "2. Run the Monte Carlo simulation for 3000 steps to reach a statistical steady state\n",
    "3. Run the Monte Carlo simulation for another 1000 steps to obtain the mean and standard deviation of magnetization for the given temperature\n",
    "4. Return the mean and standard deviation obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a98f7",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we examined different attempts to simulate the Ising model in two dimensions.\n",
    "\n",
    "The main goal of this exercise was to illuminate some considerations when writing algorithms that run **correctly** and **efficiently** on a GPU.\n",
    "\n",
    "Starting from a sequential Python version, we encountered a fundamental challenge: while separating the lattice into \"current\" and \"updated\" grids eliminates race conditions, this approach inadvertently alters the underlying physics, producing an algorithm that no longer faithfully reproduces the statistical mechanics of the original sequential implementation.\n",
    "\n",
    "Finally, we saw that a checkerboard algorithm allows us to recover the intended physics while addressing the data dependency issues that hindered the initial approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e0df8d",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "You can find the Warp GitHub repository and documentation below:\n",
    "* \"NVIDIA/warp: A Python framework for accelerated simulation, data generation and spatial computing.\", GitHub, https://github.com/NVIDIA/warp.\n",
    "* Warp Developers, \"NVIDIA Warp Documentation,\" GitHub Pages, https://nvidia.github.io/warp.\n",
    "\n",
    "Note: This tutorial was inspired by [Romero et al.'s](https://www.sciencedirect.com/science/article/abs/pii/S0010465520302228) work on GPU-accelerated 2-D Ising model simulations."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "warp-cfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
