{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3cebfbd2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Copyright 2025 NVIDIA Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b41de3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Chapter 13: GPU-Accelerated Ising Model Simulation in NVIDIA Warp\n",
    "\n",
    "## Overview\n",
    "\n",
    "In Chapter 12, we introduced NVIDIA Warp as a framework for writing high-performance GPU code in Python. We explored its fundamental concepts: the kernel-based programming model, data structures like arrays and built-in types, and the just-in-time compilation process that enables near-native performance.\n",
    "\n",
    "In this chapter, we will apply these concepts to implement a classic physics simulation: the 2D Ising model. This serves as an excellent case study for GPU acceleration because:\n",
    "\n",
    "1. **Inherent Parallelism**: Each lattice site can potentially be updated independently\n",
    "2. **Memory Access Patterns**: Requires careful consideration of neighbor interactions\n",
    "3. **Real-World Relevance**: The Ising model is fundamental in statistical physics, materials science, etc.\n",
    "\n",
    "Through this implementation, you'll learn:\n",
    "\n",
    "* How to translate a sequential algorithm into a parallel GPU kernel\n",
    "* Common pitfalls when parallelizing algorithms with neighbor dependencies\n",
    "* The checkerboard decomposition pattern for avoiding race conditions\n",
    "* Performance optimization techniques specific to GPU architectures\n",
    "* How to visualize and analyze simulation results\n",
    "\n",
    "By the end of this chapter, you'll have a GPU-accelerated Ising model simulation that runs orders of magnitude faster than its CPU counterpart, while gaining practical experience in applying Warp's features to solve real computational physics problems.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d431841",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we begin implementing the Ising model, let's ensure we have all the necessary packages installed.\n",
    "\n",
    "First, we'll install NVIDIA Warp if it's not already available:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaea329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NVIDIA Warp\n",
    "%pip install warp-lang\n",
    "\n",
    "# Install visualization dependencies\n",
    "%pip install matplotlib ipympl Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292eb53a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Now let's import the necessary libraries and initialize Warp to ensure GPU support is available:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import warp as wp\n",
    "\n",
    "# Initialize Warp and verify GPU is available\n",
    "wp.init()\n",
    "\n",
    "# Check for GPU availability\n",
    "devices = wp.get_devices()\n",
    "if \"cuda:0\" not in [d.alias for d in devices]:\n",
    "    raise RuntimeError(\"No GPU detected! This notebook requires an NVIDIA GPU.\")\n",
    "else:\n",
    "    print(\"✓ GPU detected successfully\")\n",
    "    gpu_device = wp.get_device(\"cuda:0\")\n",
    "    print(f\"  Device: {gpu_device.name}\")\n",
    "    print(f\"  Compute capability: {gpu_device.arch}\")\n",
    "    print(f\"  Memory: {gpu_device.total_memory / (1024**3):.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5750b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Introduction: From Warp Fundamentals to Real-World Applications\n",
    "\n",
    "In Chapter 12, we learned the essential building blocks of NVIDIA Warp:\n",
    "\n",
    "1. **Kernels**: Functions decorated with `@wp.kernel` that run in parallel across many threads\n",
    "2. **Arrays**: The fundamental data structure for GPU computation\n",
    "3. **Built-in Types**: Efficient vector and matrix types like `wp.vec3` and `wp.mat44`\n",
    "4. **Launch Configurations**: How to control kernel execution with `wp.launch()`\n",
    "5. **Memory Spaces**: Understanding CPU vs. GPU memory and data transfers\n",
    "\n",
    "Now, we'll apply these concepts to implement a classic computational physics problem: the 2D Ising model. This implementation will demonstrate:\n",
    "\n",
    "- **Kernel Design Patterns**: How to structure kernels for algorithms with neighbor dependencies\n",
    "- **Memory Access Optimization**: Efficient patterns for reading and writing shared data\n",
    "- **Synchronization Strategies**: Avoiding race conditions in parallel updates\n",
    "- **Performance Analysis**: Comparing GPU vs. CPU implementations\n",
    "\n",
    "The Ising model is particularly instructive because it highlights both the power and challenges of GPU parallelization. While the algorithm seems embarrassingly parallel at first glance (each lattice site can be updated independently), the devil is in the details—neighboring sites interact, creating potential race conditions that must be carefully managed.\n",
    "\n",
    "Let's begin by understanding the physics behind the Ising model, then progressively build our GPU implementation, learning from common pitfalls along the way.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76672792",
   "metadata": {},
   "source": [
    "## Background: The Ising Model in Statistical Physics\n",
    "\n",
    "### What is the Ising Model?\n",
    "\n",
    "The [Ising model](https://en.wikipedia.org/wiki/Ising_model) serves as a fundamental framework for understanding **phase transitions** and **critical phenomena**. Named after physicist Ernst Ising, this model captures the essential physics of ferromagnetism while being simple enough to simulate and analyze computationally.\n",
    "\n",
    "### Physical Setup\n",
    "\n",
    "Imagine a two-dimensional grid where each site contains a **magnetic spin** that can point either \"up\" (↑) or \"down\" (↓). In mathematical terms, each spin $\\sigma_i$ takes the value $+1$ (up) or $-1$ (down). This seemingly simple setup gives rise to remarkably rich physics:\n",
    "\n",
    "- At **low temperatures**: Spins tend to align with their neighbors, creating ordered regions\n",
    "- At **high temperatures**: Thermal fluctuations dominate, leading to random, disordered spin configurations\n",
    "- At the **critical temperature**: The system undergoes a dramatic phase transition\n",
    "\n",
    "### The Physics: Energy and Interactions\n",
    "\n",
    "The total energy of the system is governed by the **Hamiltonian**:\n",
    "\n",
    "\\begin{equation}\n",
    "H(\\sigma) = - J \\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j\n",
    "\\end{equation}\n",
    "\n",
    "Let's break this down:\n",
    "- **$\\sum_{\\langle i,j \\rangle}$**: Sum over all pairs of nearest neighbors (4 neighbors per site in 2D)\n",
    "- **$J > 0$**: Interaction strength (we will set $J = 1$ for simplicity)  \n",
    "- **$\\sigma_i \\sigma_j$**: Product of neighboring spins\n",
    "\n",
    "The key insight is in the **negative sign**:\n",
    "- When neighboring spins are **aligned** ($\\sigma_i = \\sigma_j$): $\\sigma_i \\sigma_j = +1 \\Rightarrow$ energy contribution is $-J$ (lower energy, preferred)\n",
    "- When neighboring spins are **anti-aligned** ($\\sigma_i \\neq \\sigma_j$): $\\sigma_i \\sigma_j = -1 \\Rightarrow$ energy contribution is $+J$ (higher energy, unfavorable)\n",
    "\n",
    "This creates a natural tendency for spins to align with their neighbors.\n",
    "\n",
    "### The Battle: Order vs. Disorder\n",
    "\n",
    "The Ising model beautifully captures the competition between two fundamental forces:\n",
    "\n",
    "1. **Energy Minimization** (favors order): Spins want to align to minimize the Hamiltonian\n",
    "2. **Entropy Maximization** (favors disorder): Thermal fluctuations randomize spin orientations\n",
    "\n",
    "The **temperature** $T$ determines which force wins:\n",
    "- **$T \\ll T_c$**: Energy wins → ordered ferromagnetic state\n",
    "- **$T \\gg T_c$**: Entropy wins → disordered paramagnetic state  \n",
    "- **$T \\approx T_c$**: Critical behavior with scale-invariant fluctuations\n",
    "\n",
    "### Simulation Algorithm: Metropolis-Hastings Method\n",
    "\n",
    "To simulate this system computationally, we use the [**Metropolis-Hastings algorithm**](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm), which samples configurations according to the **Boltzmann distribution**:\n",
    "\n",
    "$$P(\\sigma) \\propto e^{-H(\\sigma)/(k_B T)}$$\n",
    "\n",
    "#### Algorithm Steps\n",
    "\n",
    "Starting from an initial configuration, we iterate the following process:\n",
    "\n",
    "1. **Selection**: Randomly choose a lattice site $i$\n",
    "2. **Proposal**: Consider flipping the spin $\\sigma_i \\rightarrow -\\sigma_i$\n",
    "3. **Energy Change**: Calculate $\\Delta E =$ (energy after flip) - (energy before flip)\n",
    "4. **Accept/Reject Decision**:\n",
    "   - If $\\Delta E \\leq 0$: **Accept** the flip (lower energy is always favorable)\n",
    "   - If $\\Delta E > 0$: **Accept** with probability $P_{accept} = e^{-\\Delta E/(k_B T)}$\n",
    "5. **Update**: Apply the flip if accepted, otherwise keep the original spin\n",
    "\n",
    "#### Why This Works\n",
    "\n",
    "The acceptance probability $e^{-\\Delta E/(k_B T)}$ ensures that:\n",
    "- **Low temperatures**: Only energy-lowering moves are likely to be accepted\n",
    "- **High temperatures**: Even energy-raising moves have significant acceptance probability\n",
    "- **Detailed balance**: The algorithm converges to the correct equilibrium distribution\n",
    "\n",
    "### Computational Significance\n",
    "\n",
    "While the 2D Ising model has known analytical solutions, it serves as an excellent computational testbed because:\n",
    "\n",
    "- **Algorithmic complexity**: The Metropolis algorithm involves neighbor interactions and probabilistic updates\n",
    "- **Parallelization challenges**: Naive parallelization leads to race conditions when updating neighboring spins simultaneously\n",
    "- **Performance optimization**: Memory access patterns and GPU parallelization strategies can be explored\n",
    "- **Scalability**: Real-world applications often involve millions or billions of spins\n",
    "\n",
    "In the next sections, we'll implement this model firs in Numpy and then in NVIDIA Warp -- progressively building from a naive parallel approach to an optimized GPU implementation that avoids race conditions through clever algorithmic design.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49981536",
   "metadata": {},
   "source": [
    "## A Basic Python Implementation\n",
    "\n",
    "Before diving into GPU acceleration with Warp, let's implement a reference version in pure Python. This serves multiple purposes:\n",
    "\n",
    "1. **Algorithm Verification**: Ensures our understanding of the Metropolis-Hastings algorithm is correct\n",
    "2. **Performance Baseline**: Provides a comparison point for measuring GPU speedup\n",
    "3. **Debugging Reference**: A simple implementation to validate against more complex GPU code\n",
    "\n",
    "### Implementation Strategy\n",
    "\n",
    "Our Python implementation follows the standard Metropolis-Hastings algorithm:\n",
    "\n",
    "- **Random Site Selection**: Instead of scanning sites in order, we randomly shuffle the update sequence to avoid artifacts\n",
    "- **Periodic Boundary Conditions**: The lattice wraps around at edges\n",
    "- **Energy-Based Acceptance**: We use the full Boltzmann acceptance probability $P = e^{-\\Delta E / T}$\n",
    "\n",
    "### Performance Limitations\n",
    "\n",
    "Since this is a pure Python implementation with nested loops and random number generation, we're restricted to relatively small lattice sizes (≤ 512×512) for reasonable simulation times. The GPU implementation will dramatically improve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a27f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "def initialize_lattice(L):\n",
    "    \"\"\"\n",
    "    Initialize a square lattice with random spin orientations.\n",
    "    \n",
    "    Creates an L×L grid where each site contains a magnetic spin that can be\n",
    "    either +1 (spin up) or -1 (spin down). The initial configuration is\n",
    "    completely random, representing a high-temperature disordered state.\n",
    "    \n",
    "    Args:\n",
    "        L (int): Linear size of the lattice (creates L×L grid)\n",
    "        \n",
    "    Returns:\n",
    "        list[list[int]]: 2D lattice where lattice[i][j] ∈ {-1, +1}\n",
    "        \n",
    "    Example:\n",
    "        >>> lattice = initialize_lattice(4)\n",
    "        >>> print(len(lattice), len(lattice[0]))  # 4x4 grid\n",
    "        4 4\n",
    "        >>> all(spin in [-1, 1] for row in lattice for spin in row)\n",
    "        True\n",
    "    \"\"\"\n",
    "    lattice = [[random.choice([-1, 1]) for _ in range(L)] for _ in range(L)]\n",
    "    return lattice\n",
    "\n",
    "\n",
    "def monte_carlo_step(lattice, L, T):\n",
    "    \"\"\"\n",
    "    Perform one complete Monte Carlo step using the Metropolis-Hastings algorithm.\n",
    "    \n",
    "    A Monte Carlo step (MCS) consists of attempting to flip each spin in the \n",
    "    lattice exactly once on average. We visit sites in random order to avoid\n",
    "    systematic biases that could arise from sequential scanning.\n",
    "    \n",
    "    For each site, we calculate the energy change ΔE that would result from\n",
    "    flipping the spin, then accept or reject the flip based on the Boltzmann\n",
    "    probability: P_accept = min(1, exp(-ΔE/T))\n",
    "    \n",
    "    Physical Parameters (using natural units):\n",
    "        - J = 1: Interaction strength (energy scale)\n",
    "        - k_B = 1: Boltzmann constant\n",
    "        - Periodic boundary conditions (toroidal lattice)\n",
    "    \n",
    "    Args:\n",
    "        lattice (list[list[int]]): Current spin configuration to update in-place\n",
    "        L (int): Linear lattice size \n",
    "        T (float): Temperature in units where k_B = J = 1\n",
    "                   T_critical ≈ 2.269 for 2D Ising model\n",
    "    \n",
    "    Algorithm Details:\n",
    "        1. Create list of all (i,j) lattice coordinates\n",
    "        2. Randomly shuffle the update order to avoid artifacts\n",
    "        3. For each site (i,j):\n",
    "           a. Calculate sum of 4 nearest neighbors using periodic boundaries\n",
    "           b. Compute energy change: ΔE = 2 * J * σ_ij * Σ_neighbors  \n",
    "           c. Accept flip with probability P = exp(-ΔE/T)\n",
    "           d. Update lattice[i][j] *= -1 if flip accepted\n",
    "    \n",
    "    Note:\n",
    "        The acceptance ratio simplifies to exp(-2 * β * σ_ij * neighbor_sum)\n",
    "        because we only consider the energy difference, not absolute energy.\n",
    "    \"\"\"\n",
    "    # Convert temperature to inverse temperature (β = 1/T in natural units)\n",
    "    beta = 1.0 / T\n",
    "\n",
    "    # Generate all lattice coordinates and randomize update order\n",
    "    # This prevents systematic artifacts from sequential scanning\n",
    "    site_indices = [(r_idx, c_idx) for r_idx in range(L) for c_idx in range(L)]\n",
    "    random.shuffle(site_indices)\n",
    "\n",
    "    # Attempt to flip each spin according to Metropolis acceptance criterion\n",
    "    for i, j in site_indices:\n",
    "        # Current spin at site (i,j)\n",
    "        spin_ij = lattice[i][j]\n",
    "\n",
    "        # Calculate sum of 4 nearest neighbors with periodic boundary conditions\n",
    "        # Modulo arithmetic wraps around lattice edges: (i-1+L)%L handles i=0 case\n",
    "        nn_sum = (\n",
    "            lattice[(i - 1 + L) % L][j]      # neighbor above\n",
    "            + lattice[(i + 1) % L][j]        # neighbor below  \n",
    "            + lattice[i][(j - 1 + L) % L]    # neighbor left\n",
    "            + lattice[i][(j + 1) % L]        # neighbor right\n",
    "        )\n",
    "\n",
    "        # Energy change from flipping spin: ΔE = -J * (σ_new - σ_old) * Σ_neighbors\n",
    "        # Since σ_new = -σ_old, we get: ΔE = 2 * J * σ_ij * Σ_neighbors\n",
    "        # Acceptance probability: P = exp(-β * ΔE) = exp(-2 * β * σ_ij * Σ_neighbors)\n",
    "        acceptance_ratio = math.exp(-2.0 * beta * spin_ij * nn_sum)\n",
    "\n",
    "        # Accept flip if random number < acceptance probability\n",
    "        if random.random() < acceptance_ratio:\n",
    "            lattice[i][j] *= -1  # Flip the spin: +1 → -1 or -1 → +1\n",
    "        # If flip rejected, spin remains unchanged (no action needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import IPython.display\n",
    "\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ================================\n",
    "# Demonstration 1: Visual Evolution\n",
    "# ================================\n",
    "\"\"\"\n",
    "This demonstration shows the real-time evolution of the Ising model as an animated GIF.\n",
    "We'll observe how the system evolves from a random initial state toward equilibrium.\n",
    "\n",
    "Key observations to look for:\n",
    "- Domain formation: Regions of aligned spins (same color) will grow\n",
    "- Thermal fluctuations: At finite temperature, domains constantly change\n",
    "- Steady state: Eventually the system reaches dynamic equilibrium\n",
    "\"\"\"\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "LATTICE_SIZE = 256\n",
    "TEMPERATURE = 1.0 # Try: T=1.0 (ordered), T=2.269 (critical), T=5.0 (disordered)\n",
    "\n",
    "print(f\"Simulating {LATTICE_SIZE}×{LATTICE_SIZE} Ising model at T={TEMPERATURE}\")\n",
    "print(f\"Critical temperature T_c ≈ 2.269 (this run: {'below' if TEMPERATURE < 2.269 else 'above'} T_c)\")\n",
    "\n",
    "# Initialize with random spins (mimics infinite temperature initial condition)\n",
    "lattice = initialize_lattice(LATTICE_SIZE)\n",
    "\n",
    "# Set up visualization colormap\n",
    "# Viridis colormap: dark blue (-1 spins) to bright yellow (+1 spins)\n",
    "viridis = plt.cm.viridis\n",
    "norm = Normalize(vmin=-1, vmax=1)\n",
    "\n",
    "# Collect animation frames\n",
    "frames = []\n",
    "print(\"Running simulation and capturing frames...\")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for step in range(200):  # 200 Monte Carlo steps\n",
    "    # Evolve the system by one complete lattice sweep\n",
    "    monte_carlo_step(lattice, LATTICE_SIZE, TEMPERATURE)\n",
    "\n",
    "    # Convert lattice to colored image for visualization\n",
    "    # Each spin value (-1 or +1) gets mapped to a color\n",
    "    colored_frame = viridis(norm(np.array(lattice)))\n",
    "\n",
    "    # Convert to 8-bit RGB for GIF creation\n",
    "    rgb_frame = (colored_frame[:, :, :3] * 255).astype(np.uint8)\n",
    "    frames.append(rgb_frame)\n",
    "\n",
    "    # Progress indicator\n",
    "    if (step + 1) % 50 == 0:\n",
    "        print(f\"  Step {step + 1}/200 completed\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Simulation completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Create animated GIF to visualize time evolution\n",
    "print(\"Creating animated GIF...\")\n",
    "pil_images = [Image.fromarray(frame, mode=\"RGB\") for frame in frames]\n",
    "output_filename = f\"output/{LATTICE_SIZE}x{LATTICE_SIZE}_{TEMPERATURE}.gif\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "\n",
    "# Save as animated GIF (100ms per frame = 10 FPS)\n",
    "pil_images[0].save(\n",
    "    output_filename, \n",
    "    save_all=True, \n",
    "    append_images=pil_images[1:], \n",
    "    duration=100,  # milliseconds per frame\n",
    "    loop=0         # infinite loop\n",
    ")\n",
    "\n",
    "IPython.display.Image(output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Demonstration 2: Magnetization Analysis\n",
    "# =======================================\n",
    "\"\"\"\n",
    "This demonstration tracks the magnetization over time to study thermodynamic properties.\n",
    "Magnetization M = ⟨Σᵢ σᵢ⟩ / N is the order parameter for the ferromagnetic transition.\n",
    "\n",
    "Physical meaning:\n",
    "- M ≈ ±1: Ordered state (most spins aligned)\n",
    "- M ≈ 0: Disordered state (equal up/down spins)\n",
    "- |M| decreases as T approaches T_c from below\n",
    "\"\"\"\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "LATTICE_SIZE = 256\n",
    "TEMPERATURE = 1.0 # Try: T=1.0 (ordered), T=2.269 (critical), T=5.0 (disordered)\n",
    "\n",
    "print(f\"Magnetization analysis: {LATTICE_SIZE}×{LATTICE_SIZE} lattice at T={TEMPERATURE}\")\n",
    "\n",
    "# Initialize with random configuration\n",
    "lattice = initialize_lattice(LATTICE_SIZE)\n",
    "magnetization_values = []\n",
    "\n",
    "\n",
    "def calculate_magnetization(lattice, L):\n",
    "    \"\"\"\n",
    "    Calculate the normalized magnetization of the lattice.\n",
    "    \n",
    "    The magnetization M is the order parameter for the ferromagnetic phase transition.\n",
    "    It measures the degree of spin alignment in the system.\n",
    "    \n",
    "    Args:\n",
    "        lattice (list[list[int]]): Current spin configuration\n",
    "        L (int): Linear lattice size\n",
    "        \n",
    "    Returns:\n",
    "        float: Normalized magnetization M ∈ [-1, +1]\n",
    "               M = +1: All spins up (perfect ferromagnetic order)\n",
    "               M = -1: All spins down (perfect ferromagnetic order)  \n",
    "               M = 0: Equal numbers of up/down spins (disordered)\n",
    "    \n",
    "    Physics Notes:\n",
    "        - M is the thermal average ⟨Σᵢ σᵢ⟩ / N in equilibrium\n",
    "        - |M| → 0 as T → T_c from below (continuous phase transition)\n",
    "        - M fluctuates around its equilibrium value due to thermal noise\n",
    "    \"\"\"\n",
    "    total_spin = sum(sum(row) for row in lattice)\n",
    "    return total_spin / (L * L)\n",
    "\n",
    "\n",
    "# Run simulation and track magnetization evolution\n",
    "print(\"Running magnetization tracking simulation...\")\n",
    "for step in range(500):\n",
    "    monte_carlo_step(lattice, LATTICE_SIZE, TEMPERATURE)\n",
    "    current_mag = calculate_magnetization(lattice, LATTICE_SIZE)\n",
    "    magnetization_values.append(current_mag)\n",
    "    \n",
    "    # Progress update\n",
    "    if (step + 1) % 100 == 0:\n",
    "        print(f\"  Step {step + 1}/500, Current M = {current_mag:.3f}\")\n",
    "\n",
    "# Create magnetization time series plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(magnetization_values, \"-\", linewidth=1.5, color=\"#76b900\", alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(\"Monte Carlo Steps\", fontsize=12)\n",
    "ax.set_ylabel(\"Magnetization M\", fontsize=12)\n",
    "ax.set_title(f\"Magnetization Evolution (T={TEMPERATURE:.3f}, T_c≈2.269)\", fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = False\n",
    "fig.canvas.resizable = False\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79595acc",
   "metadata": {},
   "source": [
    "--- \n",
    "## GPU Implementation Part 1: Naive Parallelization Approach\n",
    "\n",
    "Now that we have established our baseline CPU implementation, let's leverage NVIDIA Warp to accelerate our simulation.\n",
    "\n",
    "### Parallel Monte Carlo Strategy\n",
    "\n",
    "Our first approach uses a straightforward parallelization strategy:\n",
    "\n",
    "1. Launch a GPU kernel across a $N \\times N$ grid where each thread processes one lattice site\n",
    "2. Use a double-buffer approach to avoid race conditions:\n",
    "   - `lattice_0`: Contains the current state (read-only during update)\n",
    "   - `lattice_1`: Stores the updated state after parallel processing\n",
    "\n",
    "### Core Update Logic\n",
    "\n",
    "The core update logic would then look something like this\n",
    "\n",
    "```python\n",
    "def parallel_update_site(i, j, lattice_0, lattice_1, L, beta):\n",
    "    # Read current spin value\n",
    "    spin_ij = lattice_0[i, j]\n",
    "    \n",
    "    # Calculate nearest neighbor sum with periodic boundary conditions\n",
    "    # from lattice_0\n",
    "    nn_sum = (\n",
    "        lattice_0[(i - 1 + L) % L, j] +      # Top neighbor\n",
    "        lattice_0[(i + 1) % L, j] +          # Bottom neighbor  \n",
    "        lattice_0[i, (j - 1 + L) % L] +      # Left neighbor\n",
    "        lattice_0[i, (j + 1) % L]            # Right neighbor\n",
    "    )\n",
    "    \n",
    "    # Calculate acceptance probability using Metropolis criterion\n",
    "    acceptance_probability = wp.exp(-2.0 * beta * spin_ij * nn_sum)\n",
    "    \n",
    "    # Generate random number and decide whether to flip\n",
    "    if wp.randf() < acceptance_probability:\n",
    "        lattice_1[i, j] = -lattice_0[i, j]     # Flip the spin and save to lattice_1\n",
    "```\n",
    "\n",
    "Let's implement this approach and examine its performance characteristics..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad518b01",
   "metadata": {},
   "source": [
    "### GPU Memory Allocation\n",
    "\n",
    "To implement this on the GPU, we need to allocate storage for our lattice data structure. We will use a 2D Warp array to store the spin configuration. We use `wp.int8` as our data type since each spin only needs to store values of +1 or -1, making this the most memory-efficient choice.\n",
    "\n",
    "### Random Number Generation in Warp\n",
    "\n",
    "For the Monte Carlo acceptance decisions, each GPU thread needs to generate independent random numbers. Warp provides a built-in random number generator that can be called directly from within kernels.\n",
    "\n",
    "The key components of Warp's RNG system are:\n",
    "\n",
    "1. **Initialization**: Create an RNG state using `wp.rand_init(seed, offset)`\n",
    "   - `seed`: Common value shared across all threads (ensures reproducibility)\n",
    "   - `offset`: Unique value per thread (ensures uncorrelated sequences)\n",
    "\n",
    "2. **Generation**: Use `wp.randf(state)` to generate random floats in [0,1)\n",
    "\n",
    "This approach ensures that:\n",
    "- Each thread generates independent random numbers\n",
    "- The simulation is reproducible when using the same seed\n",
    "- Random number generation happens efficiently on the GPU without CPU-GPU transfers\n",
    "\n",
    "Now let's implement the complete solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warp as wp\n",
    "\n",
    "# ==============================================\n",
    "# Direct Parallelization Implementation\n",
    "# ==============================================\n",
    "\n",
    "# Define lattice dimensions - using 256x256 for demonstration\n",
    "# Larger sizes will showcase GPU acceleration benefits more clearly\n",
    "LATTICE_SIZE = 256\n",
    "\n",
    "# Allocate GPU memory for the spin lattice\n",
    "# wp.int8 stores values -1 and +1 efficiently (1 byte per spin)\n",
    "# wp.empty() allocates uninitialized memory on the default device (GPU)\n",
    "lattice = wp.empty((LATTICE_SIZE, LATTICE_SIZE), dtype=wp.int8)\n",
    "\n",
    "@wp.kernel\n",
    "def generate_lattice(lattice: wp.array2d(dtype=wp.int8), rng_seed: int):\n",
    "    \"\"\"\n",
    "    GPU kernel to initialize the lattice with random spin configurations.\n",
    "    \n",
    "    Each GPU thread handles one lattice site, generating a random spin value.\n",
    "    This demonstrates Warp's parallel random number generation capabilities.\n",
    "    \n",
    "    Args:\n",
    "        lattice: 2D array to fill with random spins (+1 or -1)\n",
    "        rng_seed: Seed for reproducible random number generation\n",
    "    \n",
    "    Kernel Launch:\n",
    "        wp.launch(generate_lattice, dim=(LATTICE_SIZE, LATTICE_SIZE), ...)\n",
    "        Creates LATTICE_SIZE² threads, one per lattice site\n",
    "    \"\"\"\n",
    "    # Get this thread's 2D coordinates within the lattice\n",
    "    # wp.tid() returns (i, j) where i∈[0,LATTICE_SIZE), j∈[0,LATTICE_SIZE)\n",
    "    i, j = wp.tid()\n",
    "\n",
    "    # Initialize random number generator state for this specific thread\n",
    "    # - rng_seed: Shared across all threads for reproducible simulations\n",
    "    # - offset: Unique per thread to ensure independent random sequences\n",
    "    # - Linear indexing: thread (i,j) gets offset = i*width + j\n",
    "    thread_offset = i * lattice.shape[1] + j\n",
    "    rng_state = wp.rand_init(rng_seed, thread_offset)\n",
    "    \n",
    "    # Generate random spin value: +1 or -1 with equal probability\n",
    "    # wp.randf() produces uniform random float in [0.0, 1.0)\n",
    "    # 50% probability for each spin direction\n",
    "    random_value = wp.randf(rng_state, 0.0, 1.0)\n",
    "    if random_value < 0.5:\n",
    "        lattice[i, j] = wp.int8(1)   # Spin up\n",
    "    else:\n",
    "        lattice[i, j] = wp.int8(-1)  # Spin down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6aeccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wp.launch(generate_lattice, lattice.shape, inputs=[lattice, 42])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(lattice.numpy(), cmap=\"viridis\")\n",
    "plt.title(f\"Lattice {LATTICE_SIZE}x{LATTICE_SIZE}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ab41c",
   "metadata": {},
   "source": [
    "### Implementing the Monte Carlo Update Kernel on GPU\n",
    "\n",
    "Now we'll implement the core of our GPU-accelerated Ising model simulation: a Warp kernel that performs the Metropolis-Hastings algorithm across the entire lattice in parallel.\n",
    "\n",
    "#### Kernel Input Parameters\n",
    "\n",
    "Our `update_lattice` kernel requires four key inputs:\n",
    "\n",
    "1. **`lattice_in`**: The 2D spin configuration array that serves as input\n",
    "2. **`lattice_out`**: The 2D spin configuration array that serves as output and will be modified in place\n",
    "3. **`rng_seed`**: Random number seed for generating acceptance probabilities  \n",
    "4. **`beta`**: Inverse temperature $\\beta = 1/(k_B T)$\n",
    "\n",
    "#### Parallel Execution Strategy\n",
    "\n",
    "Each GPU thread will:\n",
    "1. Calculate the energy change $\\Delta E$ from flipping its assigned spin\n",
    "2. Compute the acceptance ratio\n",
    "3. Generate a random number and accept/reject the flip accordingly\n",
    "4. Update the lattice site in **lattice_out** array\n",
    "\n",
    "This massively parallel approach allows us to evaluate $N^2$ spin flip proposals simultaneously, achieving speedups over sequential CPU implementations that you will see in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wp.kernel\n",
    "def update_lattice(\n",
    "    beta: float,\n",
    "    rng_seed: int,\n",
    "    lattice_in: wp.array2d(dtype=wp.int8),\n",
    "    lattice_out: wp.array2d(dtype=wp.int8),\n",
    "):\n",
    "    i, j = wp.tid()\n",
    "\n",
    "    # Neighbors: top, bottom, left, right\n",
    "    nn_sum = (\n",
    "        lattice_in[(i - 1 + LATTICE_SIZE) % LATTICE_SIZE, j]\n",
    "        + lattice_in[(i + 1) % LATTICE_SIZE, j]\n",
    "        + lattice_in[i, (j - 1 + LATTICE_SIZE) % LATTICE_SIZE]\n",
    "        + lattice_in[i, (j + 1) % LATTICE_SIZE]\n",
    "    )\n",
    "\n",
    "    # Determine whether to flip spin\n",
    "    spin_ij = lattice_in[i, j]\n",
    "    acceptance_ratio = wp.exp(-2.0 * beta * wp.float32(nn_sum) * wp.float32(spin_ij))\n",
    "\n",
    "    # Generate random number between [0.0, 1.0).\n",
    "    rng_state = wp.rand_init(rng_seed, i * LATTICE_SIZE + j)\n",
    "\n",
    "    if wp.randf(rng_state, 0.0, 1.0) < acceptance_ratio:\n",
    "        lattice_out[i, j] = -spin_ij\n",
    "    else:\n",
    "        lattice_out[i, j] = spin_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86139f9",
   "metadata": {},
   "source": [
    "### Performance Analysis: First Results\n",
    "\n",
    "Now let's examine the performance and behavior of our direct parallelization approach. The implementation we've created closely mirrors our earlier CPU-based Python version, with the key difference being the use of Warp kernels for GPU acceleration.\n",
    "\n",
    "#### Performance Gains: The Promise of Parallelization\n",
    "\n",
    "Running the same lattice size and number of Monte Carlo steps reveals dramatic performance improvements:\n",
    "\n",
    "- **CPU Implementation**: ~5.0 seconds for 200 Monte Carlo steps on a 256×256 lattice\n",
    "- **GPU Implementation**: ~0.1-0.2 seconds for the same workload\n",
    "\n",
    "This represents a **25-50× speedup** - a remarkable improvement that demonstrates the power of GPU parallelization for Monte Carlo simulations. The acceleration comes from processing all 65,536 lattice sites simultaneously rather than sequentially.\n",
    "\n",
    "#### Unexpected Results: A Physics Puzzle\n",
    "\n",
    "However, careful examination of the simulation results at T = 1.0 reveals something concerning. At this low temperature, the 2D Ising model should exhibit strong ferromagnetic ordering - we should see large domains of aligned spins with well-defined boundaries.\n",
    "\n",
    "Instead, the lattice configuration appears unusually fragmented and disordered. This unexpected behavior suggests that our seemingly straightforward parallelization approach may have introduced subtle but significant algorithmic issues.\n",
    "\n",
    "#### Investigating the Discrepancy\n",
    "\n",
    "The dramatic speedup is certainly encouraging, but the incorrect physics behavior indicates that raw performance gains mean nothing if the underlying algorithm produces wrong results. This observation leads us to an important question:\n",
    "\n",
    "**What could be causing this discrepancy between expected and observed behavior?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b224ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import IPython.display\n",
    "\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ================================\n",
    "# Demonstration 1: Visual Evolution\n",
    "# ================================\n",
    "\"\"\"\n",
    "This demonstration shows the real-time evolution of the Ising model as an animated GIF.\n",
    "We'll observe how the system evolves from a random initial state toward equilibrium.\n",
    "\n",
    "Key observations to look for:\n",
    "- Domain formation: Regions of aligned spins (same color) will grow\n",
    "- Thermal fluctuations: At finite temperature, domains constantly change\n",
    "- Steady state: Eventually the system reaches dynamic equilibrium\n",
    "\"\"\"\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "LATTICE_SIZE = 256\n",
    "TEMPERATURE = 1.0 # Try: T=1.0 (ordered), T=2.269 (critical), T=5.0 (disordered)\n",
    "\n",
    "\n",
    "#--- Warp related initializations/declarations ---\n",
    "BETA = 1.0 / TEMPERATURE\n",
    "lattice_0 = wp.empty((LATTICE_SIZE, LATTICE_SIZE), dtype=wp.int8)\n",
    "lattice_1 = wp.empty((LATTICE_SIZE, LATTICE_SIZE), dtype=wp.int8)\n",
    "\n",
    "wp.launch(generate_lattice, lattice_0.shape, inputs=[lattice_0, 42])\n",
    "\n",
    "print(f\"Simulating {LATTICE_SIZE}×{LATTICE_SIZE} Ising model at T={TEMPERATURE}\")\n",
    "print(f\"Critical temperature T_c ≈ 2.269 (this run: {'below' if TEMPERATURE < 2.269 else 'above'} T_c)\")\n",
    "\n",
    "# Set up visualization colormap\n",
    "# Viridis colormap: dark blue (-1 spins) to bright yellow (+1 spins)\n",
    "viridis = plt.cm.viridis\n",
    "norm = Normalize(vmin=-1, vmax=1)\n",
    "\n",
    "# Collect animation frames\n",
    "frames = []\n",
    "print(\"Running simulation and capturing frames...\")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for step in range(200):  # 200 Monte Carlo steps\n",
    "    # Warp kernel call that updates the lattice\n",
    "    wp.launch(update_lattice, lattice.shape, inputs=[BETA, step, lattice_0, lattice_1])\n",
    "    lattice_0, lattice_1 = lattice_1, lattice_0\n",
    "\n",
    "    # Convert lattice to colored image for visualization\n",
    "    # Each spin value (-1 or +1) gets mapped to a color\n",
    "    colored_frame = viridis(norm(np.array(lattice_1.numpy())))\n",
    "\n",
    "    # Convert to 8-bit RGB for GIF creation\n",
    "    rgb_frame = (colored_frame[:, :, :3] * 255).astype(np.uint8)\n",
    "    frames.append(rgb_frame)\n",
    "\n",
    "    # Progress indicator\n",
    "    if (step + 1) % 50 == 0:\n",
    "        print(f\"  Step {step + 1}/200 completed\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Simulation completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Create animated GIF to visualize time evolution\n",
    "print(\"Creating animated GIF...\")\n",
    "pil_images = [Image.fromarray(frame, mode=\"RGB\") for frame in frames]\n",
    "output_filename = f\"output/{LATTICE_SIZE}x{LATTICE_SIZE}_{TEMPERATURE}.gif\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "\n",
    "# Save as animated GIF (100ms per frame = 10 FPS)\n",
    "pil_images[0].save(\n",
    "    output_filename, \n",
    "    save_all=True, \n",
    "    append_images=pil_images[1:], \n",
    "    duration=100,  # milliseconds per frame\n",
    "    loop=0         # infinite loop\n",
    ")\n",
    "\n",
    "IPython.display.Image(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a78493",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GPU Implementation Part 2: Checkerboard Approach\n",
    "\n",
    "The issue with the previous approach is that multiple threads are reading and writing to the shared data in an uncoordinated way. If you remember the baseline Python implementation, the subsequenct at different site_indices can have dependency on the new values of lattice points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warp-cfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
