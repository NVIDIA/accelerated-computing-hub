{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b6145d",
   "metadata": {},
   "source": [
    "# CUDA Parallel Tutorial - High-Level GPU Programming\n",
    "## Table of Contents\n",
    "\n",
    "1. Introduction to cuda.cccl.parallel\n",
    "2. Setting Up Your Environment\n",
    "3. Understanding Parallel Algorithms\n",
    "4. Your First Reduction\n",
    "5. Working with Iterators\n",
    "6. Scan Operations (Prefix Sums)\n",
    "7. Sorting Algorithms\n",
    "8. Transform Operations\n",
    "9. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea40ed6",
   "metadata": {},
   "source": [
    "## 1. Introduction to cuda.cccl.parallel\n",
    "The `cuda.cccl.parallel` module provides a high-level, Pythonic interface to GPU programming. Unlike `cuda.core`, it abstracts away many low-level details while still providing excellent performance.\n",
    "\n",
    "Think of `cuda.cccl.parallel` as a toolkit of pre-built, highly optimized parallel algorithms that you can use without writing any CUDA code yourself.\n",
    "\n",
    "### What Makes It Special?\n",
    "\n",
    "**High-Level Abstractions**: Instead of writing complex GPU kernels, you call simple Python functions like `reduce_into()`, `sort()`, or `scan()`.\n",
    "\n",
    "**Performance**: These algorithms deliver the performance of hand-optimized CUDA kernels - they're written by NVIDIA's experts and optimized for all GPU architectures.\n",
    "\n",
    "**Pythonic**: Works seamlessly with NumPy arrays and CuPy arrays, using familiar Python syntax.\n",
    "\n",
    "**No Memory Management**: The library handles all GPU memory allocation and deallocation automatically.\n",
    "\n",
    "### When to Use cuda.cccl.parallel\n",
    "**Best used for:**\n",
    "\n",
    "* Data science and scientific computing\n",
    "* When you need fast parallel algorithms (reduce, scan, sort, transform)\n",
    "* Prototyping GPU-accelerated applications\n",
    "* Learning parallel programming concepts\n",
    "* When you want GPU performance without CUDA complexity\n",
    "\n",
    "Comparison with cuda.core:\n",
    "| Feature             | cuda.core              | cuda.parallel         |\n",
    "|---------------------|------------------------|-----------------------|\n",
    "| Memory Management   | Manual                 | Automatic             |\n",
    "| Kernel Definition   | CUDA C/C++ strings     | Python decorators     |\n",
    "| Learning Curve      | Steep                  | Gentle                |\n",
    "| Performance Control | Maximum                | Good                  |\n",
    "| Development Speed   | Slow                   | Fast                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034acedd",
   "metadata": {},
   "source": [
    "## 2. Setting Up Your Environment\n",
    "### Prerequisites\n",
    "\n",
    "* NVIDIA GPU with CUDA capability\n",
    "* CUDA driver version 12.2 or higher\n",
    "* Python 3.8+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71178c05",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d7fc4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install cuda-cccl\n",
    "!pip install \"cuda-cccl[test-cu12]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c38f3",
   "metadata": {},
   "source": [
    "### Quick Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63305c3f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cuda.cccl.parallel.experimental as parallel\n",
    "\n",
    "def verify_installation():\n",
    "    \"\"\"Test that cuda.cccl.parallel is working correctly\"\"\"\n",
    "    \n",
    "    print(\"=== CUDA Parallel Installation Test ===\")\n",
    "    \n",
    "    # Test 1: Check if we can create GPU arrays\n",
    "    try:\n",
    "        test_array = cp.array([1, 2, 3, 4, 5], dtype=np.int32)\n",
    "        print(\"✓ CuPy GPU arrays working\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ CuPy error: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 2: Simple reduction operation\n",
    "    try:\n",
    "        def add_op(a, b):\n",
    "            return a + b\n",
    "        \n",
    "        # Input data\n",
    "        d_input = cp.array([1, 2, 3, 4, 5], dtype=np.int32)\n",
    "        d_output = cp.empty(1, dtype=np.int32)\n",
    "        h_init = np.array([0], dtype=np.int32)\n",
    "        \n",
    "        # Perform reduction\n",
    "        parallel.reduce_into(d_input, d_output, add_op, len(d_input), h_init)\n",
    "        \n",
    "        result = d_output.get()[0]  # Copy result back to CPU\n",
    "        expected = 15  # 1+2+3+4+5\n",
    "        \n",
    "        if result == expected:\n",
    "            print(f\"✓ Parallel reduction working: {result}\")\n",
    "        else:\n",
    "            print(f\"✗ Reduction failed: got {result}, expected {expected}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Parallel operation error: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"✓ All tests passed! cuda.cccl.parallel is ready to use.\")\n",
    "    return True\n",
    "\n",
    "# Run verification\n",
    "verify_installation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff9447",
   "metadata": {},
   "source": [
    "**What this test does**:\n",
    "1. Creates GPU arrays: Verifies CuPy can allocate GPU memory\n",
    "2. Tests parallel reduction: Confirms the parallel library can sum numbers on GPU\n",
    "3. Checks results: Ensures the computation is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682a8b8",
   "metadata": {},
   "source": [
    "## 3. Understanding Parallel Algorithms\n",
    "### What Are Parallel Algorithms?\n",
    "**Sequential algorithm** (like a for-loop): Does one operation at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a185fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Sequential sum - does one addition at a time\n",
    "total = 0\n",
    "for num in [1, 2, 3, 4, 5]:\n",
    "    total += num  # One operation per step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14843c87",
   "metadata": {},
   "source": [
    "**Parallel algorithm**: Does many operations simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e4bbe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Parallel sum - combines pairs simultaneously\n",
    "# Step 1: [1,2,3,4,5] → [3, 7, 5] (1+2=3, 3+4=7, 5 remains)\n",
    "# Step 2: [3, 7, 5] → [10, 5] (3+7=10, 5 remains) \n",
    "# Step 3: [10, 5] → [15] (10+5=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a4b5e",
   "metadata": {},
   "source": [
    "### The Power of Parallelism\n",
    "**Why parallel algorithms matter:**\n",
    "* Speed: What takes 1 second on CPU might take 0.01 seconds on GPU\n",
    "* Scalability: Performance improves as data size increases\n",
    "* Efficiency: Better use of modern hardware\n",
    "\n",
    "**Real-world example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfbdfd7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Processing 1 million numbers\n",
    "# CPU sequential: ~100ms\n",
    "# GPU parallel: ~1ms (100x faster!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd466d",
   "metadata": {},
   "source": [
    "### Core Algorithm Types\n",
    "Let's understand the main types of parallel algorithms:\n",
    "**1. Reduction: Combine all elements into one result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380b3b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Examples: sum, max, min, average\n",
    "[1, 2, 3, 4, 5] → 15 (sum)\n",
    "[1, 2, 3, 4, 5] → 5 (max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8f619",
   "metadata": {},
   "source": [
    "**2. Scan (Prefix Sum): Running total of elements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8660b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Inclusive scan (include current element)\n",
    "[1, 2, 3, 4, 5] → [1, 3, 6, 10, 15]\n",
    "\n",
    "# Exclusive scan (exclude current element)\n",
    "[1, 2, 3, 4, 5] → [0, 1, 3, 6, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3acd46",
   "metadata": {},
   "source": [
    "**3. Sort: Arrange elements in order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b83ee4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[5, 2, 8, 1, 9] → [1, 2, 5, 8, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde06a02",
   "metadata": {},
   "source": [
    "**4. Transform: Apply function to each element**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37da5ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Square each element\n",
    "[1, 2, 3, 4, 5] → [1, 4, 9, 16, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01908d54",
   "metadata": {},
   "source": [
    "#### Understanding Algorithm Complexity\n",
    "**Why parallel algorithms are different:**\n",
    "\n",
    "**Sequential complexity**: O(n) - time grows linearly with data size\n",
    "\n",
    "**Parallel complexit**y**: O(log n) - time grows logarithmically with data size\n",
    "\n",
    "**Real example with 1 million elements:**\n",
    "* Sequential: 1,000,000 operations\n",
    "* Parallel: ~20 operations (log₂(1,000,000) ≈ 20)\n",
    "\n",
    "This is why GPU algorithms can be 100x faster!\n",
    "\n",
    "### 4. Your First Reduction\n",
    "**What is a Reduction?**\n",
    "\n",
    "A **reduction** takes many values and combines them into a single result using a binary operation (a function that takes two inputs).\n",
    "\n",
    "**Common reductions:**\n",
    "* Sum: Add all numbers together\n",
    "* Maximum: Find the largest number\n",
    "* Minimum: Find the smallest number\n",
    "* Product: Multiply all numbers together\n",
    "\n",
    "**Basic Sum Reduction**\n",
    "\n",
    "Let's start with the simplest example, adding numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce5791",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cuda.cccl.parallel.experimental as parallel\n",
    "\n",
    "def basic_sum_example():\n",
    "    \"\"\"Learn reduction by summing numbers on GPU\"\"\"\n",
    "    \n",
    "    print(\"=== Basic Sum Reduction ===\")\n",
    "    \n",
    "    # Step 1: Define our operation (how to combine two numbers)\n",
    "    def add_op(a, b):\n",
    "        \"\"\"Add two numbers together\"\"\"\n",
    "        return a + b\n",
    "    \n",
    "    # Step 2: Create input data on GPU\n",
    "    input_data = [1, 2, 3, 4, 5]\n",
    "    print(f\"Input data: {input_data}\")\n",
    "    \n",
    "    d_input = cp.array(input_data, dtype=np.int32)  # Move to GPU\n",
    "    print(f\"Created GPU array with {len(d_input)} elements\")\n",
    "    \n",
    "    # Step 3: Prepare output storage\n",
    "    d_output = cp.empty(1, dtype=np.int32)  # Space for 1 result\n",
    "    \n",
    "    # Step 4: Set initial value (what to start the sum with)\n",
    "    h_init = np.array([0], dtype=np.int32)  # Start from 0\n",
    "    \n",
    "    # Step 5: Perform the reduction\n",
    "    parallel.reduce_into(\n",
    "        d_input,        # Input array on GPU\n",
    "        d_output,       # Output array on GPU  \n",
    "        add_op,         # Function to combine elements\n",
    "        len(d_input),   # Number of elements to process\n",
    "        h_init          # Initial value\n",
    "    )\n",
    "    \n",
    "    # Step 6: Get result back to CPU\n",
    "    result = d_output.get()[0]\n",
    "    expected = sum(input_data)\n",
    "    \n",
    "    print(f\"GPU result: {result}\")\n",
    "    print(f\"CPU verification: {expected}\")\n",
    "    print(f\"Correct: {result == expected}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run the example\n",
    "basic_sum_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e011f13",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "1. Define operation: `add_op(a, b)` tells the GPU how to combine two numbers\n",
    "2. Create GPU data: `cp.array()` moves our data to GPU memory\n",
    "3. Prepare output: `cp.empty(1)` allocates space for the single result\n",
    "4. Set initial value: Start the sum from 0\n",
    "5. Run reduction: The GPU combines all elements in parallel\n",
    "6. Get result: `.get()` copies the result back to CPU memory\n",
    "\n",
    "**Understanding the parallel execution:**\n",
    "Input: [1, 2, 3, 4, 5]\n",
    "Step 1: Pairs combine → [3, 7, 5] (1+2=3, 3+4=7)\n",
    "Step 2: Continue → [10, 5] (3+7=10)  \n",
    "Step 3: Final → [15] (10+5=15)\n",
    "\n",
    "**Finding Maximum Value**\n",
    "Let's try a different reduction, finding the largest number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad1976",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def maximum_reduction_example():\n",
    "    \"\"\"Find the maximum value in an array\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Maximum Value Reduction ===\")\n",
    "    \n",
    "    # Step 1: Define how to find maximum of two numbers\n",
    "    def max_op(a, b):\n",
    "        \"\"\"Return the larger of two numbers\"\"\"\n",
    "        return a if a > b else b\n",
    "    \n",
    "    # Step 2: Create test data with some large and small numbers\n",
    "    input_data = [23, 7, 91, 15, 4, 88, 12, 77, 3, 99]\n",
    "    print(f\"Input data: {input_data}\")\n",
    "    \n",
    "    d_input = cp.array(input_data, dtype=np.int32)\n",
    "    d_output = cp.empty(1, dtype=np.int32)\n",
    "    \n",
    "    # Step 3: Set initial value (start with very small number)\n",
    "    h_init = np.array([-999999], dtype=np.int32)  # Very small starting value\n",
    "    \n",
    "    # Step 4: Find maximum\n",
    "    parallel.reduce_into(d_input, d_output, max_op, len(d_input), h_init)\n",
    "    \n",
    "    # Step 5: Compare with CPU result\n",
    "    gpu_max = d_output.get()[0]\n",
    "    cpu_max = max(input_data)\n",
    "    \n",
    "    print(f\"GPU maximum: {gpu_max}\")\n",
    "    print(f\"CPU maximum: {cpu_max}\")\n",
    "    print(f\"Correct: {gpu_max == cpu_max}\")\n",
    "    \n",
    "    return gpu_max\n",
    "\n",
    "# Run the example\n",
    "maximum_reduction_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc43a2",
   "metadata": {},
   "source": [
    "**Why we use a very small initial value:**\n",
    "* The reduction combines the initial value with our data\n",
    "* If we started with 0, and all our numbers were negative, we'd get 0 (wrong!)\n",
    "* Starting with -999999 ensures any real number will be larger\n",
    "\n",
    "### Custom Reduction: Average\n",
    "Let's create a more complex reduction to calculate the average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e903da39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def average_reduction_example():\n",
    "    \"\"\"Calculate average using reduction (more advanced)\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Average Calculation ===\")\n",
    "    \n",
    "    # For average, we need both sum and count\n",
    "    # We'll use a custom data structure\n",
    "    \n",
    "    @parallel.gpu_struct\n",
    "    class SumCount:\n",
    "        \"\"\"Custom type to hold sum and count together\"\"\"\n",
    "        total: np.float64\n",
    "        count: np.int32\n",
    "    \n",
    "    def combine_sum_count(a, b):\n",
    "        \"\"\"Combine two SumCount structures\"\"\"\n",
    "        return SumCount(a.total + b.total, a.count + b.count)\n",
    "    \n",
    "    def value_to_sum_count(value):\n",
    "        \"\"\"Convert a single value to SumCount\"\"\"\n",
    "        return SumCount(float(value), 1)\n",
    "    \n",
    "    # Create input data\n",
    "    input_data = [10, 20, 30, 40, 50]\n",
    "    print(f\"Input data: {input_data}\")\n",
    "    \n",
    "    d_input = cp.array(input_data, dtype=np.float64)\n",
    "    \n",
    "    # Transform each value to SumCount structure\n",
    "    transform_it = parallel.TransformIterator(d_input, value_to_sum_count)\n",
    "    \n",
    "    # Prepare output\n",
    "    d_output = cp.empty(1, dtype=SumCount.dtype)\n",
    "    h_init = SumCount(0.0, 0)\n",
    "    \n",
    "    # Perform reduction\n",
    "    parallel.reduce_into(transform_it, d_output, combine_sum_count, len(d_input), h_init)\n",
    "    \n",
    "    # Calculate average\n",
    "    result = d_output.get()[0]\n",
    "    gpu_average = result['total'] / result['count']\n",
    "    cpu_average = sum(input_data) / len(input_data)\n",
    "    \n",
    "    print(f\"GPU average: {gpu_average}\")\n",
    "    print(f\"CPU average: {cpu_average}\")\n",
    "    print(f\"Correct: {abs(gpu_average - cpu_average) < 1e-10}\")\n",
    "    \n",
    "    return gpu_average\n",
    "\n",
    "# Run the example\n",
    "average_reduction_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8f7c0",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "1. Custom type: We create `SumCount` to hold both sum and count\n",
    "2. Transform: Convert each number to a `SumCount(value, 1)`\n",
    "3. Combine: Add sums and counts separately\n",
    "4. Final calculation: Divide total by count to get average\n",
    "\n",
    "This shows how parallel algorithms can handle complex operations!\n",
    "\n",
    "### Performance Comparison\n",
    "Let's see how much faster GPU reduction is compared to CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f179363",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def performance_comparison():\n",
    "    \"\"\"Compare GPU vs CPU performance for large arrays\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Performance Comparison ===\")\n",
    "    \n",
    "    # Test with different array sizes\n",
    "    sizes = [1000, 10000, 100000, 1000000]\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    for size in sizes:\n",
    "        print(f\"\\nTesting with {size:,} elements:\")\n",
    "        \n",
    "        # Create large random array\n",
    "        np.random.seed(42)  # For reproducible results\n",
    "        data = np.random.randint(0, 100, size, dtype=np.int32)\n",
    "        \n",
    "        # Test CPU performance\n",
    "        start_time = time.time()\n",
    "        cpu_result = np.sum(data)  # NumPy sum\n",
    "        cpu_time = time.time() - start_time\n",
    "        \n",
    "        # Test GPU performance\n",
    "        d_input = cp.array(data)\n",
    "        d_output = cp.empty(1, dtype=np.int32)\n",
    "        h_init = np.array([0], dtype=np.int32)\n",
    "        \n",
    "        # Warm up GPU (first run is always slower)\n",
    "        parallel.reduce_into(d_input, d_output, add_op, len(d_input), h_init)\n",
    "        \n",
    "        # Time the actual operation\n",
    "        start_time = time.time()\n",
    "        parallel.reduce_into(d_input, d_output, add_op, len(d_input), h_init)\n",
    "        gpu_result = d_output.get()[0]\n",
    "        gpu_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate speedup\n",
    "        speedup = cpu_time / gpu_time if gpu_time > 0 else float('inf')\n",
    "        \n",
    "        print(f\"  CPU time: {cpu_time*1000:.2f} ms\")\n",
    "        print(f\"  GPU time: {gpu_time*1000:.2f} ms\") \n",
    "        print(f\"  Speedup: {speedup:.1f}x\")\n",
    "        print(f\"  Results match: {cpu_result == gpu_result}\")\n",
    "\n",
    "# Run performance comparison\n",
    "performance_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2567bc4d",
   "metadata": {},
   "source": [
    "Expected results:\n",
    "* Small arrays (1,000 elements): GPU might be slower due to overhead\n",
    "* Large arrays (1,000,000+ elements): GPU can be 10-100x faster\n",
    "* The speedup increases with array size\n",
    "\n",
    "Why this happens:\n",
    "* GPU has setup overhead but massive parallel processing power\n",
    "* CPU is fast for small tasks but doesn't scale well\n",
    "* As data grows, GPU's parallel advantage becomes dominant\n",
    "\n",
    "## 5. Working with Iterators\n",
    "#### **What Are Iterators?**\n",
    "\n",
    "Iterators provide a way to represent sequences of data without needing to allocate memory for them. Think of them as \"virtual arrays\" that generate values on-demand.\n",
    "\n",
    "**Benefits of iterators:**\n",
    "* Memory efficient: No need to store all values in memory\n",
    "* Composable: Can combine multiple iterators together\n",
    "* Flexible: Generate sequences, transform data, reverse arrays\n",
    "\n",
    "#### CountingIterator: Generate Number Sequences\n",
    "The most basic iterator generates a sequence of consecutive numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e5f6b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def counting_iterator_example():\n",
    "    \"\"\"Learn iterators by generating number sequences\"\"\"\n",
    "    \n",
    "    print(\"=== CountingIterator Example ===\")\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    # Instead of creating an array [10, 11, 12], we use an iterator\n",
    "    first_number = 10\n",
    "    how_many = 5  # Generate 5 numbers: 10, 11, 12, 13, 14\n",
    "    \n",
    "    print(f\"Generating sequence starting from {first_number}, {how_many} numbers\")\n",
    "    print(f\"Virtual sequence: {list(range(first_number, first_number + how_many))}\")\n",
    "    \n",
    "    # Create the counting iterator\n",
    "    counting_it = parallel.CountingIterator(np.int32(first_number))\n",
    "    \n",
    "    # Prepare reduction\n",
    "    d_output = cp.empty(1, dtype=np.int32)\n",
    "    h_init = np.array([0], dtype=np.int32)\n",
    "    \n",
    "    # Sum the sequence without storing it in memory!\n",
    "    parallel.reduce_into(counting_it, d_output, add_op, how_many, h_init)\n",
    "    \n",
    "    # Verify result\n",
    "    gpu_result = d_output.get()[0]\n",
    "    cpu_result = sum(range(first_number, first_number + how_many))\n",
    "    \n",
    "    print(f\"GPU sum: {gpu_result}\")\n",
    "    print(f\"CPU sum: {cpu_result}\")\n",
    "    print(f\"Correct: {gpu_result == cpu_result}\")\n",
    "    \n",
    "    # Show memory efficiency\n",
    "    print(f\"\\nMemory efficiency:\")\n",
    "    print(f\"  Array approach: would need {how_many * 4} bytes\")\n",
    "    print(f\"  Iterator approach: needs ~0 bytes (generated on-demand)\")\n",
    "\n",
    "counting_iterator_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7e377",
   "metadata": {},
   "source": [
    "Why this is powerful:\n",
    "* No memory allocation for the sequence\n",
    "* Can generate huge sequences without running out of memory\n",
    "* Perfect for mathematical sequences and patterns\n",
    "### ConstantIterator: Repeat the Same Value\n",
    "Sometimes you need a sequence of identical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8254c7b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def constant_iterator_example():\n",
    "    \"\"\"Use ConstantIterator to create sequences of repeated values\"\"\"\n",
    "    \n",
    "    print(\"\\n=== ConstantIterator Example ===\")\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    # Create virtual array of repeated 7s: [7, 7, 7, 7, 7]\n",
    "    repeated_value = 7\n",
    "    how_many = 1000\n",
    "    \n",
    "    print(f\"Creating {how_many} copies of {repeated_value}\")\n",
    "    \n",
    "    # Create constant iterator\n",
    "    constant_it = parallel.ConstantIterator(np.int32(repeated_value))\n",
    "    \n",
    "    # Sum all the repeated values\n",
    "    d_output = cp.empty(1, dtype=np.int32)\n",
    "    h_init = np.array([0], dtype=np.int32)\n",
    "    \n",
    "    parallel.reduce_into(constant_it, d_output, add_op, how_many, h_init)\n",
    "    \n",
    "    gpu_result = d_output.get()[0]\n",
    "    expected = repeated_value * how_many  # 7 * 1000 = 7000\n",
    "    \n",
    "    print(f\"GPU result: {gpu_result}\")\n",
    "    print(f\"Expected: {expected}\")\n",
    "    print(f\"Correct: {gpu_result == expected}\")\n",
    "    \n",
    "    # Real-world use case\n",
    "    print(f\"\\nReal-world use: Initialize arrays, default values, padding\")\n",
    "\n",
    "constant_iterator_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd7bcd",
   "metadata": {},
   "source": [
    "**Use cases for ConstantIterator:**\n",
    "* Initializing arrays with default values\n",
    "* Creating padding for algorithms\n",
    "* Mathematical operations with constants\n",
    "\n",
    "### TransformIterator: Apply Functions On-The-Fly\n",
    "TransformIterator provides a way to compose operations by applying a function to each element as it's accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07692972",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def transform_iterator_example():\n",
    "    \"\"\"Use TransformIterator to apply functions without storing intermediate results\"\"\"\n",
    "    \n",
    "    print(\"\\n=== TransformIterator Example ===\")\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    def square_op(x):\n",
    "        \"\"\"Square a number\"\"\"\n",
    "        return x * x\n",
    "    \n",
    "    # We want to: \n",
    "    # 1. Generate numbers [1, 2, 3, 4, 5]\n",
    "    # 2. Square each one [1, 4, 9, 16, 25]  \n",
    "    # 3. Sum the squares = 55\n",
    "    # All without storing intermediate arrays!\n",
    "    \n",
    "    first_number = 1\n",
    "    how_many = 5\n",
    "    \n",
    "    print(f\"Computing sum of squares from {first_number} to {first_number + how_many - 1}\")\n",
    "    \n",
    "    # Step 1: Create counting iterator for [1, 2, 3, 4, 5]\n",
    "    counting_it = parallel.CountingIterator(np.int32(first_number))\n",
    "    \n",
    "    # Step 2: Transform each number by squaring it\n",
    "    transform_it = parallel.TransformIterator(counting_it, square_op)\n",
    "    \n",
    "    # Step 3: Sum the transformed values\n",
    "    d_output = cp.empty(1, dtype=np.int32)\n",
    "    h_init = np.array([0], dtype=np.int32)\n",
    "    \n",
    "    parallel.reduce_into(transform_it, d_output, add_op, how_many, h_init)\n",
    "    \n",
    "    # Verify\n",
    "    gpu_result = d_output.get()[0]\n",
    "    numbers = list(range(first_number, first_number + how_many))\n",
    "    cpu_result = sum(x * x for x in numbers)\n",
    "    \n",
    "    print(f\"Original numbers: {numbers}\")\n",
    "    print(f\"Squared numbers: {[x*x for x in numbers]}\")\n",
    "    print(f\"GPU sum of squares: {gpu_result}\")\n",
    "    print(f\"CPU sum of squares: {cpu_result}\")\n",
    "    print(f\"Correct: {gpu_result == cpu_result}\")\n",
    "    \n",
    "    # Show the power of composition\n",
    "    print(f\"\\nPower of composition:\")\n",
    "    print(f\"  No intermediate arrays stored\")\n",
    "    print(f\"  Operations fused together for efficiency\")\n",
    "\n",
    "transform_iterator_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7a9da",
   "metadata": {},
   "source": [
    "**The magic of TransformIterator:**\n",
    "1. Memory efficient: No intermediate arrays stored\n",
    "2. Composable: Chain multiple transformations together\n",
    "3. Efficient: Operations are \"fused\" together on the GPU\n",
    "\n",
    "### Complex Iterator Composition\n",
    "Let's combine multiple iterators to solve a real problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d33a85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def complex_iterator_example():\n",
    "    \"\"\"Combine multiple iterators to solve: sum of squares of even numbers\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Complex Iterator Composition ===\")\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    def square_if_even(x):\n",
    "        \"\"\"Square the number if it's even, otherwise return 0\"\"\"\n",
    "        return (x * x) if (x % 2 == 0) else 0\n",
    "    \n",
    "    # Goal: From numbers 1-10, square the even ones and sum\n",
    "    # Even numbers: 2, 4, 6, 8, 10\n",
    "    # Squares: 4, 16, 36, 64, 100  \n",
    "    # Sum: 220\n",
    "    \n",
    "    first_number = 1\n",
    "    how_many = 10\n",
    "    \n",
    "    print(f\"Finding sum of squares of even numbers from {first_number} to {first_number + how_many - 1}\")\n",
    "    \n",
    "    # Chain operations together\n",
    "    counting_it = parallel.CountingIterator(np.int32(first_number))\n",
    "    transform_it = parallel.TransformIterator(counting_it, square_if_even)\n",
    "    \n",
    "    # Perform reduction\n",
    "    d_output = cp.empty(1, dtype=np.int32)\n",
    "    h_init = np.array([0], dtype=np.int32)\n",
    "    \n",
    "    parallel.reduce_into(transform_it, d_output, add_op, how_many, h_init)\n",
    "    \n",
    "    # Verify result\n",
    "    gpu_result = d_output.get()[0]\n",
    "    \n",
    "    # CPU verification\n",
    "    numbers = list(range(first_number, first_number + how_many))\n",
    "    even_numbers = [x for x in numbers if x % 2 == 0]\n",
    "    squares = [x * x for x in even_numbers]\n",
    "    cpu_result = sum(squares)\n",
    "    \n",
    "    print(f\"All numbers: {numbers}\")\n",
    "    print(f\"Even numbers: {even_numbers}\")\n",
    "    print(f\"Squares of evens: {squares}\")\n",
    "    print(f\"GPU result: {gpu_result}\")\n",
    "    print(f\"CPU result: {cpu_result}\")\n",
    "    print(f\"Correct: {gpu_result == cpu_result}\")\n",
    "\n",
    "complex_iterator_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf81527",
   "metadata": {},
   "source": [
    "### Iterator Performance Benefits\n",
    "Let's compare memory usage between arrays and iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea3c50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def iterator_performance_comparison():\n",
    "    \"\"\"Compare memory usage: arrays vs iterators\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Iterator Performance Comparison ===\")\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    def square_op(x):\n",
    "        return x * x\n",
    "    \n",
    "    # Test with large sequences\n",
    "    sequence_size = 1000000  # 1 million numbers\n",
    "    \n",
    "    print(f\"Processing {sequence_size:,} numbers\")\n",
    "    \n",
    "    # Method 1: Using arrays (memory intensive)\n",
    "    print(\"\\nMethod 1: Using Arrays\")\n",
    "    try:\n",
    "        # This creates actual arrays in memory\n",
    "        start_time = time.time()\n",
    "        d_input = cp.arange(1, sequence_size + 1, dtype=np.int32)\n",
    "        d_squared = cp.square(d_input)  # Another array\n",
    "        result_array = cp.sum(d_squared)\n",
    "        array_time = time.time() - start_time\n",
    "        \n",
    "        memory_used = d_input.nbytes + d_squared.nbytes\n",
    "        print(f\"  Time: {array_time*1000:.2f} ms\")\n",
    "        print(f\"  Memory used: {memory_used / (1024**2):.1f} MB\")\n",
    "        print(f\"  Result: {result_array}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Failed: {e}\")\n",
    "        array_time = float('inf')\n",
    "        memory_used = float('inf')\n",
    "    \n",
    "    # Method 2: Using iterators (memory efficient)  \n",
    "    print(\"\\nMethod 2: Using Iterators\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    counting_it = parallel.CountingIterator(np.int32(1))\n",
    "    transform_it = parallel.TransformIterator(counting_it, square_op)\n",
    "    \n",
    "    d_output = cp.empty(1, dtype=np.int64)  # Only need space for result\n",
    "    h_init = np.array([0], dtype=np.int64)\n",
    "    \n",
    "    parallel.reduce_into(transform_it, d_output, add_op, sequence_size, h_init)\n",
    "    result_iterator = d_output.get()[0]\n",
    "    iterator_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  Time: {iterator_time*1000:.2f} ms\")\n",
    "    print(f\"  Memory used: {d_output.nbytes} bytes (~0 MB)\")\n",
    "    print(f\"  Result: {result_iterator}\")\n",
    "    \n",
    "    # Compare efficiency\n",
    "    if array_time != float('inf'):\n",
    "        speedup = array_time / iterator_time\n",
    "        memory_savings = memory_used / d_output.nbytes\n",
    "        print(f\"\\nComparison:\")\n",
    "        print(f\"  Iterator is {speedup:.1f}x faster\")\n",
    "        print(f\"  Iterator uses {memory_savings:.0f}x less memory\")\n",
    "    else:\n",
    "        print(f\"\\nArrays failed due to memory constraints, iterators succeeded!\")\n",
    "\n",
    "iterator_performance_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3c384",
   "metadata": {},
   "source": [
    "**Key takeaways about iterators:**\n",
    "1. Memory efficient: Generate data on-demand, no storage needed\n",
    "2. Composable: Chain operations together easily\n",
    "3. Performance: Often faster due to better memory usage\n",
    "4. Scalable: Work with sequences too large to fit in memory\n",
    "\n",
    "### 6. Scan Operations (Prefix Sums)\n",
    "#### What is a Scan Operation?\n",
    "A **scan** (also called prefix sum) computes a running total of elements. For each position, it shows the cumulative result up to that point.\n",
    "\n",
    "**Two types of scans:**\n",
    "* Inclusive scan: Includes the current element in the sum\n",
    "* Exclusive scan: Excludes the current element (shifts results)\n",
    "\n",
    "**Visual example:**\n",
    "\n",
    "Input:     [3, 1, 4, 1, 5]\n",
    "Inclusive: [3, 4, 8, 9, 14]  (3, 3+1, 3+1+4, 3+1+4+1, 3+1+4+1+5)\n",
    "Exclusive: [0, 3, 4, 8, 9]   (0, 3, 3+1, 3+1+4, 3+1+4+1)\n",
    "\n",
    "**Why Scans Are Useful**\n",
    "\n",
    "Scans are building blocks for many parallel algorithms:\n",
    "* Parallel selection: Filter arrays in parallel\n",
    "* Stream compaction: Remove unwanted elements\n",
    "* Histogram computation: Count occurrences efficiently\n",
    "* Load balancing: Distribute work evenly\n",
    "\n",
    "**Basic Inclusive Scan**\n",
    "\n",
    "Let's start with an inclusive scan (running sum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486482c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def inclusive_scan_example():\n",
    "    \"\"\"Learn inclusive scan with running sum\"\"\"\n",
    "    \n",
    "    print(\"=== Inclusive Scan Example ===\")\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    # Input data\n",
    "    input_data = [3, 1, 4, 1, 5, 9, 2, 6]\n",
    "    print(f\"Input data: {input_data}\")\n",
    "    \n",
    "    # Setup GPU arrays\n",
    "    d_input = cp.array(input_data, dtype=np.int32)\n",
    "    d_output = cp.empty_like(d_input)  # Same size as input\n",
    "    \n",
    "    # Initial value (what to start the scan with)\n",
    "    h_init = np.array([0], dtype=np.int32)\n",
    "    \n",
    "    # Perform inclusive scan\n",
    "    parallel.inclusive_scan(\n",
    "        d_input,        # Input array\n",
    "        d_output,       # Output array (same size)\n",
    "        add_op,         # Operation to apply\n",
    "        h_init,         # Initial value\n",
    "        len(d_input)    # Number of elements\n",
    "    )\n",
    "    \n",
    "    # Get results\n",
    "    gpu_result = d_output.get()\n",
    "    \n",
    "    # CPU verification\n",
    "    cpu_result = np.cumsum(input_data)  # NumPy cumulative sum\n",
    "    \n",
    "    print(f\"GPU inclusive scan: {gpu_result}\")\n",
    "    print(f\"CPU cumulative sum: {cpu_result}\")\n",
    "    print(f\"Results match: {np.array_equal(gpu_result, cpu_result)}\")\n",
    "    \n",
    "    # Show step-by-step breakdown\n",
    "    print(f\"\\nStep-by-step breakdown:\")\n",
    "    for i, (inp, out) in enumerate(zip(input_data, gpu_result)):\n",
    "        running_sum = sum(input_data[:i+1])\n",
    "        print(f\"  Position {i}: input={inp}, running_sum={running_sum}, output={out}\")\n",
    "\n",
    "inclusive_scan_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f951878",
   "metadata": {},
   "source": [
    "**Understanding inclusive scan:**\n",
    "* Each output position contains the sum from start up to (and including) that position\n",
    "* * Position 0: sum of elements 0 to 0 = 3\n",
    "* Position 1: sum of elements 0 to 1 = 3+1 = 4\n",
    "* Position 2: sum of elements 0 to 2 = 3+1+4 = 8\n",
    "* And so on...\n",
    "\n",
    "#### Exclusive Scan\n",
    "Exclusive scan shifts the results by one position and starts with the initial value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8abe7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def exclusive_scan_example():\n",
    "    \"\"\"Learn exclusive scan with shifted running sum\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Exclusive Scan Example ===\")\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    # Same input data\n",
    "    input_data = [3, 1, 4, 1, 5, 9, 2, 6]\n",
    "    print(f\"Input data: {input_data}\")\n",
    "    \n",
    "    # Setup GPU arrays\n",
    "    d_input = cp.array(input_data, dtype=np.int32)\n",
    "    d_output = cp.empty_like(d_input)\n",
    "    \n",
    "    # Initial value\n",
    "    h_init = np.array([0], dtype=np.int32)\n",
    "    \n",
    "    # Perform exclusive scan\n",
    "    parallel.exclusive_scan(\n",
    "        d_input,\n",
    "        d_output,\n",
    "        add_op,\n",
    "        h_init,\n",
    "        len(d_input)\n",
    "    )\n",
    "    \n",
    "    # Get results\n",
    "    gpu_result = d_output.get()\n",
    "    \n",
    "    # CPU verification (exclusive scan)\n",
    "    cpu_result = np.concatenate([[0], np.cumsum(input_data)[:-1]])\n",
    "    \n",
    "    print(f\"GPU exclusive scan: {gpu_result}\")\n",
    "    print(f\"CPU exclusive scan: {cpu_result}\")\n",
    "    print(f\"Results match: {np.array_equal(gpu_result, cpu_result)}\")\n",
    "    \n",
    "    # Show step-by-step breakdown\n",
    "    print(f\"\\nStep-by-step breakdown:\")\n",
    "    for i, (inp, out) in enumerate(zip(input_data, gpu_result)):\n",
    "        if i == 0:\n",
    "            running_sum = 0  # Initial value\n",
    "        else:\n",
    "            running_sum = sum(input_data[:i])\n",
    "        print(f\"  Position {i}: input={inp}, sum_before={running_sum}, output={out}\")\n",
    "\n",
    "exclusive_scan_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee198a",
   "metadata": {},
   "source": [
    "**Understanding exclusive scan:**\n",
    "* Each output position contains the sum from start up to (but excluding) that position\n",
    "* Position 0: sum before position 0 = 0 (initial value)\n",
    "* Position 1: sum before position 1 = 3\n",
    "* Position 2: sum before position 2 = 3+1 = 4\n",
    "* And so on...\n",
    "\n",
    "### Maximum Scan\n",
    "Scans aren't just for addition. Let's find running maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e87f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def maximum_scan_example():\n",
    "    \"\"\"Find running maximum using scan\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Maximum Running Scan ===\")\n",
    "    \n",
    "    def max_op(a, b):\n",
    "        return a if a > b else b\n",
    "    \n",
    "    # Input data with various values\n",
    "    input_data = [3, 7, 2, 9, 1, 8, 4, 6]\n",
    "    print(f\"Input data: {input_data}\")\n",
    "    \n",
    "    # Setup\n",
    "    d_input = cp.array(input_data, dtype=np.int32)\n",
    "    d_output = cp.empty_like(d_input)\n",
    "    \n",
    "    # Start with very small value\n",
    "    h_init = np.array([-999999], dtype=np.int32)\n",
    "    \n",
    "    # Perform inclusive scan with max operation\n",
    "    parallel.inclusive_scan(d_input, d_output, max_op, h_init, len(d_input))\n",
    "    \n",
    "    # Get results  \n",
    "    gpu_result = d_output.get()\n",
    "    \n",
    "    # CPU verification\n",
    "    cpu_result = np.maximum.accumulate(input_data)\n",
    "    \n",
    "    print(f\"GPU running max: {gpu_result}\")\n",
    "    print(f\"CPU running max: {cpu_result}\")\n",
    "    print(f\"Results match: {np.array_equal(gpu_result, cpu_result)}\")\n",
    "    \n",
    "    # Show interpretation\n",
    "    print(f\"\\nInterpretation:\")\n",
    "    for i, (inp, out) in enumerate(zip(input_data, gpu_result)):\n",
    "        print(f\"  Position {i}: current={inp}, max_so_far={out}\")\n",
    "\n",
    "maximum_scan_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b9e86",
   "metadata": {},
   "source": [
    "### Performance Comparison: Scan vs Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c89fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def scan_performance_comparison():\n",
    "    \"\"\"Compare scan performance with sequential operations\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Scan Performance Comparison ===\")\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        return a + b\n",
    "    \n",
    "    # Test with different sizes\n",
    "    sizes = [1000, 10000, 100000, 1000000]\n",
    "    \n",
    "    for size in sizes:\n",
    "        print(f\"\\nTesting with {size:,} elements:\")\n",
    "        \n",
    "        # Create test data\n",
    "        np.random.seed(42)\n",
    "        data = np.random.randint(1, 10, size, dtype=np.int32)\n",
    "        \n",
    "        # CPU sequential cumulative sum\n",
    "        start_time = time.time()\n",
    "        cpu_result = np.cumsum(data)\n",
    "        cpu_time = time.time() - start_time\n",
    "        \n",
    "        # GPU parallel scan\n",
    "        d_input = cp.array(data)\n",
    "        d_output = cp.empty_like(d_input)\n",
    "        h_init = np.array([0], dtype=np.int32)\n",
    "        \n",
    "        # Warm up\n",
    "        parallel.inclusive_scan(d_input, d_output, add_op, h_init, len(d_input))\n",
    "        \n",
    "        # Time the operation\n",
    "        start_time = time.time()\n",
    "        parallel.inclusive_scan(d_input, d_output, add_op, h_init, len(d_input))\n",
    "        gpu_result = d_output.get()\n",
    "        gpu_time = time.time() - start_time\n",
    "        \n",
    "        # Compare\n",
    "        speedup = cpu_time / gpu_time if gpu_time > 0 else float('inf')\n",
    "        \n",
    "        print(f\"  CPU time: {cpu_time*1000:.2f} ms\")\n",
    "        print(f\"  GPU time: {gpu_time*1000:.2f} ms\")\n",
    "        print(f\"  Speedup: {speedup:.1f}x\")\n",
    "        print(f\"  Results match: {np.allclose(cpu_result, gpu_result)}\")\n",
    "\n",
    "scan_performance_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c9542",
   "metadata": {},
   "source": [
    "**Scan performance insights:**\n",
    "* Small arrays: CPU might be faster due to GPU overhead\n",
    "* Large arrays: GPU can be 10-50x faster\n",
    "* Memory bound: Performance limited by memory bandwidth, not compute\n",
    "* Scalability: GPU advantage increases with array size\n",
    "\n",
    "## 7. Sorting Algorithms\n",
    "### Why GPU Sorting Matters\n",
    "Sorting is fundamental to many algorithms:\n",
    "* Data preprocessing: Organize data before analysis\n",
    "* Search optimization: Binary search requires sorted data\n",
    "* Grouping operations: Group similar items together\n",
    "* Statistical analysis: Find medians, percentiles, ranges\n",
    "\n",
    "**GPU sorting advantages:**\n",
    "* Parallel comparison: Compare many pairs simultaneously\n",
    "* High throughput: Process millions of elements per second\n",
    "* Stable sorting: Preserve order of equal elements\n",
    "\n",
    "### Basic Radix Sort\n",
    "Let's start with basic array sorting using radix sort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b308a11d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def basic_radix_sort_example():\n",
    "    \"\"\"Learn GPU sorting with radix sort\"\"\"\n",
    "    \n",
    "    print(\"=== Basic Radix Sort Example ===\")\n",
    "    \n",
    "    # Create unsorted data\n",
    "    input_data = [64, 34, 25, 12, 22, 11, 90, 5, 77, 30]\n",
    "    print(f\"Input data: {input_data}\")\n",
    "    \n",
    "    # Setup GPU arrays\n",
    "    d_input = cp.array(input_data, dtype=np.int32)\n",
    "    d_output = cp.empty_like(d_input)\n",
    "    \n",
    "    # Perform radix sort (ascending order)\n",
    "    parallel.radix_sort(\n",
    "        d_input,                           # Input keys\n",
    "        d_output,                          # Output keys\n",
    "        None,                              # Input values (none)\n",
    "        None,                              # Output values (none)\n",
    "        parallel.SortOrder.ASCENDING,     # Sort order\n",
    "        len(d_input)                       # Number of elements\n",
    "    )\n",
    "    \n",
    "    # Get results\n",
    "    gpu_result = d_output.get()\n",
    "    cpu_result = sorted(input_data)\n",
    "    \n",
    "    print(f\"GPU sorted: {gpu_result}\")\n",
    "    print(f\"CPU sorted: {cpu_result}\")\n",
    "    print(f\"Results match: {np.array_equal(gpu_result, cpu_result)}\")\n",
    "    \n",
    "    # Show sorting verification\n",
    "    is_sorted = all(gpu_result[i] <= gpu_result[i+1] for i in range(len(gpu_result)-1))\n",
    "    print(f\"Array is properly sorted: {is_sorted}\")\n",
    "\n",
    "basic_radix_sort_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37cb0e7",
   "metadata": {},
   "source": [
    "**Understanding radix sort:**\n",
    "* Radix sort: Sorts by processing digits/bits from least to most significant\n",
    "* Non-comparative: Doesn't compare elements directly\n",
    "* Stable: Equal elements maintain their relative order\n",
    "* Fast: O(k*n) complexity where k is number of digits\n",
    "\n",
    "#### Descending Sort\n",
    "Sorting in reverse order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8ff8d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def descending_sort_example():\n",
    "    \"\"\"Sort in descending (largest to smallest) order\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Descending Sort Example ===\")\n",
    "    \n",
    "    # Test data with duplicates\n",
    "    input_data = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]\n",
    "    print(f\"Input data: {input_data}\")\n",
    "    \n",
    "    # Setup\n",
    "    d_input = cp.array(input_data, dtype=np.int32)\n",
    "    d_output = cp.empty_like(d_input)\n",
    "    \n",
    "    # Sort in descending order\n",
    "    parallel.radix_sort(\n",
    "        d_input,\n",
    "        d_output,\n",
    "        None,\n",
    "        None,\n",
    "        parallel.SortOrder.DESCENDING,  # Reverse order\n",
    "        len(d_input)\n",
    "    )\n",
    "    \n",
    "    # Results\n",
    "    gpu_result = d_output.get()\n",
    "    cpu_result = sorted(input_data, reverse=True)\n",
    "    \n",
    "    print(f\"GPU descending: {gpu_result}\")\n",
    "    print(f\"CPU descending: {cpu_result}\")\n",
    "    print(f\"Results match: {np.array_equal(gpu_result, cpu_result)}\")\n",
    "    \n",
    "    # Verify descending order\n",
    "    is_descending = all(gpu_result[i] >= gpu_result[i+1] for i in range(len(gpu_result)-1))\n",
    "    print(f\"Array is properly sorted (descending): {is_descending}\")\n",
    "\n",
    "descending_sort_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f0d60",
   "metadata": {},
   "source": [
    "#### Key-Value Sorting\n",
    "Often you want to sort one array (keys) while rearranging another array (values) to match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb0c248",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def key_value_sort_example():\n",
    "    \"\"\"Sort keys while keeping values aligned\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Key-Value Sort Example ===\")\n",
    "    \n",
    "    # Example: Sort students by grade, keep names aligned\n",
    "    grades = [85, 92, 78, 96, 88, 71, 94]\n",
    "    names = [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\", \"Frank\", \"Grace\"]\n",
    "    \n",
    "    print(\"Unsorted data:\")\n",
    "    for grade, name in zip(grades, names):\n",
    "        print(f\"  {name}: {grade}\")\n",
    "    \n",
    "    # Setup GPU arrays\n",
    "    d_keys = cp.array(grades, dtype=np.int32)\n",
    "    d_values = cp.arange(len(names), dtype=np.int32)  # Use indices instead of strings\n",
    "    \n",
    "    d_keys_out = cp.empty_like(d_keys)\n",
    "    d_values_out = cp.empty_like(d_values)\n",
    "    \n",
    "    # Sort by grades (keys) while rearranging indices (values)\n",
    "    parallel.radix_sort(\n",
    "        d_keys,                           # Input grades\n",
    "        d_keys_out,                       # Output grades\n",
    "        d_values,                         # Input indices\n",
    "        d_values_out,                     # Output indices\n",
    "        parallel.SortOrder.DESCENDING,   # Highest grade first\n",
    "        len(d_keys)\n",
    "    )\n",
    "    \n",
    "    # Get results\n",
    "    sorted_grades = d_keys_out.get()\n",
    "    sorted_indices = d_values_out.get()\n",
    "    \n",
    "    print(\"\\nSorted data (by grade, highest first):\")\n",
    "    for grade, idx in zip(sorted_grades, sorted_indices):\n",
    "        print(f\"  {names[idx]}: {grade}\")\n",
    "    \n",
    "    # Verify sorting\n",
    "    cpu_pairs = list(zip(grades, range(len(names))))\n",
    "    cpu_sorted = sorted(cpu_pairs, key=lambda x: x[0], reverse=True)\n",
    "    cpu_grades = [pair[0] for pair in cpu_sorted]\n",
    "    cpu_indices = [pair[1] for pair in cpu_sorted]\n",
    "    \n",
    "    print(f\"\\nVerification:\")\n",
    "    print(f\"Grades match: {np.array_equal(sorted_grades, cpu_grades)}\")\n",
    "    print(f\"Indices match: {np.array_equal(sorted_indices, cpu_indices)}\")\n",
    "\n",
    "key_value_sort_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94778e7",
   "metadata": {},
   "source": [
    "**Key-value sorting applications:**\n",
    "* Database operations: Sort records by one field\n",
    "* Index arrays: Create sorted indices for data access\n",
    "* Paired data: Keep related arrays synchronized\n",
    "\n",
    "#### Merge Sort for Custom Comparisons\n",
    "For more complex sorting criteria, use merge sort with custom comparison functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe5a09",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def merge_sort_example():\n",
    "    \"\"\"Use merge sort with custom comparison function\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Merge Sort with Custom Comparison ===\")\n",
    "    \n",
    "    # Example: Sort by absolute value\n",
    "    input_data = [-15, 3, -7, 22, -1, 8, -12, 5]\n",
    "    print(f\"Input data: {input_data}\")\n",
    "    \n",
    "    def compare_absolute(a, b):\n",
    "        \"\"\"Compare by absolute value\"\"\"\n",
    "        return np.uint8(abs(a) < abs(b))\n",
    "    \n",
    "    # Setup\n",
    "    d_input = cp.array(input_data, dtype=np.int32)\n",
    "    d_output = cp.empty_like(d_input)\n",
    "    \n",
    "    # Merge sort with custom comparison\n",
    "    parallel.merge_sort(\n",
    "        d_input,         # Input keys\n",
    "        None,            # Input values (none)\n",
    "        d_output,        # Output keys\n",
    "        None,            # Output values (none)\n",
    "        compare_absolute, # Custom comparison function\n",
    "        len(d_input)     # Number of elements\n",
    "    )\n",
    "    \n",
    "    # Results\n",
    "    gpu_result = d_output.get()\n",
    "    cpu_result = sorted(input_data, key=abs)\n",
    "    \n",
    "    print(f\"GPU sort (by absolute value): {gpu_result}\")\n",
    "    print(f\"CPU sort (by absolute value): {cpu_result}\")\n",
    "    print(f\"Results match: {np.array_equal(gpu_result, cpu_result)}\")\n",
    "    \n",
    "    # Show absolute values for clarity\n",
    "    print(f\"\\nAbsolute values: {[abs(x) for x in gpu_result]}\")\n",
    "    \n",
    "    # Verify proper ordering by absolute value\n",
    "    abs_values = [abs(x) for x in gpu_result]\n",
    "    is_sorted_by_abs = all(abs_values[i] <= abs_values[i+1] for i in range(len(abs_values)-1))\n",
    "    print(f\"Sorted by absolute value: {is_sorted_by_abs}\")\n",
    "\n",
    "merge_sort_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c320ceca",
   "metadata": {},
   "source": [
    "### Sorting Performance Comparison\n",
    "Let's compare different sorting approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3881ff1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def sorting_performance_comparison():\n",
    "    \"\"\"Compare GPU sorting vs CPU sorting performance\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Sorting Performance Comparison ===\")\n",
    "    \n",
    "    # Test different array sizes\n",
    "    sizes = [1000, 10000, 100000, 1000000]\n",
    "    \n",
    "    for size in sizes:\n",
    "        print(f\"\\nTesting with {size:,} elements:\")\n",
    "        \n",
    "        # Create random data\n",
    "        np.random.seed(42)\n",
    "        data = np.random.randint(0, size, size, dtype=np.int32)\n",
    "        \n",
    "        # CPU sorting (NumPy)\n",
    "        start_time = time.time()\n",
    "        cpu_result = np.sort(data)\n",
    "        cpu_time = time.time() - start_time\n",
    "        \n",
    "        # GPU radix sort\n",
    "        d_input = cp.array(data)\n",
    "        d_output = cp.empty_like(d_input)\n",
    "        \n",
    "        # Warm up GPU\n",
    "        parallel.radix_sort(d_input, d_output, None, None, parallel.SortOrder.ASCENDING, len(d_input))\n",
    "        \n",
    "        # Time GPU sort\n",
    "        start_time = time.time()\n",
    "        parallel.radix_sort(d_input, d_output, None, None, parallel.SortOrder.ASCENDING, len(d_input))\n",
    "        gpu_result = d_output.get()\n",
    "        gpu_time = time.time() - start_time\n",
    "        \n",
    "        # Compare\n",
    "        speedup = cpu_time / gpu_time if gpu_time > 0 else float('inf')\n",
    "        \n",
    "        print(f\"  CPU time: {cpu_time*1000:.2f} ms\")\n",
    "        print(f\"  GPU time: {gpu_time*1000:.2f} ms\")\n",
    "        print(f\"  Speedup: {speedup:.1f}x\")\n",
    "        print(f\"  Results match: {np.array_equal(cpu_result, gpu_result)}\")\n",
    "        \n",
    "        # Check sorting correctness\n",
    "        is_cpu_sorted = np.all(cpu_result[:-1] <= cpu_result[1:])\n",
    "        is_gpu_sorted = np.all(gpu_result[:-1] <= gpu_result[1:])\n",
    "        print(f\"  CPU sorted correctly: {is_cpu_sorted}\")\n",
    "        print(f\"  GPU sorted correctly: {is_gpu_sorted}\")\n",
    "\n",
    "sorting_performance_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db4753",
   "metadata": {},
   "source": [
    "**Sorting performance insights:**\n",
    "* GPU advantage: Most apparent with large arrays (100k+ elements)\n",
    "* Memory bandwidth: GPU sorting is often memory-bound\n",
    "* Algorithm choice: Radix sort excels for integers, merge sort for custom comparisons\n",
    "* Stability: Both algorithms preserve order of equal elements\n",
    "\n",
    "### Practical Sorting Applications\n",
    "Here's a real world example, organizing data for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb83c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def practical_sorting_application():\n",
    "    \"\"\"Real-world example: Organize sensor data by timestamp\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Practical Application: Sensor Data Organization ===\")\n",
    "    \n",
    "    # Simulate sensor data (timestamp, temperature, humidity, sensor_id)\n",
    "    np.random.seed(42)\n",
    "    num_readings = 20\n",
    "    \n",
    "    # Random timestamps (simulate out-of-order arrival)\n",
    "    timestamps = np.random.randint(1000, 2000, num_readings)\n",
    "    temperatures = np.random.uniform(18.0, 35.0, num_readings)\n",
    "    humidity = np.random.uniform(30.0, 90.0, num_readings)\n",
    "    sensor_ids = np.random.randint(1, 6, num_readings)\n",
    "    \n",
    "    print(\"Unsorted sensor data (first 10 readings):\")\n",
    "    print(\"Timestamp | Temp | Humidity | Sensor\")\n",
    "    print(\"-\" * 40)\n",
    "    for i in range(min(10, num_readings)):\n",
    "        print(f\"{timestamps[i]:>9} | {temperatures[i]:4.1f} | {humidity[i]:6.1f}% | {sensor_ids[i]:>6}\")\n",
    "    \n",
    "    # Sort by timestamp using key-value sort\n",
    "    d_keys = cp.array(timestamps, dtype=np.int32)\n",
    "    d_values = cp.arange(num_readings, dtype=np.int32)  # Original indices\n",
    "    \n",
    "    d_keys_out = cp.empty_like(d_keys)\n",
    "    d_values_out = cp.empty_like(d_values)\n",
    "    \n",
    "    # Sort timestamps, keep track of original indices\n",
    "    parallel.radix_sort(\n",
    "        d_keys, d_keys_out,\n",
    "        d_values, d_values_out,\n",
    "        parallel.SortOrder.ASCENDING,\n",
    "        num_readings\n",
    "    )\n",
    "    \n",
    "    # Get sorted results\n",
    "    sorted_timestamps = d_keys_out.get()\n",
    "    sorted_indices = d_values_out.get()\n",
    "    \n",
    "    print(f\"\\nSorted sensor data (by timestamp):\")\n",
    "    print(\"Timestamp | Temp | Humidity | Sensor\")\n",
    "    print(\"-\" * 40)\n",
    "    for i in range(min(10, num_readings)):\n",
    "        orig_idx = sorted_indices[i]\n",
    "        print(f\"{sorted_timestamps[i]:>9} | {temperatures[orig_idx]:4.1f} | {humidity[orig_idx]:6.1f}% | {sensor_ids[orig_idx]:>6}\")\n",
    "    \n",
    "    # Verify chronological order\n",
    "    is_chronological = all(sorted_timestamps[i] <= sorted_timestamps[i+1] \n",
    "                          for i in range(len(sorted_timestamps)-1))\n",
    "    print(f\"\\nData is now in chronological order: {is_chronological}\")\n",
    "    \n",
    "    # Show benefits\n",
    "    print(f\"\\nBenefits of sorted data:\")\n",
    "    print(f\"  - Time-series analysis becomes efficient\")\n",
    "    print(f\"  - Binary search for specific timestamps\")\n",
    "    print(f\"  - Easy to find data ranges\")\n",
    "    print(f\"  - Temporal patterns become visible\")\n",
    "\n",
    "practical_sorting_application()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0bff1c",
   "metadata": {},
   "source": [
    "This example shows how GPU sorting enables efficient data organization for real-world applications like sensor monitoring, financial data analysis, and scientific computing.\n",
    "\n",
    "## 8. Transform Operations\n",
    "### What Are Transform Operations?\n",
    "Transform operations apply a function to each element of an array (or iterator) to create a new array. Think of it as a parallel \"map\" operation from functional programming.\n",
    "\n",
    "**Key characteristics:**\n",
    "* Element-wise: Each input element produces exactly one output element\n",
    "* Independent: Each transformation is independent of others\n",
    "* Parallel: All transformations happen simultaneously on GPU\n",
    "* Memory efficient: Can be combined with other operations\n",
    "\n",
    "**Common use cases:**\n",
    "* Mathematical operations (square, sqrt, trigonometric functions)\n",
    "* Unit conversions (Celsius to Fahrenheit, meters to feet)\n",
    "* Data normalization and scaling\n",
    "* Feature engineering in machine learning\n",
    "\n",
    "### Basic Unary Transform\n",
    "Let's start with simple element-wise transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1248f23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def basic_unary_transform_example():\n",
    "    \"\"\"Learn basic transform operations\"\"\"\n",
    "    \n",
    "    print(\"=== Basic Unary Transform Example ===\")\n",
    "    \n",
    "    # Example: Convert temperatures from Celsius to Fahrenheit\n",
    "    celsius_temps = [0, 10, 20, 25, 30, 37.5, 100]\n",
    "    print(f\"Temperatures in Celsius: {celsius_temps}\")\n",
    "    \n",
    "    def celsius_to_fahrenheit(c):\n",
    "        \"\"\"Convert Celsius to Fahrenheit: F = C * 9/5 + 32\"\"\"\n",
    "        return c * 9.0 / 5.0 + 32.0\n",
    "    \n",
    "    # Setup GPU arrays\n",
    "    d_input = cp.array(celsius_temps, dtype=np.float32)\n",
    "    d_output = cp.empty_like(d_input)\n",
    "    \n",
    "    # Perform transform\n",
    "    parallel.unary_transform(\n",
    "        d_input,              # Input array\n",
    "        d_output,             # Output array\n",
    "        celsius_to_fahrenheit, # Transform function\n",
    "        len(d_input)          # Number of elements\n",
    "    )\n",
    "    \n",
    "    # Get results\n",
    "    gpu_result = d_output.get()\n",
    "    cpu_result = [celsius_to_fahrenheit(c) for c in celsius_temps]\n",
    "    \n",
    "    print(f\"GPU Fahrenheit temps: {gpu_result}\")\n",
    "    print(f\"CPU Fahrenheit temps: {cpu_result}\")\n",
    "    print(f\"Results match: {np.allclose(gpu_result, cpu_result)}\")\n",
    "    \n",
    "    # Show conversion table\n",
    "    print(f\"\\nTemperature Conversion Table:\")\n",
    "    print(f\"{'Celsius':<8} | {'Fahrenheit':<10}\")\n",
    "    print(\"-\" * 20)\n",
    "    for c, f in zip(celsius_temps, gpu_result):\n",
    "        print(f\"{c:<8.1f} | {f:<10.1f}\")\n",
    "\n",
    "basic_unary_transform_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e585509e",
   "metadata": {},
   "source": [
    "Understanding unary transform:\n",
    "* Input: Array of Celsius temperatures\n",
    "* Function: Conversion formula applied to each element\n",
    "* Output: Array of Fahrenheit temperatures (same size)\n",
    "* Parallel: All conversions happen simultaneously\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c150fed",
   "metadata": {},
   "source": [
    "### Binary Transform Operations\n",
    "\n",
    "Binary transforms combine two input arrays element-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eaeb0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def binary_transform_example():\n",
    "    \"\"\"Combine two arrays with binary transform\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Binary Transform Example ===\")\n",
    "    \n",
    "    # Example: Calculate area of rectangles given width and height\n",
    "    widths = [2.5, 4.0, 1.5, 6.2, 3.8]\n",
    "    heights = [3.0, 2.5, 4.5, 1.8, 5.2]\n",
    "    \n",
    "    print(f\"Rectangle widths: {widths}\")\n",
    "    print(f\"Rectangle heights: {heights}\")\n",
    "    \n",
    "    def calculate_area(width, height):\n",
    "        \"\"\"Calculate rectangular area\"\"\"\n",
    "        return width * height\n",
    "    \n",
    "    def calculate_perimeter(width, height):\n",
    "        \"\"\"Calculate rectangular perimeter\"\"\"\n",
    "        return 2 * (width + height)\n",
    "    \n",
    "    # Setup GPU arrays\n",
    "    d_widths = cp.array(widths, dtype=np.float32)\n",
    "    d_heights = cp.array(heights, dtype=np.float32)\n",
    "    d_areas = cp.empty_like(d_widths)\n",
    "    d_perimeters = cp.empty_like(d_widths)\n",
    "    \n",
    "    # Calculate areas\n",
    "    parallel.binary_transform(\n",
    "        d_widths,      # First input array\n",
    "        d_heights,     # Second input array\n",
    "        d_areas,       # Output array\n",
    "        calculate_area, # Binary function\n",
    "        len(d_widths)  # Number of elements\n",
    "    )\n",
    "    \n",
    "    # Calculate perimeters\n",
    "    parallel.binary_transform(\n",
    "        d_widths, d_heights, d_perimeters, calculate_perimeter, len(d_widths)\n",
    "    )\n",
    "    \n",
    "    # Get results\n",
    "    gpu_areas = d_areas.get()\n",
    "    gpu_perimeters = d_perimeters.get()\n",
    "    \n",
    "    # CPU verification\n",
    "    cpu_areas = [w * h for w, h in zip(widths, heights)]\n",
    "    cpu_perimeters = [2 * (w + h) for w, h in zip(widths, heights)]\n",
    "    \n",
    "    print(f\"\\nRectangle Properties:\")\n",
    "    print(f\"{'Width':<6} | {'Height':<6} | {'Area':<8} | {'Perimeter':<10}\")\n",
    "    print(\"-\" * 35)\n",
    "    for w, h, a, p in zip(widths, heights, gpu_areas, gpu_perimeters):\n",
    "        print(f\"{w:<6.1f} | {h:<6.1f} | {a:<8.2f} | {p:<10.2f}\")\n",
    "    \n",
    "    print(f\"\\nVerification:\")\n",
    "    print(f\"Areas match: {np.allclose(gpu_areas, cpu_areas)}\")\n",
    "    print(f\"Perimeters match: {np.allclose(gpu_perimeters, cpu_perimeters)}\")\n",
    "\n",
    "binary_transform_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f37ec",
   "metadata": {},
   "source": [
    "### Transform with Iterators\n",
    "Combining transforms with iterators for memory-efficient processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770ac3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def transform_with_iterators_example():\n",
    "    \"\"\"Use transforms with iterators for memory efficiency\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Transform with Iterators Example ===\")\n",
    "    \n",
    "    # Problem: Calculate sum of squares from 1 to 1000 without storing arrays\n",
    "    start_num = 1\n",
    "    count = 1000\n",
    "    \n",
    "    print(f\"Calculating sum of squares from {start_num} to {start_num + count - 1}\")\n",
    "    \n",
    "    def square_function(x):\n",
    "        \"\"\"Square a number\"\"\"\n",
    "        return x * x\n",
    "    \n",
    "    def add_op(a, b):\n",
    "        \"\"\"Addition for reduction\"\"\"\n",
    "        return a + b\n",
    "    \n",
    "    # Method 1: Using iterator composition (memory efficient)\n",
    "    print(f\"\\nMethod 1: Iterator Composition\")\n",
    "    \n",
    "    # Create counting iterator for numbers 1, 2, 3, ..., 1000\n",
    "    counting_it = parallel.CountingIterator(np.int64(start_num))\n",
    "    \n",
    "    # Transform each number by squaring it\n",
    "    squares_it = parallel.TransformIterator(counting_it, square_function)\n",
    "    \n",
    "    # Sum all the squares\n",
    "    d_output = cp.empty(1, dtype=np.int64)\n",
    "    h_init = np.array([0], dtype=np.int64)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    parallel.reduce_into(squares_it, d_output, add_op, count, h_init)\n",
    "    iterator_time = time.time() - start_time\n",
    "    \n",
    "    iterator_result = d_output.get()[0]\n",
    "    \n",
    "    # Method 2: Using arrays (memory intensive)\n",
    "    print(f\"Method 2: Array-based\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    d_numbers = cp.arange(start_num, start_num + count, dtype=np.int64)\n",
    "    d_squares = cp.empty_like(d_numbers)\n",
    "    \n",
    "    parallel.unary_transform(d_numbers, d_squares, square_function, count)\n",
    "    \n",
    "    d_sum = cp.empty(1, dtype=np.int64)\n",
    "    parallel.reduce_into(d_squares, d_sum, add_op, count, h_init)\n",
    "    array_result = d_sum.get()[0]\n",
    "    array_time = time.time() - start_time\n",
    "    \n",
    "    # CPU verification using formula: sum of squares = n(n+1)(2n+1)/6\n",
    "    n = count\n",
    "    formula_result = n * (n + 1) * (2 * n + 1) // 6\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"Iterator method: {iterator_result} ({iterator_time*1000:.2f} ms)\")\n",
    "    print(f\"Array method: {array_result} ({array_time*1000:.2f} ms)\")\n",
    "    print(f\"Mathematical formula: {formula_result}\")\n",
    "    \n",
    "    print(f\"\\nVerification:\")\n",
    "    print(f\"Iterator correct: {iterator_result == formula_result}\")\n",
    "    print(f\"Array correct: {array_result == formula_result}\")\n",
    "    print(f\"Methods match: {iterator_result == array_result}\")\n",
    "    \n",
    "    # Memory usage comparison\n",
    "    iterator_memory = d_output.nbytes  # Just the result\n",
    "    array_memory = d_numbers.nbytes + d_squares.nbytes + d_sum.nbytes\n",
    "    \n",
    "    print(f\"\\nMemory Usage:\")\n",
    "    print(f\"Iterator method: {iterator_memory} bytes\")\n",
    "    print(f\"Array method: {array_memory:,} bytes\")\n",
    "    print(f\"Memory savings: {array_memory // iterator_memory}x\")\n",
    "\n",
    "transform_with_iterators_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baee59c",
   "metadata": {},
   "source": [
    "### Data Normalization Example\n",
    "A practical machine learning preprocessing example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15babd83",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def data_normalization_example():\n",
    "    \"\"\"Normalize data using transforms (common ML preprocessing)\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Data Normalization Example ===\")\n",
    "    \n",
    "    # Simulate feature data (e.g., house prices, areas, ages)\n",
    "    np.random.seed(42)\n",
    "    house_prices = np.random.normal(300000, 100000, 100).astype(np.float32)\n",
    "    house_areas = np.random.normal(2000, 500, 100).astype(np.float32)\n",
    "    house_ages = np.random.uniform(0, 50, 100).astype(np.float32)\n",
    "    \n",
    "    print(f\"Raw data statistics:\")\n",
    "    print(f\"Prices: mean={np.mean(house_prices):.0f}, std={np.std(house_prices):.0f}\")\n",
    "    print(f\"Areas: mean={np.mean(house_areas):.0f}, std={np.std(house_areas):.0f}\")\n",
    "    print(f\"Ages: mean={np.mean(house_ages):.1f}, std={np.std(house_ages):.1f}\")\n",
    "    \n",
    "    # Z-score normalization: (x - mean) / std\n",
    "    def normalize_z_score(data, mean_val, std_val):\n",
    "        \"\"\"Create normalization function with captured mean and std\"\"\"\n",
    "        def normalize_func(x):\n",
    "            return (x - mean_val) / std_val\n",
    "        return normalize_func\n",
    "    \n",
    "    # Calculate statistics\n",
    "    price_mean, price_std = np.mean(house_prices), np.std(house_prices)\n",
    "    area_mean, area_std = np.mean(house_areas), np.std(house_areas)\n",
    "    age_mean, age_std = np.mean(house_ages), np.std(house_ages)\n",
    "    \n",
    "    # Create normalization functions\n",
    "    price_normalizer = normalize_z_score(house_prices, price_mean, price_std)\n",
    "    area_normalizer = normalize_z_score(house_areas, area_mean, area_std)\n",
    "    age_normalizer = normalize_z_score(house_ages, age_mean, age_std)\n",
    "    \n",
    "    # Setup GPU arrays\n",
    "    d_prices = cp.array(house_prices)\n",
    "    d_areas = cp.array(house_areas)\n",
    "    d_ages = cp.array(house_ages)\n",
    "    \n",
    "    d_norm_prices = cp.empty_like(d_prices)\n",
    "    d_norm_areas = cp.empty_like(d_areas)\n",
    "    d_norm_ages = cp.empty_like(d_ages)\n",
    "    \n",
    "    # Normalize on GPU\n",
    "    parallel.unary_transform(d_prices, d_norm_prices, price_normalizer, len(house_prices))\n",
    "    parallel.unary_transform(d_areas, d_norm_areas, area_normalizer, len(house_areas))\n",
    "    parallel.unary_transform(d_ages, d_norm_ages, age_normalizer, len(house_ages))\n",
    "    \n",
    "    # Get normalized results\n",
    "    norm_prices = d_norm_prices.get()\n",
    "    norm_areas = d_norm_areas.get()\n",
    "    norm_ages = d_norm_ages.get()\n",
    "    \n",
    "    print(f\"\\nNormalized data statistics:\")\n",
    "    print(f\"Prices: mean={np.mean(norm_prices):.6f}, std={np.std(norm_prices):.6f}\")\n",
    "    print(f\"Areas: mean={np.mean(norm_areas):.6f}, std={np.std(norm_areas):.6f}\")\n",
    "    print(f\"Ages: mean={np.mean(norm_ages):.6f}, std={np.std(norm_ages):.6f}\")\n",
    "    \n",
    "    # Show sample of normalized data\n",
    "    print(f\"\\nSample of normalized data (first 5 houses):\")\n",
    "    print(f\"{'Price':<8} | {'Area':<8} | {'Age':<8}\")\n",
    "    print(\"-\" * 28)\n",
    "    for i in range(5):\n",
    "        print(f\"{norm_prices[i]:<8.3f} | {norm_areas[i]:<8.3f} | {norm_ages[i]:<8.3f}\")\n",
    "    \n",
    "    # Verify normalization properties\n",
    "    all_close_to_zero = (abs(np.mean(norm_prices)) < 1e-6 and \n",
    "                        abs(np.mean(norm_areas)) < 1e-6 and \n",
    "                        abs(np.mean(norm_ages)) < 1e-6)\n",
    "    \n",
    "    all_close_to_one = (abs(np.std(norm_prices) - 1.0) < 1e-6 and \n",
    "                       abs(np.std(norm_areas) - 1.0) < 1e-6 and \n",
    "                       abs(np.std(norm_ages) - 1.0) < 1e-6)\n",
    "    \n",
    "    print(f\"\\nNormalization verification:\")\n",
    "    print(f\"All means ≈ 0: {all_close_to_zero}\")\n",
    "    print(f\"All std devs ≈ 1: {all_close_to_one}\")\n",
    "    print(f\"Normalization successful: {all_close_to_zero and all_close_to_one}\")\n",
    "\n",
    "data_normalization_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467b87d",
   "metadata": {},
   "source": [
    "## 9. Exercises\n",
    "\n",
    "Now it's time to practice. Here are some hands-on exercises to reinforce your learning:\n",
    "\n",
    "### Exercise 1: Compute the minimum value of a sequence\n",
    "Use `reduce_into()` to compute the minimum value of a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad355e-a71a-4d95-9314-81fe4a007c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input and output arrays.\n",
    "d_input = cp.array([-2, 3, 5, 1, 7, -6, 8, -4], dtype=np.int32)\n",
    "d_output = cp.empty(1, dtype=np.int32)\n",
    "\n",
    "# begin TODO\n",
    "\n",
    "\n",
    "# end TODO\n",
    "\n",
    "expected_output = -6\n",
    "assert (d_output == expected_output).all()\n",
    "result = d_output[0]\n",
    "print(f\"Min reduction result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c918a54-abaf-40f5-892f-67f3dc2afb40",
   "metadata": {},
   "source": [
    "### Exercise 2: Sort by the last digit\n",
    "Use `merge_sort()` with a custom comparator function to sort elements by the last digit. For example, \n",
    "[9, 23, 1001, 802] -> [1001, 802, 23, 9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a919b-0e6e-462c-861b-ea7cd29743e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input and output arrays.\n",
    "d_in_keys = cp.asarray([29, 9, 136, 1001, 72, 24, 32, 1], dtype=\"int32\")\n",
    "\n",
    "# define the custom comparator.\n",
    "def comparison_op(lhs, rhs):\n",
    "    # begin TODO\n",
    "\n",
    "    # end TODO\n",
    "\n",
    "# Perform the merge sort.\n",
    "parallel.merge_sort(\n",
    "    # begin TODO\n",
    "\n",
    "    # end TODO\n",
    ")\n",
    "\n",
    "print(f\"Result: {d_in_keys}\")\n",
    "expected = np.asarray([1001, 1, 72, 32, 24, 136, 29, 9], dtype=np.int32)\n",
    "assert (d_in_keys.get() == expected).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a22e1a",
   "metadata": {},
   "source": [
    "## Resources\n",
    "API Reference: https://nvidia.github.io/cccl/python/parallel_api.html#module-cuda.cccl.parallel.experimental.algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
