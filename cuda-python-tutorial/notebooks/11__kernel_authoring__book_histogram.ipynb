{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1a8560a-c91b-48db-af1c-18fcd4892448",
      "metadata": {
        "id": "f1a8560a-c91b-48db-af1c-18fcd4892448"
      },
      "source": [
        "# Exercise - Kernel Authoring - Book Histogram\n",
        "\n",
        "Let's learn to use some advanced CUDA features like shared memory, atomics, and [cuda.cooperative](https://nvidia.github.io/cccl/python/cooperative.html) to write an efficient histogram kernel to determine the most frequent characters in a collection of books.\n",
        "\n",
        "First, let's download our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce42d5e5-db1e-46da-a64a-831d0f3d59ff",
      "metadata": {
        "id": "ce42d5e5-db1e-46da-a64a-831d0f3d59ff"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.exists(\"/ach-installed\"): # If running in Google Colab:\n",
        "  !curl -s -L -O https://developer.nvidia.com/downloads/assets/tools/secure/nsight-systems/2025_3/NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb\n",
        "  !sudo dpkg -i NsightSystems-linux-cli-public-2025.3.1.90-3582212.deb > /dev/null\n",
        "  !pip uninstall \"cuda-python\" --yes > /dev/null\n",
        "  !pip install \"numba-cuda\" \"cuda-cccl[test-cu12]\" \"nsightful[notebook] @ git+https://github.com/brycelelbach/nsightful.git\" > /dev/null 2>&1\n",
        "  open(\"/ach-installed\", \"a\").close()\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nsightful\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e1ae9dc-39f1-4c93-b923-85a96b45a057",
      "metadata": {
        "id": "6e1ae9dc-39f1-4c93-b923-85a96b45a057"
      },
      "outputs": [],
      "source": [
        "urllib.request.urlretrieve(\n",
        "  \"https://drive.usercontent.google.com/download?id=1MW1lPgkTq3YG9ikuq6u3d9sfpt-wKQZ0&export=download\",\n",
        "  \"books__15m.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9109d3c0-e276-44cc-9f36-f8c79eb48b31",
      "metadata": {
        "id": "9109d3c0-e276-44cc-9f36-f8c79eb48b31"
      },
      "source": [
        "A histogram kernel counts the number of times a value occurs in a dataset. To implement this, we create an array that is large enough to store all possible values (in the case of counting 1-byte ASCII characters, 256 elements). Then for the value of each element in the dataset, we increment its location in the array.\n",
        "\n",
        "Let's try a simple way to implement this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c12795-b14a-4447-9dcf-9748616cc453",
      "metadata": {
        "id": "61c12795-b14a-4447-9dcf-9748616cc453"
      },
      "outputs": [],
      "source": [
        "%%writefile histogram_global.py\n",
        "\n",
        "from numba import cuda\n",
        "import cupy as cp\n",
        "import cupyx as cpx\n",
        "import sys\n",
        "import os\n",
        "\n",
        "bins = 256\n",
        "\n",
        "values = cp.fromfile(\"books__15m.txt\", dtype=cp.uint8)\n",
        "histogram = cp.zeros((bins), dtype=cp.int32)\n",
        "\n",
        "threads_per_block = 512 if len(sys.argv) < 3 else int(sys.argv[2])\n",
        "items_per_thread = 8 if len(sys.argv) < 4 else int(sys.argv[3])\n",
        "items_per_block = threads_per_block * items_per_thread\n",
        "blocks = int(len(values) / (threads_per_block * items_per_thread))\n",
        "assert values.size % items_per_block == 0\n",
        "\n",
        "@cuda.jit\n",
        "def histogram_global(values, histogram):\n",
        "  for i in range(items_per_thread):\n",
        "    value = values[cuda.grid(1) * items_per_thread + i]\n",
        "    old_count = histogram[value]\n",
        "    new_count = old_count + 1\n",
        "    histogram[value] = new_count\n",
        "\n",
        "def launch(output):\n",
        "  histogram[:] = 0 # Reset histogram to 0 each trial.\n",
        "  histogram_global[blocks, threads_per_block](values, histogram)\n",
        "\n",
        "  if (output):\n",
        "    cp.savetxt(sys.stdout, histogram, delimiter=\",\", fmt=\"%i\")\n",
        "\n",
        "if len(sys.argv) >= 2 and sys.argv[1] == \"output\":\n",
        "  launch(output=True)\n",
        "elif os.getenv(\"NV_COMPUTE_PROFILER_PERFWORKS_DIR\"): # Running under `ncu`.\n",
        "  launch(output=False) # `ncu` slows things down; so just launch once when running under it.\n",
        "else:\n",
        "  launch(output=False)\n",
        "  D = cpx.profiler.benchmark(launch, (False), n_repeat=15, n_warmup=4).gpu_times[0]\n",
        "  print(f\"{D.mean():.3g} s ± {(D.std() / D.mean()):.2%} (mean ± relative stdev of {D.size} runs)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27e30efa-3a37-402f-9414-e444214d8ce6",
      "metadata": {
        "id": "27e30efa-3a37-402f-9414-e444214d8ce6"
      },
      "source": [
        "Now let's make sure it runs and check the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3f32240-ad7b-4717-98b3-82b0298a099a",
      "metadata": {
        "id": "b3f32240-ad7b-4717-98b3-82b0298a099a"
      },
      "outputs": [],
      "source": [
        "!python histogram_global.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "815cb072-b3a0-47aa-af6c-dd66c626a440",
      "metadata": {
        "id": "815cb072-b3a0-47aa-af6c-dd66c626a440"
      },
      "outputs": [],
      "source": [
        "histogram_output = !python histogram_global.py output\n",
        "histogram = np.loadtxt(histogram_output, delimiter=\",\")\n",
        "\n",
        "# Print most frequently occuring characters.\n",
        "pairs = sorted(((i,c) for i,c in enumerate(histogram) if c), key=lambda x: x[1], reverse=True)[:20]\n",
        "labels = [('SPACE' if i==32 else chr(i)) if 32<=i<=126 else f'0x{i:02X}' for i,_ in pairs]\n",
        "plt.barh(labels[::-1], [c for _,c in pairs][::-1]); plt.xlabel('count'); plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b14fa522-b41b-4538-8c34-ecc355e55116",
      "metadata": {
        "id": "b14fa522-b41b-4538-8c34-ecc355e55116"
      },
      "source": [
        "It looks like something is wrong - our counts are very low, and the most common characters don't make a lot of sense. Many of our increments seem to get lost!\n",
        "\n",
        "What's happening here is called a data race. Many different threads are trying to access the bins of the histogram at the same time.\n",
        "\n",
        "Imagine that two threads are trying to update the same bin.\n",
        "\n",
        "- Thread 0 reads the count of the bin, which is 0, and stores it in its local variable `old_count`.\n",
        "- Thread 0 adds 1 to its `old_count`, producing a `new_count` of 1.\n",
        "- Thread 1 reads the count of the bin, which is still 0, and stores it in its local variable `old_count`.\n",
        "- Thread 1 adds 1 to its `old_count`, producing a `new_count` of 1.\n",
        "- Thread 0 stores `new_count` to the bin, setting it to 1.\n",
        "- Thread 1 stores `new_count` to the bin, setting it to 1, and losing the increment from thread 0!\n",
        "\n",
        "To fix this, we need to use atomic operations. `cuda.atomic.add(array, index, value)` will perform `array[index] += value` as a single indivisible operation. This will ensure that no increments get lost.\n",
        "\n",
        "**TODO: Fix the code above by modifying it to use `cuda.atomic.add`.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08f4dded-26a7-4ef8-b981-e00c569ca4d0",
      "metadata": {
        "id": "08f4dded-26a7-4ef8-b981-e00c569ca4d0"
      },
      "source": [
        "Now let's profile our code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dbd226c-66f2-43df-868a-6b024b1de24c",
      "metadata": {
        "id": "8dbd226c-66f2-43df-868a-6b024b1de24c"
      },
      "outputs": [],
      "source": [
        "!ncu -f --kernel-name regex:histogram_global --set full -o histogram_global python histogram_global.py\n",
        "histogram_global_csv = !ncu --import histogram_global.ncu-rep --csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad12380e-253b-4410-ab34-9479411fdf81",
      "metadata": {
        "id": "ad12380e-253b-4410-ab34-9479411fdf81"
      },
      "outputs": [],
      "source": [
        "nsightful.display_ncu_csv_in_notebook(histogram_global_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f72831-780f-4cf5-8ff1-2092ecb193d9",
      "metadata": {
        "id": "e1f72831-780f-4cf5-8ff1-2092ecb193d9"
      },
      "source": [
        "Looking at the profile trace, it seems like our code is quite slow - look at the memory workload tab and see how low the throughput is!\n",
        "\n",
        "One improvement we should make is to separate loading from values from the histogram update and to perform striped loads. We'll use [cuda.cooperative](https://nvidia.github.io/cccl/python/cooperative.html)'s block load instead of writing this by hand.\n",
        "\n",
        "**TODO: Rewrite the code below to use `cuda.cooperative` to load from `values` into local memory.**\n",
        "- **Create a `coop.block.load(dtype, threads_per_block, items_per_thread, algorithm)` object outside of the kernel.**\n",
        "- **Make sure to link the algorithm object to the kernel by adding a `link` parameter to the decorator.**\n",
        "- **Create storage for the items we'll load with `cuda.local.array`.**\n",
        "\n",
        "**TODO: Look at the profile trace and code and think about how we could improve performance further.**\n",
        "\n",
        "**HINT:**\n",
        "- **What sorts of operations are we performing? Are they expensive? Can we make the code more efficient by reducing the number of expensive operations we perform?**\n",
        "- **You can allocate memory accessible by the entire block with `cuda.shared.array`.**\n",
        "- **You can synchronize all threads within a block with `cuda.syncthreads`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7c9865-646a-4bbd-9b41-61cadfc5484c",
      "metadata": {
        "id": "cf7c9865-646a-4bbd-9b41-61cadfc5484c"
      },
      "outputs": [],
      "source": [
        "%%writefile histogram_localized.py\n",
        "\n",
        "from numba import cuda\n",
        "import cupy as cp\n",
        "import cupyx as cpx\n",
        "import sys\n",
        "import os\n",
        "\n",
        "bins = 256\n",
        "\n",
        "values = cp.fromfile(\"books__15m.txt\", dtype=cp.uint8)\n",
        "histogram = cp.zeros((bins), dtype=cp.int32)\n",
        "\n",
        "threads_per_block = 512 if len(sys.argv) < 3 else int(sys.argv[2])\n",
        "items_per_thread = 8 if len(sys.argv) < 4 else int(sys.argv[3])\n",
        "items_per_block = threads_per_block * items_per_thread\n",
        "blocks = int(len(values) / (threads_per_block * items_per_thread))\n",
        "assert values.size % items_per_block == 0\n",
        "\n",
        "@cuda.jit\n",
        "def histogram_localized(values, histogram):\n",
        "  for i in range(items_per_thread):\n",
        "    value = values[cuda.grid(1) * items_per_thread + i]\n",
        "    old_count = histogram[value]\n",
        "    new_count = old_count + 1\n",
        "    histogram[value] = new_count\n",
        "\n",
        "def launch(check, output):\n",
        "  histogram[:] = 0 # Reset histogram to 0 each trial.\n",
        "  histogram_localized[blocks, threads_per_block](values, histogram)\n",
        "\n",
        "  if (check):\n",
        "    assert cp.sum(histogram) == len(values)\n",
        "\n",
        "  if (output):\n",
        "    cp.savetxt(sys.stdout, histogram, delimiter=\",\", fmt=\"%i\")\n",
        "\n",
        "if len(sys.argv) >= 2 and sys.argv[1] == \"output\":\n",
        "  launch(check=True, output=True)\n",
        "elif os.getenv(\"NV_COMPUTE_PROFILER_PERFWORKS_DIR\"): # Running under `ncu`.\n",
        "  launch(check=False, output=False) # `ncu` slows things down; so just launch once when running under it.\n",
        "else:\n",
        "  launch(check=True, output=False)\n",
        "  D = cpx.profiler.benchmark(launch, (False, False), n_repeat=15, n_warmup=4).gpu_times[0]\n",
        "  print(f\"{D.mean():.3g} s ± {(D.std() / D.mean()):.2%} (mean ± relative stdev of {D.size} runs)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd090ee6-a5d3-46f6-a58e-d34e077a99c0",
      "metadata": {
        "id": "fd090ee6-a5d3-46f6-a58e-d34e077a99c0"
      },
      "source": [
        "Now let's profile our code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b30e9b3-5a4c-4181-b642-b7def5e9f258",
      "metadata": {
        "id": "1b30e9b3-5a4c-4181-b642-b7def5e9f258"
      },
      "outputs": [],
      "source": [
        "!python histogram_localized.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f0c3cd-349b-490f-b6bd-7afbeb442fff",
      "metadata": {
        "id": "73f0c3cd-349b-490f-b6bd-7afbeb442fff"
      },
      "outputs": [],
      "source": [
        "histogram_output = !python histogram_localized.py output\n",
        "histogram = np.loadtxt(histogram_output, delimiter=\",\")\n",
        "\n",
        "# Print most frequently occuring characters.\n",
        "pairs = sorted(((i,c) for i,c in enumerate(histogram) if c), key=lambda x: x[1], reverse=True)[:20]\n",
        "labels = [('SPACE' if i==32 else chr(i)) if 32<=i<=126 else f'0x{i:02X}' for i,_ in pairs]\n",
        "plt.barh(labels[::-1], [c for _,c in pairs][::-1]); plt.xlabel('count'); plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d637b6b1-fb0b-4807-b70b-c80227c0fd6f",
      "metadata": {
        "id": "d637b6b1-fb0b-4807-b70b-c80227c0fd6f"
      },
      "outputs": [],
      "source": [
        "!ncu -f --kernel-name regex:histogram_localized --set full -o histogram_localized python histogram_localized.py\n",
        "histogram_localized_csv = !ncu --import histogram_localized.ncu-rep --csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "114e8ff7-b6fb-42ad-abda-f6d53479c052",
      "metadata": {
        "id": "114e8ff7-b6fb-42ad-abda-f6d53479c052"
      },
      "outputs": [],
      "source": [
        "nsightful.display_ncu_csv_in_notebook(histogram_localized_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3f9ca4-b61b-4536-9896-7a41498cc986",
      "metadata": {
        "id": "2a3f9ca4-b61b-4536-9896-7a41498cc986"
      },
      "outputs": [],
      "source": [
        "histogram_global_duration    = !python histogram_global.py\n",
        "histogram_localized_duration = !python histogram_localized.py\n",
        "speedup = float(histogram_global_duration[0].split()[0]) / float(histogram_localized_duration[0].split()[0])\n",
        "\n",
        "print(f\"histogram_global:    {histogram_global_duration[0]}\")\n",
        "print(f\"histogram_localized: {histogram_localized_duration[0]}\")\n",
        "print(f\"histogram_localized speedup over histogram_global: {speedup:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}