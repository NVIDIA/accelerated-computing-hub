{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise: Use NVTX\n",
        "\n",
        "In this exercise, you will learn how to ease the analysis of your application by using NVTX to annotate your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"): # If running in Google Colab:\n",
        "  !mkdir -p Sources\n",
        "  !wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/gpu-cpp-tutorial/notebooks/02.02-Asynchrony/Sources/ach.h -nv -O Sources/ach.h\n",
        "!wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/gpu-cpp-tutorial/notebooks/02.02-Asynchrony/Sources/nvtx3.hpp -nv -O Sources/nvtx3.hpp\n",
        "!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub > /dev/null 2>&1\n",
        "!sudo add-apt-repository -y \"deb https://developer.download.nvidia.com/devtools/repos/ubuntu$(source /etc/lsb-release; echo \"$DISTRIB_RELEASE\" | tr -d .)/$(dpkg --print-architecture)/ /\" > /dev/null 2>&1\n",
        "!sudo apt install -y nsight-systems > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile Sources/nvtx.cpp\n",
        "#include \"ach.h\"\n",
        "\n",
        "void simulate(int width, int height, const thrust::device_vector<float> &in,\n",
        "              thrust::device_vector<float> &out)\n",
        "{\n",
        "  cuda::std::mdspan temp_in(thrust::raw_pointer_cast(in.data()), height, width);\n",
        "  cub::DeviceTransform::Transform(\n",
        "      thrust::make_counting_iterator(0), out.begin(), width * height,\n",
        "      [=] __host__ __device__(int id) { return ach::compute(id, temp_in); });\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int height = 2048;\n",
        "  int width = 8192;\n",
        "\n",
        "  thrust::device_vector<float> d_prev = ach::init(height, width);\n",
        "  thrust::device_vector<float> d_next(height * width);\n",
        "  thrust::host_vector<float> h_prev(height * width);\n",
        "\n",
        "  const int compute_steps = 750;\n",
        "  const int write_steps = 3;\n",
        "  for (int write_step = 0; write_step < write_steps; write_step++)\n",
        "  {\n",
        "    nvtx3::scoped_range r{std::string(\"write step \") + std::to_string(write_step)};\n",
        "\n",
        "    {\n",
        "      // TODO: Annotate the \"copy\" step using nvtx range\n",
        "      thrust::copy(d_prev.begin(), d_prev.end(), h_prev.begin());\n",
        "    }\n",
        "\n",
        "    {\n",
        "      // TODO: Annotate the \"compute\" step using nvtx range\n",
        "      for (int compute_step = 0; compute_step < compute_steps; compute_step++)\n",
        "      {\n",
        "        simulate(width, height, d_prev, d_next);\n",
        "        d_prev.swap(d_next);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    {\n",
        "      // TODO: Annotate the \"write\" step using nvtx range\n",
        "      ach::store(write_step, height, width, h_prev);\n",
        "    }\n",
        "\n",
        "    {\n",
        "      // TODO: Annotate the \"wait\" step using nvtx range\n",
        "      cudaDeviceSynchronize();\n",
        "    }\n",
        "  }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc --extended-lambda -o /tmp/a.out Sources/nvtx.cpp -x cu -arch=native # build executable\n",
        "!nsys profile --force-overwrite true -o nvtx /tmp/a.out # run and profile executable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code above stores the output in a file called `nvtx` in the current directory.\n",
        "\n",
        "If you just completed the Nsight exercise, your UI interface should still be open.  \n",
        "If not, review the steps provided in the [Nsight exercise](02.02.03-Exercise-Nsight.ipynb).\n",
        "\n",
        "Open the new `nvtx` report and navigate to see the timeline of your application.\n",
        "Identify:\n",
        "- when GPU compute is launched\n",
        "- when CPU writes data on disk\n",
        "- when CPU waits for GPU\n",
        "- when data is transferred between CPU and GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you’re unsure how to proceed, consider expanding this section for guidance. Use the hint only after giving the problem a genuine attempt.\n",
        "\n",
        "<details>\n",
        "  <summary>Hints</summary>\n",
        "  \n",
        "  - `nvtx3::scoped_range r{\"name\"}` creates a range called `name`\n",
        "  - you can find NVTX ranges in the \"NVTX\" timeline row of Nsight Systems\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open this section only after you’ve made a serious attempt at solving the problem. Once you’ve completed your solution, compare it with the reference provided here to evaluate your approach and identify any potential improvements.\n",
        "\n",
        "<details>\n",
        "  <summary>Solution</summary>\n",
        "\n",
        "  You can annotate scopes as follows:\n",
        "  ```c++\n",
        "  {\n",
        "    nvtx3::scoped_range r{\"copy\"};\n",
        "    thrust::copy(d_prev.begin(), d_prev.end(), h_prev.begin());\n",
        "  }\n",
        "\n",
        "  {\n",
        "    nvtx3::scoped_range r{\"compute\"};\n",
        "    for (int compute_step = 0; compute_step < compute_steps; compute_step++) {\n",
        "      simulate(width, height, d_prev, d_next);\n",
        "      d_prev.swap(d_next);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  {\n",
        "    nvtx3::scoped_range r{\"write\"};\n",
        "    ach::store(write_step, height, width, h_prev);\n",
        "  }\n",
        "\n",
        "  {\n",
        "    nvtx3::scoped_range r{\"wait\"};\n",
        "    cudaDeviceSynchronize();\n",
        "  }\n",
        "  ```\n",
        "\n",
        "  You can find the full solution [here](Solutions/nvtx.cu).<br>\n",
        "  The esulting timeline should look like this:\n",
        "\n",
        "  ![Compute](Images/nvtx.png \"NVTX\")\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Great job!  You've learned how to use NVTX to annotate your code.  Proceed to the [next section](../02.03-Streams/02.03.01-Streams.ipynb) on streams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
