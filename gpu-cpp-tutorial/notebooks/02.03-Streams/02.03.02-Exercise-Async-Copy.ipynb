{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise: Async Copy and Streams\n",
        "\n",
        "Usage of streams:\n",
        "\n",
        "```c++\n",
        "cudaStream_t stream;\n",
        "\n",
        "// create a stream\n",
        "cudaStreamCreate(&stream); \n",
        "\n",
        "// make CPU wait for all operations in the stream to complete\n",
        "cudaStreamSynchronize(stream); \n",
        "\n",
        "// destroy the stream\n",
        "cudaStreamDestroy(stream);\n",
        "```\n",
        "\n",
        "Usage of `cub::DeviceTransform`:\n",
        "\n",
        "```c++\n",
        "cub::DeviceTransform::Transform(input_iterator, output_iterator, num_items, op, stream);\n",
        "```\n",
        "\n",
        "Usage of `cudaMemcpyAsync`:\n",
        "\n",
        "```c++\n",
        "cudaMemcpyAsync(dst, src, num_bytes, cudaMemcpyDeviceToHost, stream);\n",
        "```\n",
        "\n",
        "For this exercise, we'll attempt to make transfers between the host and device asynchronous.\n",
        "To do this, you are expected to:\n",
        "\n",
        "- replace `thrust::copy` with `cudaMemcpyAsync`\n",
        "- put compute and copy operations in separate CUDA streams\n",
        "- synchronize the streams to follow the pattern from the diagram below\n",
        "\n",
        "![Compute-Copy-Overlap](Images/async-copy.png \"Compute/Copy Overlap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Google Colab Setup\n",
        "!mkdir -p Sources\n",
        "!wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/gpu-cpp-tutorial/notebooks/02.03-Streams/Sources/ach.h -nv -O Sources/ach.h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile Sources/async-copy.cpp\n",
        "#include \"ach.h\"\n",
        "\n",
        "void simulate(int width, int height, const thrust::device_vector<float> &in,\n",
        "              thrust::device_vector<float> &out, \n",
        "              cudaStream_t stream = 0) \n",
        "{\n",
        "  cuda::std::mdspan temp_in(thrust::raw_pointer_cast(in.data()), height, width);\n",
        "  cub::DeviceTransform::Transform(\n",
        "      thrust::make_counting_iterator(0), out.begin(), width * height,\n",
        "      [=] __host__ __device__(int id) { return ach::compute(id, temp_in); },\n",
        "      stream);\n",
        "}\n",
        "\n",
        "int main() \n",
        "{\n",
        "  int height = 2048;\n",
        "  int width = 8192;\n",
        "\n",
        "  thrust::device_vector<float> d_prev = ach::init(height, width);\n",
        "  thrust::device_vector<float> d_next(height * width);\n",
        "  thrust::device_vector<float> d_buffer(height * width);\n",
        "  thrust::host_vector<float> h_prev(height * width);\n",
        "\n",
        "  const int compute_steps = 750;\n",
        "  const int write_steps = 3;\n",
        "\n",
        "  // 1. Create compute and copy streams\n",
        "\n",
        "  for (int write_step = 0; write_step < write_steps; write_step++) \n",
        "  {\n",
        "    thrust::copy(d_prev.begin(), d_prev.end(), d_buffer.begin());\n",
        "\n",
        "    // 2. Replace `thrust::copy` with `cudaMemcpyAsync` on copy stream.\n",
        "    //    Use `thrust::raw_pointer_cast(vec.data())` to get raw pointers from Thrust containers.\n",
        "    thrust::copy(d_buffer.begin(), d_buffer.end(), h_prev.begin());\n",
        "\n",
        "    for (int compute_step = 0; compute_step < compute_steps; compute_step++) \n",
        "    {\n",
        "      // 3. Put `simulate` on compute stream\n",
        "      simulate(width, height, d_prev, d_next);\n",
        "      d_prev.swap(d_next);\n",
        "    }\n",
        "\n",
        "    // 4. Make sure to synchronize copy stream before reading `h_prev`\n",
        "    ach::store(write_step, height, width, h_prev);\n",
        "\n",
        "    // 5. Make sure to synchronize compute stream before next iteration\n",
        "    cudaDeviceSynchronize(); \n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc --extended-lambda -o /tmp/a.out Sources/async-copy.cpp -x cu -arch=native # build executable\n",
        "!nsys profile --force-overwrite true -o ../nsight-reports/copy /tmp/a.out # run and profile executable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you’re unsure how to proceed, consider expanding this section for guidance. Use the hint only after giving the problem a genuine attempt.\n",
        "\n",
        "<details>\n",
        "  <summary>Hints</summary>\n",
        "  \n",
        "  - CUB accepts `stream` as its last argument `cub::DeviceTransform::Transform(input, output, num_items, op, stream)` \n",
        "  - `cudaMemcpyAsync` accepts `stream` as its last argument `cudaMemcpyAsync(dst, src, size, cudaMemcpyDeviceToHost, stream)`\n",
        "  - You can use the following operations on a CUDA stream:\n",
        "    - `cudaStreamCreate(&stream)` to create a stream\n",
        "    - `cudaStreamDestroy(stream)` to destroy a stream\n",
        "    - `cudaStreamSynchronize(stream)` to make the CPU wait for `stream` to finish all operations\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open this section only after you’ve made a serious attempt at solving the problem. Once you’ve completed your solution, compare it with the reference provided here to evaluate your approach and identify any potential improvements.\n",
        "\n",
        "<details>\n",
        "  <summary>Solution</summary>\n",
        "\n",
        "  Key points:\n",
        "\n",
        "  - Synchronize the copy stream before storing the data\n",
        "\n",
        "  Solution:\n",
        "  ```c++\n",
        "  cudaStream_t compute_stream;\n",
        "  cudaStreamCreate(&compute_stream);\n",
        "\n",
        "  cudaStream_t copy_stream;\n",
        "  cudaStreamCreate(&copy_stream);\n",
        "\n",
        "  for (int write_step = 0; write_step < write_steps; write_step++) \n",
        "  {\n",
        "    cudaMemcpy(thrust::raw_pointer_cast(d_buffer.data()),\n",
        "               thrust::raw_pointer_cast(d_prev.data()),\n",
        "               height * width * sizeof(float), cudaMemcpyDeviceToDevice);\n",
        "    cudaMemcpyAsync(thrust::raw_pointer_cast(h_temp.data()),\n",
        "                    thrust::raw_pointer_cast(d_buffer.data()),\n",
        "                    height * width * sizeof(float), cudaMemcpyDeviceToHost,\n",
        "                    copy_stream);\n",
        "\n",
        "    for (int compute_step = 0; compute_step < compute_steps; compute_step++) {\n",
        "      simulate(width, height, d_prev, d_next, compute_stream);\n",
        "      d_prev.swap(d_next);\n",
        "    }\n",
        "\n",
        "    cudaStreamSynchronize(copy_stream);\n",
        "    ach::store(write_step, height, width, h_temp);\n",
        "\n",
        "    cudaStreamSynchronize(compute_stream);\n",
        "  }\n",
        "\n",
        "  cudaStreamDestroy(compute_stream);\n",
        "  cudaStreamDestroy(copy_stream);\n",
        "  ```\n",
        "\n",
        "  You can find the full solution [here](Solutions/async-copy.cu).\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Great job!  Proceed to the [next section](../02.04-Pinned-Memory/02.04.01-Pinned.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}