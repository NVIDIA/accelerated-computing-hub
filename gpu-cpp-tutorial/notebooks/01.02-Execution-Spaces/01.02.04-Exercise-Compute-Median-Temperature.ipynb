{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise: Compute Median Temperature\n",
        "\n",
        "In many cases, porting code from CPU to GPU is as simple as replacing `std::` with `thrust::`.\n",
        "To verify this, we'll focus on calculating the median temperature in the vector. \n",
        "You'll start with a CPU-based implementation and modify the code to run on the GPU. \n",
        "Below is the original CPU code that you'll need to adapt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-10 23:45:15 URL:https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/gpu-cpp-tutorial/notebooks/01.02-Execution-Spaces/Sources/ach.h [2893/2893] -> \"Sources/ach.h\" [1]\n"
          ]
        }
      ],
      "source": [
        "#@title Google Colab Setup\n",
        "!mkdir -p Sources\n",
        "!wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/gpu-cpp-tutorial/notebooks/01.02-Execution-Spaces/Sources/ach.h -nv -O Sources/ach.h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile Sources/port-sort-to-gpu.cpp\n",
        "#include \"ach.h\"\n",
        "\n",
        "float median(thrust::universal_vector<float> vec) \n",
        "{\n",
        "    std::sort(vec.begin(), vec.end());\n",
        "    return vec[vec.size() / 2];\n",
        "}\n",
        "\n",
        "int main() \n",
        "{\n",
        "    float k = 0.5;\n",
        "    float ambient_temp = 20;\n",
        "    thrust::universal_vector<float> temp{ 42, 24, 50 };\n",
        "    auto transformation = [=] __host__ __device__ (float temp) { return temp + k * (ambient_temp - temp); };\n",
        "\n",
        "    std::printf(\"step  median\\n\");\n",
        "    for (int step = 0; step < 3; step++) {\n",
        "        thrust::transform(thrust::device, temp.begin(), temp.end(), temp.begin(), transformation);\n",
        "        float median_temp = median(temp);\n",
        "        std::printf(\"%d     %.2f\\n\", step, median_temp);\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc warning : Support for offline compilation for architectures prior to '<compute/sm/lto>_75' will be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "step  median\n",
            "0     31.00\n",
            "1     25.50\n",
            "2     22.75\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o /tmp/a.out --extended-lambda Sources/port-sort-to-gpu.cpp -x cu -arch=native # build executable\n",
        "!/tmp/a.out # run executable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If everything goes well, the cell above should print:\n",
        "\n",
        "| step | median\n",
        "| :--- | :-----\n",
        "| 0    | 31.00\n",
        "| 1    | 25.50\n",
        "| 2    | 22.75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you’re unsure how to proceed, consider expanding this section for guidance. Use the hint only after giving the problem a genuine attempt.\n",
        "\n",
        "<details>\n",
        "  <summary>Hints</summary>\n",
        "  \n",
        "  - Thrust provides a `thrust::sort` function that can be used to sort data on the GPU\n",
        "  - Use `thrust::device` execution policy to specify where you want `thrust::sort` to run\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open this section only after you’ve made a serious attempt at solving the problem. Once you’ve completed your solution, compare it with the reference provided here to evaluate your approach and identify any potential improvements.\n",
        "\n",
        "<details>\n",
        "  <summary>Solution</summary>\n",
        "\n",
        "  Key points:\n",
        "  - change `std::sort` to `thrust::sort`\n",
        "  - add `thrust::device` execution policy parameter\n",
        "\n",
        "  Solution:\n",
        "  ```c++\n",
        "  float median(thrust::universal_vector<float> vec) {\n",
        "    thrust::sort(thrust::device, vec.begin(), vec.end());\n",
        "    return vec[vec.size() / 2];\n",
        "  }\n",
        "  ```\n",
        "\n",
        "  You can find full solution [here](Solutions/port-sort-to-gpu.cu).\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "Now you should be comfortable with the concept of execution spaces and be able to port standard algorithms to GPU with Thrust!\n",
        "\n",
        "But what if your algorithm is not a standard one?\n",
        "\n",
        "Proceed to the [next section](../01.03-Extending-Algorithms/01.03.01-Extending-Algorithms.ipynb) to learn how to extend standard algorithms to your unique use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },

    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}