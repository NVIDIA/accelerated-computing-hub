{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise: Async Copy and Pinned Memory\n",
        "\n",
        "For this exercise, we'll attempt to fix our program to make the copy actually asynchronous.\n",
        "To do this, you are expected to:\n",
        "\n",
        "- Use `thrust::universal_host_pinned_vector` to allocate pinned memory for the host buffer\n",
        "- Profile the program to see if the copy becomes asynchronous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>Copy of the original code if you need to refer to it.</summary>\n",
        "\n",
        "```c++\n",
        "%%writefile Sources/copy-overlap.cpp\n",
        "#include \"ach.h\"\n",
        "\n",
        "int main() \n",
        "{\n",
        "  int height = 2048;\n",
        "  int width = 8192;\n",
        "\n",
        "  cudaStream_t compute_stream;\n",
        "  cudaStreamCreate(&compute_stream);\n",
        "\n",
        "  cudaStream_t copy_stream;\n",
        "  cudaStreamCreate(&copy_stream);\n",
        "\n",
        "  thrust::device_vector<float> d_prev = ach::init(height, width);\n",
        "  thrust::device_vector<float> d_next(height * width);\n",
        "  thrust::device_vector<float> d_buffer(height * width);\n",
        "\n",
        "  // 1. Change code below to allocate host vector in pinned memory\n",
        "  thrust::host_vector<float> h_prev(height * width);\n",
        "\n",
        "  const int compute_steps = 750;\n",
        "  const int write_steps = 3;\n",
        "  for (int write_step = 0; write_step < write_steps; write_step++) \n",
        "  {\n",
        "    cudaMemcpy(thrust::raw_pointer_cast(d_buffer.data()),\n",
        "               thrust::raw_pointer_cast(d_prev.data()),\n",
        "               height * width * sizeof(float), cudaMemcpyDeviceToDevice);\n",
        "    cudaMemcpyAsync(thrust::raw_pointer_cast(h_prev.data()),\n",
        "                    thrust::raw_pointer_cast(d_buffer.data()),\n",
        "                    height * width * sizeof(float), cudaMemcpyDeviceToHost,\n",
        "                    copy_stream);\n",
        "\n",
        "    for (int compute_step = 0; compute_step < compute_steps; compute_step++) \n",
        "    {\n",
        "      ach::simulate(width, height, d_prev, d_next, compute_stream);\n",
        "      d_prev.swap(d_next);\n",
        "    }\n",
        "\n",
        "    cudaStreamSynchronize(copy_stream);\n",
        "    ach::store(write_step, height, width, h_prev);\n",
        "\n",
        "    cudaStreamSynchronize(compute_stream);\n",
        "  }\n",
        "\n",
        "  cudaStreamDestroy(compute_stream);\n",
        "  cudaStreamDestroy(copy_stream);\n",
        "}\n",
        "```\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Google Colab Setup\n",
        "!mkdir -p Sources\n",
        "!wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/gpu-cpp-tutorial/notebooks/02.04-Pinned-Memory/Sources/ach.h -nv -O Sources/ach.h\n",
        "!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub > /dev/null 2>&1 \n",
        "!sudo add-apt-repository -y \"deb https://developer.download.nvidia.com/devtools/repos/ubuntu$(source /etc/lsb-release; echo \"$DISTRIB_RELEASE\" | tr -d .)/$(dpkg --print-architecture)/ /\" > /dev/null 2>&1 \n",
        "!sudo apt install -y nsight-systems > /dev/null 2>&1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile Sources/copy-overlap.cpp\n",
        "#include \"ach.h\"\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int height = 2048;\n",
        "  int width = 8192;\n",
        "\n",
        "  cudaStream_t compute_stream;\n",
        "  cudaStreamCreate(&compute_stream);\n",
        "\n",
        "  cudaStream_t copy_stream;\n",
        "  cudaStreamCreate(&copy_stream);\n",
        "\n",
        "  thrust::device_vector<float> d_prev = ach::init(height, width);\n",
        "  thrust::device_vector<float> d_next(height * width);\n",
        "  thrust::device_vector<float> d_buffer(height * width);\n",
        "\n",
        "  // TODO: Change code below to allocate host vector in pinned memory\n",
        "  thrust::host_vector<float> h_prev(height * width);\n",
        "\n",
        "  const int compute_steps = 750;\n",
        "  const int write_steps = 3;\n",
        "  for (int write_step = 0; write_step < write_steps; write_step++)\n",
        "  {\n",
        "    cudaMemcpy(thrust::raw_pointer_cast(d_buffer.data()),\n",
        "               thrust::raw_pointer_cast(d_prev.data()),\n",
        "               height * width * sizeof(float), cudaMemcpyDeviceToDevice);\n",
        "    cudaMemcpyAsync(thrust::raw_pointer_cast(h_prev.data()),\n",
        "                    thrust::raw_pointer_cast(d_buffer.data()),\n",
        "                    height * width * sizeof(float), cudaMemcpyDeviceToHost,\n",
        "                    copy_stream);\n",
        "\n",
        "    for (int compute_step = 0; compute_step < compute_steps; compute_step++)\n",
        "    {\n",
        "      ach::simulate(width, height, d_prev, d_next, compute_stream);\n",
        "      d_prev.swap(d_next);\n",
        "    }\n",
        "\n",
        "    cudaStreamSynchronize(copy_stream);\n",
        "    ach::store(write_step, height, width, h_prev);\n",
        "\n",
        "    cudaStreamSynchronize(compute_stream);\n",
        "  }\n",
        "\n",
        "  cudaStreamDestroy(compute_stream);\n",
        "  cudaStreamDestroy(copy_stream);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc --extended-lambda -o /tmp/a.out Sources/copy-overlap.cpp -x cu -arch=native # build executable\n",
        "!nsys profile --force-overwrite true -o pinned /tmp/a.out # run and profile executable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you’re unsure how to proceed, consider expanding this section for guidance. Use the hint only after giving the problem a genuine attempt.\n",
        "\n",
        "<details>\n",
        "  <summary>Hints</summary>\n",
        "  \n",
        "  - You can allocate pinned memory with `thrust::universal_host_pinned_vector`\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open this section only after you’ve made a serious attempt at solving the problem. Once you’ve completed your solution, compare it with the reference provided here to evaluate your approach and identify any potential improvements.\n",
        "\n",
        "<details>\n",
        "  <summary>Solution</summary>\n",
        "\n",
        "  Key points:\n",
        "\n",
        "  - Use `thrust::universal_host_pinned_vector` to allocate pinned memory for the host buffer\n",
        "\n",
        "  Solution:\n",
        "  ```c++\n",
        "  thrust::universal_host_pinned_vector<float> h_prev(height * width);\n",
        "\n",
        "  const int compute_steps = 750;\n",
        "  const int write_steps = 3;\n",
        "  for (int write_step = 0; write_step < write_steps; write_step++) {\n",
        "    cudaMemcpy(thrust::raw_pointer_cast(d_buffer.data()),\n",
        "               thrust::raw_pointer_cast(d_prev.data()),\n",
        "               height * width * sizeof(float), cudaMemcpyDeviceToDevice);\n",
        "    cudaMemcpyAsync(thrust::raw_pointer_cast(h_prev.data()),\n",
        "                    thrust::raw_pointer_cast(d_buffer.data()),\n",
        "                    height * width * sizeof(float), cudaMemcpyDeviceToHost,\n",
        "                    copy_stream);\n",
        "    // ...\n",
        "  }\n",
        "  ```\n",
        "\n",
        "  You can find the full solution [here](Solutions/copy-overlap.cu).\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Congratulations!  You've completed the Asynchrony and Streams lab.  Move on to the [CUDA Kernels](../03.01-Introduction/03.01-Introduction.ipynb) lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
