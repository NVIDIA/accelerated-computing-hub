{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Types\n",
    "\n",
    "## Content\n",
    "\n",
    "* [Naive Heat Transfer](#Naive-Heat-Transfer)\n",
    "* [Thrust Tabulate](#Thrust-Tabulate)\n",
    "* [Code Reuse](#Code-Reuse)\n",
    "* [`mdspan`](#mdspan)\n",
    "* [Exercise: `mdspan`](01.04.02-Exercise-mdspan.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "You've learned enough tools and concepts to improve our small heat simulator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"): # If running in Google Colab:\n",
    "  !mkdir -p Sources\n",
    "  !wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/cuda-cpp-tutorial/notebooks/01.04-Vocabulary-Types/Sources/ach.h -nv -O Sources/ach.h\n",
    "  !wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/cuda-cpp-tutorial/notebooks/01.04-Vocabulary-Types/Sources/ach.py -nv -O Sources/ach.py\n",
    "  !wget https://raw.githubusercontent.com/NVIDIA/accelerated-computing-hub/refs/heads/main/cuda-cpp-tutorial/notebooks/01.04-Vocabulary-Types/Sources/__init__.py -nv -O Sources/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Heat Transfer\n",
    "\n",
    "Below is the code for the naive `simulate` function.  Execute the following two cells to run the code and observe the heat transfer via a visualization.  Note the use of `thrust::transform` and also `thrust::make_counting_iterator(0)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/naive-heat-2D.cpp\n",
    "#include \"ach.h\"\n",
    "\n",
    "void simulate(int height, int width,\n",
    "              const thrust::universal_vector<float> &in,\n",
    "                    thrust::universal_vector<float> &out)\n",
    "{\n",
    "  const float *in_ptr = thrust::raw_pointer_cast(in.data());\n",
    "\n",
    "  auto cell_indices = thrust::make_counting_iterator(0);\n",
    "  thrust::transform(\n",
    "      thrust::device, cell_indices, cell_indices + in.size(), out.begin(),\n",
    "      [in_ptr, height, width] __host__ __device__(int id) {\n",
    "        int column = id % width;\n",
    "        int row = id / width;\n",
    "\n",
    "        if (row > 0 && column > 0 && row < height - 1 && column < width - 1) {\n",
    "          float d2tdx2 = in_ptr[(row) * width + column - 1] - 2 * in_ptr[row * width + column] + in_ptr[(row) * width + column + 1];\n",
    "          float d2tdy2 = in_ptr[(row - 1) * width + column] - 2 * in_ptr[row * width + column] + in_ptr[(row + 1) * width + column];\n",
    "\n",
    "          return in_ptr[row * width + column] + 0.2f * (d2tdx2 + d2tdy2);\n",
    "        } else {\n",
    "          return in_ptr[row * width + column];\n",
    "        }\n",
    "      });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Sources.ach\n",
    "Sources.ach.run(\"Sources/naive-heat-2D.cpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thrust Tabulate\n",
    "\n",
    "The Thrust library has another function called `tabulate` that applies an operator to element indices and stores the result at the same index.  It is essentially the equivalent of the above example of transformation of the counting iterator.\n",
    "\n",
    "Execute the following two cells to illustrate the heat transfer function with the `thrust::tabulate` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/tabulate.cpp\n",
    "#include \"ach.h\"\n",
    "\n",
    "void simulate(int height, int width,\n",
    "              const thrust::universal_vector<float> &in,\n",
    "                    thrust::universal_vector<float> &out)\n",
    "{\n",
    "  const float *in_ptr = thrust::raw_pointer_cast(in.data());\n",
    "\n",
    "  thrust::tabulate(\n",
    "    thrust::device, out.begin(), out.end(),\n",
    "    [in_ptr, height, width] __host__ __device__(int id) {\n",
    "      int column = id % width;\n",
    "      int row = id / width;\n",
    "\n",
    "      if (row > 0 && column > 0 && row < height - 1 && column < width - 1) {\n",
    "        float d2tdx2 = in_ptr[(row) * width + column - 1] - 2 * in_ptr[row * width + column] + in_ptr[(row) * width + column + 1];\n",
    "        float d2tdy2 = in_ptr[(row - 1) * width + column] - 2 * in_ptr[row * width + column] + in_ptr[(row + 1) * width + column];\n",
    "\n",
    "        return in_ptr[row * width + column] + 0.2f * (d2tdx2 + d2tdy2);\n",
    "      } else {\n",
    "        return in_ptr[row * width + column];\n",
    "      }\n",
    "    });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Sources.ach\n",
    "Sources.ach.run(\"Sources/tabulate.cpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Reuse\n",
    "\n",
    "You may have noticed that in the body of the function we are doing some involved offset arithmetic to index into the correct values of the array that we're working with.  Since we are in C++, we are doing these offset calculations in row major order and we can use the `make_pair` function to do this arithmetic for us once, instead of calculating `row` and `column` repeatedly.\n",
    "\n",
    "Execute the following two cells to illustrate the use of `make_pair` to create the function `row_col`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/std-pair.cpp\n",
    "#include \"ach.h\"\n",
    "\n",
    "__host__ __device__\n",
    "std::pair<int, int> row_col(int id, int width) {\n",
    "    return std::make_pair(id / width, id % width);\n",
    "}\n",
    "\n",
    "void simulate(int height, int width,\n",
    "              const thrust::universal_vector<float> &in,\n",
    "                    thrust::universal_vector<float> &out)\n",
    "{\n",
    "  const float *in_ptr = thrust::raw_pointer_cast(in.data());\n",
    "\n",
    "  thrust::tabulate(\n",
    "    thrust::device, out.begin(), out.end(),\n",
    "    [in_ptr, height, width] __host__ __device__(int id) {\n",
    "      auto [row, column] = row_col(id, width);\n",
    "\n",
    "      if (row > 0 && column > 0 && row < height - 1 && column < width - 1) {\n",
    "        float d2tdx2 = in_ptr[(row) * width + column - 1] - 2 * in_ptr[row * width + column] + in_ptr[(row) * width + column + 1];\n",
    "        float d2tdy2 = in_ptr[(row - 1) * width + column] - 2 * in_ptr[row * width + column] + in_ptr[(row + 1) * width + column];\n",
    "\n",
    "        return in_ptr[row * width + column] + 0.2f * (d2tdx2 + d2tdy2);\n",
    "      } else {\n",
    "        return in_ptr[row * width + column];\n",
    "      }\n",
    "    });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --extended-lambda -std=c++17 -x cu -arch=native -o /tmp/a.out Sources/std-pair.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you didn't change any code, you'll have encountered a warning message similar to the following:\n",
    "\n",
    "`calling a __host__ function(\"make_pair\") from a __host__ __device__ function(\"row_col\") is not allowed.`\n",
    "\n",
    "`std::make_pair` is a host function, not a device function.  Thinking back to the earlier part of our course, a host function is compiled to run on the host, and if there is no equivalent device function, that code will NOT run on the device.  That is what the error message is telling us, i.e., we don't have any device function called `std::make_pair` and therefore it can't run on the device.\n",
    "\n",
    "Fortunately NVIDIA has implemented many of these standard types in CUDA via the [libcu++](https://nvidia.github.io/cccl/libcudacxx/) library, and for the `std::` types implemented in `libcu++`, it's as simple as prepending `cuda::` in front of the `std::` types you're using.\n",
    "\n",
    "Notice below the code is identical to the previous example, with the two small changes of prepending `cuda::` in front of both `std::pair` and `std::make_pair`.\n",
    "\n",
    "Run the code and observe that it compiles and runs without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/pair.cpp\n",
    "#include \"ach.h\"\n",
    "\n",
    "__host__ __device__\n",
    "cuda::std::pair<int, int> row_col(int id, int width) {\n",
    "    return cuda::std::make_pair(id / width, id % width);\n",
    "}\n",
    "\n",
    "void simulate(int height, int width,\n",
    "              const thrust::universal_vector<float> &in,\n",
    "                    thrust::universal_vector<float> &out)\n",
    "{\n",
    "  const float *in_ptr = thrust::raw_pointer_cast(in.data());\n",
    "\n",
    "  thrust::tabulate(\n",
    "    thrust::device, out.begin(), out.end(),\n",
    "    [in_ptr, height, width] __host__ __device__(int id) {\n",
    "      auto [row, column] = row_col(id, width);\n",
    "\n",
    "      if (row > 0 && column > 0 && row < height - 1 && column < width - 1) {\n",
    "        float d2tdx2 = in_ptr[(row) * width + column - 1] - 2 * in_ptr[row * width + column] + in_ptr[(row) * width + column + 1];\n",
    "        float d2tdy2 = in_ptr[(row - 1) * width + column] - 2 * in_ptr[row * width + column] + in_ptr[(row + 1) * width + column];\n",
    "\n",
    "        return in_ptr[row * width + column] + 0.2f * (d2tdx2 + d2tdy2);\n",
    "      } else {\n",
    "        return in_ptr[row * width + column];\n",
    "      }\n",
    "    });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Sources.ach\n",
    "Sources.ach.run(\"Sources/pair.cpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `mdspan`\n",
    "\n",
    "`pair` is not the only vocabulary type that will improve our code.  Consider how we are manually flattening the 2D coordinates to access the 1D array.  This approach is error-prone and makes the code difficult to read and understand.  Additionally, consider situations where more than 2D coordinates are being used; the complexity of the pointer indexing will rapidly increase!\n",
    "\n",
    "For the section exercise, we'll explore the use of `mdspan`, which is a vocabulary type used to make this type of indexing much easier.  See a simple use of `mdspan` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/mdspan-intro.cpp\n",
    "\n",
    "#include <cuda/std/mdspan>\n",
    "#include <cuda/std/array>\n",
    "#include <cstdio>\n",
    "\n",
    "int main() {\n",
    "  cuda::std::array<int, 6> sd {0, 1, 2, 3, 4, 5};\n",
    "  cuda::std::mdspan md(sd.data(), 2, 3);\n",
    "\n",
    "  std::printf(\"md(0, 0) = %d\\n\", md(0, 0)); // 0\n",
    "  std::printf(\"md(1, 2) = %d\\n\", md(1, 2)); // 5\n",
    "\n",
    "  std::printf(\"size   = %zu\\n\", md.size());    // 6\n",
    "  std::printf(\"height = %zu\\n\", md.extent(0)); // 2\n",
    "  std::printf(\"width  = %zu\\n\", md.extent(1)); // 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -std=c++17 -o /tmp/a.out Sources/mdspan-intro.cpp -x cu -arch=native && /tmp/a.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Proceed to [the `mdspan` exercise](01.04.02-Exercise-mdspan.ipynb)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
